{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89a1b5e3-69d3-409a-8767-2281fe7dc97e",
   "metadata": {},
   "source": [
    "# Federated learning 2-layer MLP on MNIST dataset\n",
    "\n",
    "reference: https://github.com/AshwinRJ/Federated-Learning-PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "659fc889-d7b6-4772-bb81-8a30fc842547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] Die angegebene Prozedur wurde nicht gefunden\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e8df384cf0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm import notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# reproducibility\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d64993-c220-4ba2-a351-ab730f0b9fb2",
   "metadata": {},
   "source": [
    "## Help functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fa49901-5155-4074-8b40-afc9a0a5561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a subset of some dataset that contains selected sample points of it\n",
    "class DatasetSplit(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, ids):\n",
    "        \"\"\"\n",
    "        @ dataset: raw dataset, in this example it is MNIST train dataset\n",
    "        @ ids    : a list/tensor/nparray of indices into raw dataset\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.ids = [int(i) for i in ids]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image, label = self.dataset[self.ids[item]]\n",
    "        return torch.tensor(image), torch.tensor(label)\n",
    "\n",
    "# average parameters\n",
    "def average_paras(paras, weights = None):\n",
    "    \"\"\"\n",
    "    @ paras  : list of model parameters\n",
    "    @ weights: number of data points of each client\n",
    "    \"\"\"\n",
    "    if weights == None:\n",
    "        weights = [1] * len(paras)\n",
    "        \n",
    "    paras_avg = copy.deepcopy(paras[0])\n",
    "    for key in paras_avg.keys():\n",
    "        paras_avg[key] *= weights[0]\n",
    "        for i in range(1, len(paras)):\n",
    "            paras_avg[key] += paras[i][key] * weights[i]\n",
    "        paras_avg[key] = torch.div(paras_avg[key], sum(weights))\n",
    "    return paras_avg\n",
    "\n",
    "# compute weighted average\n",
    "def weighted_avg(values, weights = None):\n",
    "    if weights == None:\n",
    "        weights = [1] * len(values)\n",
    "    summ = 0\n",
    "    for weight, value in zip(weights, values):\n",
    "        summ += weight * value\n",
    "    return summ / sum(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252917f1-9597-44fd-a277-9eb33ee80b90",
   "metadata": {},
   "source": [
    "## Data distribution among clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff06cf83-f2b0-4b35-90dc-d58966c3d02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "train_dataset = torchvision.datasets.MNIST('./data', transform=torchvision.transforms.ToTensor(), download=True, train=True)\n",
    "test_dataset  = torchvision.datasets.MNIST('./data', transform=torchvision.transforms.ToTensor(), download=True, train=False)\n",
    "\n",
    "# global test data loader\n",
    "test_loader   = torch.utils.data.DataLoader(test_dataset , batch_size = 64, shuffle = False)\n",
    "\n",
    "# some prints\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b932bcd4-f744-4f4f-b934-46529379f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data among clients\n",
    "def client_data_split(num_client = 100, iid = True, client_equal_size = True, dataset = train_dataset, num_chunk = 200):\n",
    "    \"\"\" split data among clients\n",
    "    @ num_client       : number of clients\n",
    "    @ iid              : whether data is distributed iid.\n",
    "    @ client_equal_size: whether each client gets same amount of data points\n",
    "    @ dataset          : MNIST training dataset by default, with 60000 images\n",
    "    @ num_chunk        : split whole dataset into how many chunks, used to simulate non-iid data distribution\n",
    "    \n",
    "    @ return           : list of list of indices into data\n",
    "    \"\"\"    \n",
    "    data_size = len(train_dataset)\n",
    "    \n",
    "    if iid and client_equal_size:\n",
    "        random_ids = np.random.permutation(data_size)\n",
    "        return np.array_split(random_ids, num_client)\n",
    "    \n",
    "    elif iid and not client_equal_size:\n",
    "        random_ids   = np.random.permutation(data_size)\n",
    "        split_points = np.random.choice(range(1, data_size-1), num_client - 1, replace = False)\n",
    "        split_points = np.sort(split_points)\n",
    "        split_points = np.append(0, split_points)\n",
    "        split_points = np.append(split_points, data_size)\n",
    "        return_list  = []\n",
    "        for i in range(num_client):\n",
    "            return_list.append(random_ids[split_points[i]:split_points[i+1]])\n",
    "        return return_list\n",
    "    \n",
    "    elif not iid and client_equal_size:\n",
    "        num_chunk_per_client = num_chunk // num_client\n",
    "        chunk_size  = data_size // num_chunk\n",
    "        sort_ids    = np.argsort(train_dataset.targets)\n",
    "        chunk_ids   = set(range(num_chunk))\n",
    "        return_list = []\n",
    "        for i in range(num_client):\n",
    "            chunk_ids_client = set(np.random.choice(list(chunk_ids), num_chunk_per_client, replace = False))\n",
    "            chunk_ids = chunk_ids - chunk_ids_client\n",
    "            elem = np.array([], dtype = 'int32')\n",
    "            for chunk_id in chunk_ids_client:\n",
    "                elem = np.concatenate((elem, sort_ids[chunk_id * chunk_size : (chunk_id + 1) * chunk_size]))\n",
    "            elem = np.random.permutation(elem)\n",
    "            return_list.append(elem)\n",
    "        return return_list\n",
    "    \n",
    "    else: # iid is False and client_equal_size is False:\n",
    "        raise Exception(\"non-iid & non-equal-size not implemented yet!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b16ebb-332a-4b83-adf4-8084b92df82c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c7ac4a4-b1b3-45df-80c7-c4424f31d1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vanilla_MLP(torch.nn.Module):\n",
    "    def __init__(self, input_size = 28*28, layer1_size = 64, num_class = 10, dropout = 0.5):\n",
    "        super(Vanilla_MLP, self).__init__()\n",
    "        self.layer0  = torch.nn.Linear(input_size, layer1_size)\n",
    "        self.layer1  = torch.nn.Linear(layer1_size, num_class)\n",
    "        self.relu    = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(p = dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.layer0(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadb56e6-065d-4fc6-a966-f118da20811e",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc245277-a3a1-408a-b669-81439f12ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client is an object, which contains its own dataset, dataloader, local model copy (for simplification, only local parameters) and training loop fucntion\n",
    "class Client(object):\n",
    "    def __init__(self, data_ids, client_id, model = Vanilla_MLP(), train_dataset = train_dataset, train_test_split = 0, batch_size = 64, num_epoch = 10, optimizer = torch.optim.Adam, learning_rate = 1e-4, l2_regular = 0.1, loss_func = F.cross_entropy, print_round = 1):\n",
    "        \"\"\"\n",
    "        @ data_ids        : indices into raw train dataset\n",
    "        @ client_id       : id of this client\n",
    "        @ model           : model of this client\n",
    "        @ train_dataset   : raw train dataset, by default MNIST train dataset\n",
    "        @ train_test_split: 0.8 by default\n",
    "        @ batch_size      : local batch size , by default 64\n",
    "        @ num_epoch       : number of local training epochs between two global updates, by default 10\n",
    "        @ optimizer       : Adam by default\n",
    "        @ learning_rate   : 1e-4 by default\n",
    "        @ l2_regular      : 0.1 by default\n",
    "        @ loss_func       : cross entropy by default\n",
    "        @ print_round     : print frequency, 1 by default\n",
    "        \"\"\"\n",
    "        self.model         = model\n",
    "        self.client_id     = client_id\n",
    "        self.num_epoch     = num_epoch\n",
    "        self.loss_func     = loss_func\n",
    "        self.print_round   = print_round\n",
    "        self.data_ids      = data_ids\n",
    "        self.optimizer     = optimizer(model.parameters(), lr = learning_rate, weight_decay = l2_regular)\n",
    "        \n",
    "        # local train-test-split, any value of train_test_split <= 0 or >= 1 is considered as not doing split, hence no local test\n",
    "        self.local_split = 0 < train_test_split < 1\n",
    "        if self.local_split:\n",
    "            train_test_split   = max(train_test_split, 1-train_test_split)\n",
    "            split_point        = int(train_test_split * len(data_ids))\n",
    "            self.train_ids     = data_ids[:split_point]\n",
    "            self.test_ids      = data_ids[split_point:]\n",
    "            self.train_dataset = DatasetSplit(train_dataset, self.train_ids)\n",
    "            self.test_dataset  = DatasetSplit(train_dataset, self.test_ids)\n",
    "            self.train_loader  = torch.utils.data.DataLoader(self.train_dataset, batch_size = batch_size, shuffle=True)\n",
    "            self.test_loader   = torch.utils.data.DataLoader(self.test_dataset , batch_size = batch_size, shuffle=False)\n",
    "        else:\n",
    "            self.train_ids     = self.data_ids\n",
    "            self.train_dataset = DatasetSplit(train_dataset, self.train_ids)\n",
    "            self.train_loader  = torch.utils.data.DataLoader(self.train_dataset, batch_size = batch_size, shuffle=True)\n",
    "            \n",
    "        self.train_losses       = []\n",
    "        self.test_losses_before = []\n",
    "        self.test_accus_before  = []\n",
    "        self.test_losses_after  = []\n",
    "        self.test_accus_after   = []\n",
    "    \n",
    "    ############################### local train ###################################\n",
    "    def local_train(self, global_round = -1):\n",
    "        \"\"\" local training\n",
    "        \n",
    "        @ global_round: current global update round, only used for print\n",
    "        \n",
    "        @ return      : updated model and avg training loss per epoch\n",
    "        \"\"\"\n",
    "        self.model.to(device)\n",
    "        self.model.train()\n",
    "        epoch_losses = []\n",
    "        \n",
    "        for epoch in range(self.num_epoch):\n",
    "            sum_batch_loss = 0\n",
    "            \n",
    "            for batch_id, (images, labels) in enumerate(self.train_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                predicts = self.model(images)\n",
    "                \n",
    "                loss = self.loss_func(predicts, labels, reduction = 'sum')\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                sum_batch_loss += loss.item()\n",
    "            \n",
    "            epoch_loss = sum_batch_loss / len(self.train_ids)\n",
    "            epoch_losses.append(epoch_loss)\n",
    "        \n",
    "        self.train_losses.append(epoch_losses)\n",
    "        avg_epoch_loss = sum(epoch_losses) / self.num_epoch\n",
    "        \n",
    "        if global_round % self.print_round == 0:\n",
    "            print(\"global round: {:02d}\".format(global_round), \" client: {:02d}\".format(self.client_id), \" local train loss: {:.4f}\".format(avg_epoch_loss))\n",
    "        \n",
    "        self.model.to('cpu')\n",
    "        \n",
    "        return self.model, avg_epoch_loss\n",
    "    \n",
    "    ############################### local test ###################################\n",
    "    def local_test(self, global_round = -1, before_agg = True):\n",
    "        \"\"\" local test\n",
    "        \n",
    "        @ global_round: current global update round, only used for print\n",
    "        @ before_agg  : whether test happens before or after global aggregation\n",
    "        \n",
    "        @ return      : avg test loss and avg test accuracy\n",
    "        \"\"\"\n",
    "        # only run local test if local train-test-split is done\n",
    "        assert(self.local_split)\n",
    "        \n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        sum_batch_loss = 0\n",
    "        num_correct_preds = 0\n",
    "            \n",
    "        for batch_id, (images, labels) in enumerate(self.test_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predicts = self.model(images)\n",
    "\n",
    "            loss = self.loss_func(predicts, labels, reduction = 'sum')\n",
    "            sum_batch_loss += loss.item()\n",
    "            \n",
    "            _, pred_labels = torch.max(predicts, 1)\n",
    "            pred_labels = pred_labels.view(-1)\n",
    "            num_correct_preds += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "\n",
    "        avg_loss = sum_batch_loss / len(self.test_ids)\n",
    "        avg_accu = num_correct_preds / len(self.test_ids)\n",
    "        if before_agg:\n",
    "            self.test_losses_before.append(avg_loss)\n",
    "            self.test_accus_before .append(avg_accu)\n",
    "        else:\n",
    "            self.test_losses_after .append(avg_loss)\n",
    "            self.test_accus_after  .append(avg_accu)\n",
    "        \n",
    "        if global_round % self.print_round == 0:\n",
    "            print(\"global round: {:02d}\".format(global_round), \" client: {:02d}\".format(self.client_id), \" local test  loss: {:.4f}\".format(avg_loss), \" local test accu: {:.3f}\".format(avg_accu), \" before agg:\", before_agg)\n",
    "            \n",
    "        self.model.to('cpu')\n",
    "        \n",
    "        return avg_loss, avg_accu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36771a5-14bd-402c-a0ed-a9fe0268e02c",
   "metadata": {},
   "source": [
    "## Global update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ac583ea-6915-4ef5-93ff-53f644b4584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "def federated_learning( num_global_round       = 100 ,\n",
    "                        num_client             = 100 ,\n",
    "                        same_init              = True,       # whether all local models have the same starting point \n",
    "                        update_C               = 0.1 ,       # proportion of clients updated per round, which is the parameter C in paper, range 0.0 ~ 1.0 \n",
    "                        iid                    = True,\n",
    "                        client_equal_size      = True,\n",
    "                        print_round            = 1   ,\n",
    "                        local_train_test_split = 0   ,         # any value outside of <=0 or >=1.0 is considers as not doing train-test-split locally, hence local test is also not possible\n",
    "                        local_batch_size       = 64  ,\n",
    "                        local_num_epoch        = 10  ,\n",
    "                        local_learning_rate    = 1e-4,\n",
    "                        local_l2_regular       = 0.1 ,\n",
    "                        ):\n",
    "    \"\"\" main function for federated learning global update\n",
    "    \n",
    "    @ num_global_round      : number of global update rounds\n",
    "    @ num_client            : number of clients\n",
    "    @ same_init             : whether all client models have the same initialization\n",
    "    @ update_C              : proportion of clients updated per round, which is the parameter C in paper, range 0.0 ~ 1.0\n",
    "    @ iid                   : whether data distribution among clients is iid\n",
    "    @ client_equal_size     : whether each client has same amount of data\n",
    "    @ print_round           : print something per round\n",
    "    @ local_train_test_split: whether each client does train-test-split locally, any value <= 0 or >= means not doing the split, and hence no local test/validation\n",
    "    @ local_batch_size      : batch size for local training, which is the parameter B in paper\n",
    "    @ local_num_epoch       : number of epochs each client go through between two global update rounds, which is the parameter E in paper, can be an int or a list of int\n",
    "    @ local_learning_rate   : learnng rate for local training\n",
    "    @ local_l2_regular      : weight decay for local training\n",
    "    \n",
    "    @ return                : loss/accu history and clients\n",
    "    \"\"\"\n",
    "    # split data among clients\n",
    "    data_splits     = client_data_split(num_client = num_client, iid = iid, client_equal_size = client_equal_size)\n",
    "    num_client_data = [len(i) for i in data_splits]\n",
    "\n",
    "    # global model\n",
    "    global_model = Vanilla_MLP()\n",
    "\n",
    "    # generate client instances\n",
    "    clients = []\n",
    "    local_num_epoch = [local_num_epoch] * num_client if isinstance(local_num_epoch, int) else local_num_epoch # int to list \n",
    "    for i in range(num_client):\n",
    "        if same_init:\n",
    "            client = Client(model = copy.deepcopy(global_model), batch_size = local_batch_size, num_epoch = local_num_epoch[i], learning_rate = local_learning_rate, \n",
    "                            l2_regular = local_l2_regular, print_round = print_round, data_ids = data_splits[i], train_test_split = local_train_test_split, client_id = i)\n",
    "        else:\n",
    "            client = Client(model = Vanilla_MLP(), batch_size = local_batch_size, num_epoch = local_num_epoch[i], learning_rate = local_learning_rate, \n",
    "                            l2_regular = local_l2_regular, print_round = print_round, data_ids = data_splits[i], train_test_split = local_train_test_split, client_id = i)\n",
    "        clients.append(client)\n",
    "\n",
    "    # number of clients to update per round\n",
    "    num_update_client   = min(max(int(update_C * num_client), 1), num_client)\n",
    "\n",
    "    # global update loop\n",
    "    local_split = 0 < local_train_test_split < 1\n",
    "    local_train_losses       = []\n",
    "    local_test_losses_before = []\n",
    "    local_test_accus_before  = []\n",
    "    local_test_losses_after  = []\n",
    "    local_test_accus_after   = []\n",
    "    global_test_losses       = []\n",
    "    global_test_accus        = []\n",
    "    for global_round in notebook.tqdm(range(num_global_round)):\n",
    "        client_ids         = np.random.choice(num_client, num_update_client, replace=False)\n",
    "        client_weights     = [num_client_data[client_id] for client_id in client_ids]\n",
    "        new_paras          = []\n",
    "        train_losses       = []\n",
    "        test_losses_before = []\n",
    "        test_accus_before  = []\n",
    "        test_losses_after  = []\n",
    "        test_accus_after   = []\n",
    "\n",
    "        # local train\n",
    "        for client_id in client_ids:\n",
    "            client = clients[client_id]\n",
    "\n",
    "            # local train\n",
    "            new_model, train_loss = client.local_train(global_round = global_round)\n",
    "            new_paras   .append(new_model.state_dict())\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            # local test before global aggregation\n",
    "            if local_split:\n",
    "                test_loss, test_accu = client.local_test (global_round = global_round, before_agg = True)\n",
    "                test_losses_before.append(test_loss)\n",
    "                test_accus_before .append(test_accu)\n",
    "\n",
    "        # global aggregation\n",
    "        new_paras.append(global_model.state_dict())\n",
    "        client_weights.append(len(train_dataset))\n",
    "        new_global_paras = average_paras(weights = client_weights, paras = new_paras)\n",
    "\n",
    "        # update global model\n",
    "        global_model.load_state_dict(new_global_paras)\n",
    "\n",
    "        # update local models\n",
    "        for client_id in client_ids:\n",
    "            clients[client_id].model.load_state_dict(new_global_paras)\n",
    "\n",
    "        # local test after global aggregation\n",
    "        if local_split:\n",
    "            print()\n",
    "            for client_id in client_ids:\n",
    "                client = clients[client_id]\n",
    "\n",
    "                test_loss, test_accu = client.local_test (global_round = global_round, before_agg = False)\n",
    "                test_losses_after.append(test_loss)\n",
    "                test_accus_after .append(test_accu)\n",
    "\n",
    "        # average local loss and accuracy\n",
    "        avg_train_loss = weighted_avg(weights = client_weights, values = train_losses) ; local_train_losses.append(avg_train_loss)\n",
    "        if local_split:    \n",
    "            avg_test_loss_before = weighted_avg(weights = client_weights, values = test_losses_before) ; local_test_losses_before.append(avg_test_loss_before)\n",
    "            avg_test_accu_before = weighted_avg(weights = client_weights, values = test_accus_before)  ; local_test_accus_before .append(avg_test_accu_before)\n",
    "            avg_test_loss_after  = weighted_avg(weights = client_weights, values = test_losses_after)  ; local_test_losses_after .append(avg_test_loss_after)\n",
    "            avg_test_accu_after  = weighted_avg(weights = client_weights, values = test_accus_after)   ; local_test_accus_after  .append(avg_test_accu_after)\n",
    "\n",
    "        # global test\n",
    "        global_model.to(device)\n",
    "        global_model.eval()\n",
    "        sum_batch_loss = 0\n",
    "        num_correct_preds = 0\n",
    "        for batch_id, (images, labels) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predicts = global_model(images)\n",
    "\n",
    "            loss = F.cross_entropy(predicts, labels, reduction = 'sum')\n",
    "            sum_batch_loss += loss.item()\n",
    "\n",
    "            _, pred_labels = torch.max(predicts, 1)\n",
    "            pred_labels = pred_labels.view(-1)\n",
    "            num_correct_preds += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "\n",
    "        avg_loss = sum_batch_loss / len(test_dataset)\n",
    "        global_test_losses.append(avg_loss)\n",
    "\n",
    "        avg_accu = num_correct_preds / len(test_dataset)\n",
    "        global_test_accus .append(avg_accu)\n",
    "\n",
    "        global_model.to('cpu')\n",
    "\n",
    "        # print per round\n",
    "        if global_round % print_round == 0:\n",
    "            print(\"global round: {:02d}\".format(global_round),  \" avg train loss:{:.4f}\".format(avg_train_loss), \" global test loss: {:.4f}\".format(avg_loss), \" global test accu: {:.4f}\".format(avg_accu))\n",
    "            if local_split:\n",
    "                print(\"    avg test loss before: {:.4f}\".format(avg_test_loss_before), \" avg test accu before: {:.3f}\".format(avg_test_accu_before), \" avg test loss after : {:.4f}\".format(avg_test_loss_after), \" avg test accu after : {:.3f}\".format(avg_test_accu_after),)\n",
    "            print(\"================================================================================================================\")\n",
    "            \n",
    "    # return \n",
    "    histories = {}\n",
    "    histories[\"local_train_losses\"] = local_train_losses\n",
    "    histories[\"global_test_losses\"] = global_test_losses\n",
    "    histories[\"global_test_accus\"]  = global_test_accus\n",
    "    if local_split:\n",
    "        histories[\"avg_test_loss_before\"] = avg_test_loss_before\n",
    "        histories[\"avg_test_accu_before\"] = avg_test_accu_before\n",
    "        histories[\"avg_test_loss_after\"]  = avg_test_loss_after\n",
    "        histories[\"avg_test_accu_after\"]  = avg_test_accu_after\n",
    "    return histories, clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2423903-667d-41d9-a857-e9918e7c63fa",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd69b186-1c7d-43ab-a41d-ce027a4e2cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec298e163a6d40cab3aee060f6d383c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ga92nam\\AppData\\Local\\Temp\\ipykernel_17828\\4185283577.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(image), torch.tensor(label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global round: 00  client: 18  local train loss: 2.1466\n",
      "global round: 00  client: 19  local train loss: 2.1441\n",
      "global round: 00  client: 06  local train loss: 2.1478\n",
      "global round: 00  client: 88  local train loss: 2.1685\n",
      "global round: 00  client: 68  local train loss: 2.1319\n",
      "global round: 00  client: 36  local train loss: 2.1378\n",
      "global round: 00  client: 52  local train loss: 2.1586\n",
      "global round: 00  client: 27  local train loss: 2.1315\n",
      "global round: 00  client: 15  local train loss: 2.1619\n",
      "global round: 00  client: 91  local train loss: 2.1434\n",
      "global round: 00  avg train loss:0.1952  global test loss: 2.2709  global test accu: 0.1295\n",
      "================================================================================================================\n",
      "global round: 01  client: 38  local train loss: 2.1581\n",
      "global round: 01  client: 30  local train loss: 2.1420\n",
      "global round: 01  client: 21  local train loss: 2.1542\n",
      "global round: 01  client: 17  local train loss: 2.1657\n",
      "global round: 01  client: 18  local train loss: 2.1137\n",
      "global round: 01  client: 75  local train loss: 2.1636\n",
      "global round: 01  client: 03  local train loss: 2.1481\n",
      "global round: 01  client: 87  local train loss: 2.1331\n",
      "global round: 01  client: 57  local train loss: 2.1525\n",
      "global round: 01  client: 05  local train loss: 2.1557\n",
      "global round: 01  avg train loss:0.1953  global test loss: 2.2495  global test accu: 0.1611\n",
      "================================================================================================================\n",
      "global round: 02  client: 13  local train loss: 2.1534\n",
      "global round: 02  client: 80  local train loss: 2.1527\n",
      "global round: 02  client: 18  local train loss: 2.0879\n",
      "global round: 02  client: 54  local train loss: 2.1472\n",
      "global round: 02  client: 35  local train loss: 2.1563\n",
      "global round: 02  client: 14  local train loss: 2.1486\n",
      "global round: 02  client: 41  local train loss: 2.1587\n",
      "global round: 02  client: 98  local train loss: 2.1518\n",
      "global round: 02  client: 40  local train loss: 2.1540\n",
      "global round: 02  client: 09  local train loss: 2.1405\n",
      "global round: 02  avg train loss:0.1950  global test loss: 2.2283  global test accu: 0.1956\n",
      "================================================================================================================\n",
      "global round: 03  client: 56  local train loss: 2.1520\n",
      "global round: 03  client: 53  local train loss: 2.1652\n",
      "global round: 03  client: 95  local train loss: 2.1367\n",
      "global round: 03  client: 45  local train loss: 2.1558\n",
      "global round: 03  client: 44  local train loss: 2.1559\n",
      "global round: 03  client: 05  local train loss: 2.0926\n",
      "global round: 03  client: 70  local train loss: 2.1397\n",
      "global round: 03  client: 16  local train loss: 2.1561\n",
      "global round: 03  client: 62  local train loss: 2.1293\n",
      "global round: 03  client: 72  local train loss: 2.1684\n",
      "global round: 03  avg train loss:0.1950  global test loss: 2.2082  global test accu: 0.2342\n",
      "================================================================================================================\n",
      "global round: 04  client: 35  local train loss: 2.0690\n",
      "global round: 04  client: 75  local train loss: 2.0987\n",
      "global round: 04  client: 23  local train loss: 2.1401\n",
      "global round: 04  client: 85  local train loss: 2.1481\n",
      "global round: 04  client: 58  local train loss: 2.1415\n",
      "global round: 04  client: 38  local train loss: 2.0920\n",
      "global round: 04  client: 31  local train loss: 2.1452\n",
      "global round: 04  client: 61  local train loss: 2.1622\n",
      "global round: 04  client: 62  local train loss: 2.0182\n",
      "global round: 04  client: 96  local train loss: 2.1501\n",
      "global round: 04  avg train loss:0.1924  global test loss: 2.1871  global test accu: 0.2800\n",
      "================================================================================================================\n",
      "global round: 05  client: 78  local train loss: 2.1650\n",
      "global round: 05  client: 97  local train loss: 2.1450\n",
      "global round: 05  client: 35  local train loss: 2.0330\n",
      "global round: 05  client: 23  local train loss: 2.0038\n",
      "global round: 05  client: 27  local train loss: 2.1054\n",
      "global round: 05  client: 21  local train loss: 2.0969\n",
      "global round: 05  client: 05  local train loss: 2.0530\n",
      "global round: 05  client: 51  local train loss: 2.1318\n",
      "global round: 05  client: 32  local train loss: 2.1576\n",
      "global round: 05  client: 50  local train loss: 2.1530\n",
      "global round: 05  avg train loss:0.1913  global test loss: 2.1663  global test accu: 0.3386\n",
      "================================================================================================================\n",
      "global round: 06  client: 64  local train loss: 2.1322\n",
      "global round: 06  client: 09  local train loss: 2.0608\n",
      "global round: 06  client: 60  local train loss: 2.1559\n",
      "global round: 06  client: 15  local train loss: 2.1339\n",
      "global round: 06  client: 23  local train loss: 2.0005\n",
      "global round: 06  client: 78  local train loss: 2.0133\n",
      "global round: 06  client: 17  local train loss: 2.1025\n",
      "global round: 06  client: 10  local train loss: 2.1329\n",
      "global round: 06  client: 26  local train loss: 2.1521\n",
      "global round: 06  client: 27  local train loss: 1.9736\n",
      "global round: 06  avg train loss:0.1896  global test loss: 2.1452  global test accu: 0.3962\n",
      "================================================================================================================\n",
      "global round: 07  client: 58  local train loss: 2.0058\n",
      "global round: 07  client: 50  local train loss: 1.9943\n",
      "global round: 07  client: 76  local train loss: 2.1536\n",
      "global round: 07  client: 69  local train loss: 2.1564\n",
      "global round: 07  client: 91  local train loss: 2.1133\n",
      "global round: 07  client: 53  local train loss: 2.0700\n",
      "global round: 07  client: 01  local train loss: 2.1597\n",
      "global round: 07  client: 38  local train loss: 2.0244\n",
      "global round: 07  client: 71  local train loss: 2.1646\n",
      "global round: 07  client: 36  local train loss: 2.1119\n",
      "global round: 07  avg train loss:0.1905  global test loss: 2.1261  global test accu: 0.4436\n",
      "================================================================================================================\n",
      "global round: 08  client: 59  local train loss: 2.1493\n",
      "global round: 08  client: 10  local train loss: 1.9546\n",
      "global round: 08  client: 85  local train loss: 2.0226\n",
      "global round: 08  client: 14  local train loss: 2.0608\n",
      "global round: 08  client: 82  local train loss: 2.1532\n",
      "global round: 08  client: 57  local train loss: 2.0902\n",
      "global round: 08  client: 23  local train loss: 1.9755\n",
      "global round: 08  client: 00  local train loss: 2.1470\n",
      "global round: 08  client: 21  local train loss: 2.0108\n",
      "global round: 08  client: 98  local train loss: 2.0684\n",
      "global round: 08  avg train loss:0.1876  global test loss: 2.1059  global test accu: 0.4816\n",
      "================================================================================================================\n",
      "global round: 09  client: 05  local train loss: 2.0130\n",
      "global round: 09  client: 81  local train loss: 2.1443\n",
      "global round: 09  client: 82  local train loss: 1.9408\n",
      "global round: 09  client: 21  local train loss: 1.9578\n",
      "global round: 09  client: 18  local train loss: 2.0661\n",
      "global round: 09  client: 00  local train loss: 1.9228\n",
      "global round: 09  client: 48  local train loss: 2.1476\n",
      "global round: 09  client: 96  local train loss: 2.0185\n",
      "global round: 09  client: 49  local train loss: 2.1511\n",
      "global round: 09  client: 62  local train loss: 2.0028\n",
      "global round: 09  avg train loss:0.1851  global test loss: 2.0851  global test accu: 0.5137\n",
      "================================================================================================================\n",
      "global round: 10  client: 50  local train loss: 1.9667\n",
      "global round: 10  client: 48  local train loss: 1.9136\n",
      "global round: 10  client: 16  local train loss: 2.0512\n",
      "global round: 10  client: 12  local train loss: 2.1549\n",
      "global round: 10  client: 05  local train loss: 1.9317\n",
      "global round: 10  client: 20  local train loss: 2.1632\n",
      "global round: 10  client: 58  local train loss: 1.9514\n",
      "global round: 10  client: 84  local train loss: 2.1450\n",
      "global round: 10  client: 30  local train loss: 2.0772\n",
      "global round: 10  client: 59  local train loss: 1.9361\n",
      "global round: 10  avg train loss:0.1845  global test loss: 2.0653  global test accu: 0.5385\n",
      "================================================================================================================\n",
      "global round: 11  client: 41  local train loss: 2.0704\n",
      "global round: 11  client: 70  local train loss: 2.0234\n",
      "global round: 11  client: 66  local train loss: 2.1568\n",
      "global round: 11  client: 25  local train loss: 2.1538\n",
      "global round: 11  client: 14  local train loss: 1.9360\n",
      "global round: 11  client: 55  local train loss: 2.1636\n",
      "global round: 11  client: 87  local train loss: 2.0721\n",
      "global round: 11  client: 48  local train loss: 1.9087\n",
      "global round: 11  client: 01  local train loss: 1.9698\n",
      "global round: 11  client: 46  local train loss: 2.1499\n",
      "global round: 11  avg train loss:0.1873  global test loss: 2.0500  global test accu: 0.5592\n",
      "================================================================================================================\n",
      "global round: 12  client: 29  local train loss: 2.1651\n",
      "global round: 12  client: 14  local train loss: 1.8866\n",
      "global round: 12  client: 90  local train loss: 2.1563\n",
      "global round: 12  client: 97  local train loss: 1.9854\n",
      "global round: 12  client: 27  local train loss: 1.9594\n",
      "global round: 12  client: 01  local train loss: 1.9112\n",
      "global round: 12  client: 18  local train loss: 1.9107\n",
      "global round: 12  client: 00  local train loss: 1.9181\n",
      "global round: 12  client: 38  local train loss: 1.9758\n",
      "global round: 12  client: 34  local train loss: 2.1531\n",
      "global round: 12  avg train loss:0.1820  global test loss: 2.0307  global test accu: 0.5829\n",
      "================================================================================================================\n",
      "global round: 13  client: 33  local train loss: 2.1493\n",
      "global round: 13  client: 42  local train loss: 2.1467\n",
      "global round: 13  client: 83  local train loss: 2.1584\n",
      "global round: 13  client: 15  local train loss: 1.9965\n",
      "global round: 13  client: 65  local train loss: 2.1699\n",
      "global round: 13  client: 66  local train loss: 1.8895\n",
      "global round: 13  client: 10  local train loss: 1.9309\n",
      "global round: 13  client: 05  local train loss: 1.9156\n",
      "global round: 13  client: 18  local train loss: 1.8661\n",
      "global round: 13  client: 04  local train loss: 2.1566\n",
      "global round: 13  avg train loss:0.1853  global test loss: 2.0165  global test accu: 0.5957\n",
      "================================================================================================================\n",
      "global round: 14  client: 90  local train loss: 1.8716\n",
      "global round: 14  client: 54  local train loss: 2.0590\n",
      "global round: 14  client: 86  local train loss: 2.1501\n",
      "global round: 14  client: 99  local train loss: 2.1507\n",
      "global round: 14  client: 15  local train loss: 1.8781\n",
      "global round: 14  client: 28  local train loss: 2.1544\n",
      "global round: 14  client: 58  local train loss: 1.8956\n",
      "global round: 14  client: 80  local train loss: 2.0783\n",
      "global round: 14  client: 11  local train loss: 2.1336\n",
      "global round: 14  client: 72  local train loss: 2.0581\n",
      "global round: 14  avg train loss:0.1857  global test loss: 2.0038  global test accu: 0.6058\n",
      "================================================================================================================\n",
      "global round: 15  client: 58  local train loss: 1.8485\n",
      "global round: 15  client: 47  local train loss: 2.1519\n",
      "global round: 15  client: 98  local train loss: 1.9401\n",
      "global round: 15  client: 62  local train loss: 1.9028\n",
      "global round: 15  client: 45  local train loss: 2.0449\n",
      "global round: 15  client: 94  local train loss: 2.1607\n",
      "global round: 15  client: 91  local train loss: 1.9399\n",
      "global round: 15  client: 11  local train loss: 1.8158\n",
      "global round: 15  client: 34  local train loss: 1.8721\n",
      "global round: 15  client: 05  local train loss: 1.8804\n",
      "global round: 15  avg train loss:0.1778  global test loss: 1.9842  global test accu: 0.6208\n",
      "================================================================================================================\n",
      "global round: 16  client: 13  local train loss: 2.0772\n",
      "global round: 16  client: 43  local train loss: 2.1455\n",
      "global round: 16  client: 18  local train loss: 1.8575\n",
      "global round: 16  client: 93  local train loss: 2.1443\n",
      "global round: 16  client: 85  local train loss: 1.9443\n",
      "global round: 16  client: 50  local train loss: 1.9129\n",
      "global round: 16  client: 19  local train loss: 2.1144\n",
      "global round: 16  client: 48  local train loss: 1.8968\n",
      "global round: 16  client: 95  local train loss: 2.0267\n",
      "global round: 16  client: 24  local train loss: 2.1396\n",
      "global round: 16  avg train loss:0.1842  global test loss: 1.9733  global test accu: 0.6271\n",
      "================================================================================================================\n",
      "global round: 17  client: 62  local train loss: 1.8094\n",
      "global round: 17  client: 10  local train loss: 1.8437\n",
      "global round: 17  client: 25  local train loss: 1.8823\n",
      "global round: 17  client: 69  local train loss: 1.9461\n",
      "global round: 17  client: 80  local train loss: 1.8521\n",
      "global round: 17  client: 82  local train loss: 1.9353\n",
      "global round: 17  client: 09  local train loss: 1.9668\n",
      "global round: 17  client: 15  local train loss: 1.8733\n",
      "global round: 17  client: 56  local train loss: 2.0465\n",
      "global round: 17  client: 81  local train loss: 1.9079\n",
      "global round: 17  avg train loss:0.1733  global test loss: 1.9511  global test accu: 0.6426\n",
      "================================================================================================================\n",
      "global round: 18  client: 48  local train loss: 1.8414\n",
      "global round: 18  client: 65  local train loss: 1.8706\n",
      "global round: 18  client: 91  local train loss: 1.8135\n",
      "global round: 18  client: 41  local train loss: 1.8972\n",
      "global round: 18  client: 86  local train loss: 1.8389\n",
      "global round: 18  client: 62  local train loss: 1.7710\n",
      "global round: 18  client: 15  local train loss: 1.8252\n",
      "global round: 18  client: 84  local train loss: 1.8828\n",
      "global round: 18  client: 88  local train loss: 2.1347\n",
      "global round: 18  client: 56  local train loss: 1.7993\n",
      "global round: 18  avg train loss:0.1698  global test loss: 1.9273  global test accu: 0.6568\n",
      "================================================================================================================\n",
      "global round: 19  client: 05  local train loss: 1.8535\n",
      "global round: 19  client: 50  local train loss: 1.8436\n",
      "global round: 19  client: 98  local train loss: 1.8249\n",
      "global round: 19  client: 27  local train loss: 1.8538\n",
      "global round: 19  client: 47  local train loss: 1.8267\n",
      "global round: 19  client: 73  local train loss: 2.1386\n",
      "global round: 19  client: 53  local train loss: 1.9907\n",
      "global round: 19  client: 21  local train loss: 1.9405\n",
      "global round: 19  client: 35  local train loss: 2.0134\n",
      "global round: 19  client: 61  local train loss: 2.0328\n",
      "global round: 19  avg train loss:0.1756  global test loss: 1.9115  global test accu: 0.6642\n",
      "================================================================================================================\n",
      "global round: 20  client: 06  local train loss: 2.1215\n",
      "global round: 20  client: 24  local train loss: 1.8038\n",
      "global round: 20  client: 91  local train loss: 1.7802\n",
      "global round: 20  client: 30  local train loss: 1.8778\n",
      "global round: 20  client: 01  local train loss: 1.8888\n",
      "global round: 20  client: 33  local train loss: 1.8532\n",
      "global round: 20  client: 68  local train loss: 2.1060\n",
      "global round: 20  client: 29  local train loss: 1.8797\n",
      "global round: 20  client: 66  local train loss: 1.8754\n",
      "global round: 20  client: 39  local train loss: 2.1424\n",
      "global round: 20  avg train loss:0.1757  global test loss: 1.8978  global test accu: 0.6711\n",
      "================================================================================================================\n",
      "global round: 21  client: 01  local train loss: 1.7780\n",
      "global round: 21  client: 05  local train loss: 1.7870\n",
      "global round: 21  client: 70  local train loss: 1.8659\n",
      "global round: 21  client: 04  local train loss: 1.8578\n",
      "global round: 21  client: 96  local train loss: 1.9173\n",
      "global round: 21  client: 10  local train loss: 1.7905\n",
      "global round: 21  client: 97  local train loss: 1.8620\n",
      "global round: 21  client: 55  local train loss: 1.8952\n",
      "global round: 21  client: 54  local train loss: 1.8515\n",
      "global round: 21  client: 87  local train loss: 1.8678\n",
      "global round: 21  avg train loss:0.1679  global test loss: 1.8770  global test accu: 0.6786\n",
      "================================================================================================================\n",
      "global round: 22  client: 38  local train loss: 1.8793\n",
      "global round: 22  client: 32  local train loss: 1.9957\n",
      "global round: 22  client: 95  local train loss: 1.8055\n",
      "global round: 22  client: 97  local train loss: 1.7352\n",
      "global round: 22  client: 49  local train loss: 1.9227\n",
      "global round: 22  client: 98  local train loss: 1.7712\n",
      "global round: 22  client: 74  local train loss: 2.1506\n",
      "global round: 22  client: 31  local train loss: 2.0207\n",
      "global round: 22  client: 94  local train loss: 1.8373\n",
      "global round: 22  client: 28  local train loss: 1.8460\n",
      "global round: 22  avg train loss:0.1724  global test loss: 1.8625  global test accu: 0.6870\n",
      "================================================================================================================\n",
      "global round: 23  client: 96  local train loss: 1.7391\n",
      "global round: 23  client: 66  local train loss: 1.7764\n",
      "global round: 23  client: 43  local train loss: 1.8038\n",
      "global round: 23  client: 02  local train loss: 2.1451\n",
      "global round: 23  client: 88  local train loss: 1.7874\n",
      "global round: 23  client: 33  local train loss: 1.7598\n",
      "global round: 23  client: 78  local train loss: 2.0023\n",
      "global round: 23  client: 56  local train loss: 1.7973\n",
      "global round: 23  client: 53  local train loss: 1.7948\n",
      "global round: 23  client: 16  local train loss: 1.9082\n",
      "global round: 23  avg train loss:0.1683  global test loss: 1.8447  global test accu: 0.6952\n",
      "================================================================================================================\n",
      "global round: 24  client: 33  local train loss: 1.7197\n",
      "global round: 24  client: 70  local train loss: 1.7206\n",
      "global round: 24  client: 72  local train loss: 1.8663\n",
      "global round: 24  client: 41  local train loss: 1.8037\n",
      "global round: 24  client: 73  local train loss: 1.7390\n",
      "global round: 24  client: 50  local train loss: 1.7870\n",
      "global round: 24  client: 42  local train loss: 1.8487\n",
      "global round: 24  client: 03  local train loss: 2.0936\n",
      "global round: 24  client: 18  local train loss: 1.8159\n",
      "global round: 24  client: 59  local train loss: 1.9132\n",
      "global round: 24  avg train loss:0.1664  global test loss: 1.8272  global test accu: 0.7029\n",
      "================================================================================================================\n",
      "global round: 25  client: 17  local train loss: 1.9927\n",
      "global round: 25  client: 25  local train loss: 1.8057\n",
      "global round: 25  client: 46  local train loss: 1.8701\n",
      "global round: 25  client: 07  local train loss: 2.1631\n",
      "global round: 25  client: 33  local train loss: 1.7018\n",
      "global round: 25  client: 80  local train loss: 1.8195\n",
      "global round: 25  client: 72  local train loss: 1.7162\n",
      "global round: 25  client: 50  local train loss: 1.7245\n",
      "global round: 25  client: 89  local train loss: 2.1318\n",
      "global round: 25  client: 75  local train loss: 2.0362\n",
      "global round: 25  avg train loss:0.1724  global test loss: 1.8172  global test accu: 0.7070\n",
      "================================================================================================================\n",
      "global round: 26  client: 27  local train loss: 1.7529\n",
      "global round: 26  client: 89  local train loss: 1.6505\n",
      "global round: 26  client: 79  local train loss: 2.1483\n",
      "global round: 26  client: 64  local train loss: 1.9595\n",
      "global round: 26  client: 47  local train loss: 1.7799\n",
      "global round: 26  client: 58  local train loss: 1.8284\n",
      "global round: 26  client: 53  local train loss: 1.7480\n",
      "global round: 26  client: 82  local train loss: 1.8251\n",
      "global round: 26  client: 15  local train loss: 1.8116\n",
      "global round: 26  client: 92  local train loss: 2.1559\n",
      "global round: 26  avg train loss:0.1696  global test loss: 1.8060  global test accu: 0.7107\n",
      "================================================================================================================\n",
      "global round: 27  client: 82  local train loss: 1.7003\n",
      "global round: 27  client: 86  local train loss: 1.7868\n",
      "global round: 27  client: 51  local train loss: 1.9846\n",
      "global round: 27  client: 27  local train loss: 1.6659\n",
      "global round: 27  client: 98  local train loss: 1.7316\n",
      "global round: 27  client: 11  local train loss: 1.8202\n",
      "global round: 27  client: 32  local train loss: 1.7317\n",
      "global round: 27  client: 30  local train loss: 1.7360\n",
      "global round: 27  client: 63  local train loss: 2.1494\n",
      "global round: 27  client: 97  local train loss: 1.7251\n",
      "global round: 27  avg train loss:0.1639  global test loss: 1.7904  global test accu: 0.7156\n",
      "================================================================================================================\n",
      "global round: 28  client: 56  local train loss: 1.7248\n",
      "global round: 28  client: 99  local train loss: 1.8287\n",
      "global round: 28  client: 29  local train loss: 1.7848\n",
      "global round: 28  client: 95  local train loss: 1.7172\n",
      "global round: 28  client: 68  local train loss: 1.7149\n",
      "global round: 28  client: 31  local train loss: 1.7332\n",
      "global round: 28  client: 28  local train loss: 1.7342\n",
      "global round: 28  client: 90  local train loss: 1.8608\n",
      "global round: 28  client: 78  local train loss: 1.7283\n",
      "global round: 28  client: 36  local train loss: 1.9379\n",
      "global round: 28  avg train loss:0.1615  global test loss: 1.7724  global test accu: 0.7200\n",
      "================================================================================================================\n",
      "global round: 29  client: 33  local train loss: 1.6972\n",
      "global round: 29  client: 37  local train loss: 2.1599\n",
      "global round: 29  client: 27  local train loss: 1.6582\n",
      "global round: 29  client: 87  local train loss: 1.7238\n",
      "global round: 29  client: 19  local train loss: 1.8061\n",
      "global round: 29  client: 23  local train loss: 1.9380\n",
      "global round: 29  client: 98  local train loss: 1.6714\n",
      "global round: 29  client: 24  local train loss: 1.7468\n",
      "global round: 29  client: 50  local train loss: 1.7074\n",
      "global round: 29  client: 90  local train loss: 1.6702\n",
      "global round: 29  avg train loss:0.1616  global test loss: 1.7573  global test accu: 0.7231\n",
      "================================================================================================================\n",
      "global round: 30  client: 44  local train loss: 2.0511\n",
      "global round: 30  client: 80  local train loss: 1.7035\n",
      "global round: 30  client: 41  local train loss: 1.7194\n",
      "global round: 30  client: 66  local train loss: 1.7292\n",
      "global round: 30  client: 04  local train loss: 1.7455\n",
      "global round: 30  client: 27  local train loss: 1.6264\n",
      "global round: 30  client: 58  local train loss: 1.6737\n",
      "global round: 30  client: 92  local train loss: 1.6864\n",
      "global round: 30  client: 26  local train loss: 1.9730\n",
      "global round: 30  client: 46  local train loss: 1.6842\n",
      "global round: 30  avg train loss:0.1599  global test loss: 1.7410  global test accu: 0.7286\n",
      "================================================================================================================\n",
      "global round: 31  client: 06  local train loss: 1.7498\n",
      "global round: 31  client: 99  local train loss: 1.6484\n",
      "global round: 31  client: 08  local train loss: 2.1659\n",
      "global round: 31  client: 83  local train loss: 1.8605\n",
      "global round: 31  client: 68  local train loss: 1.6183\n",
      "global round: 31  client: 91  local train loss: 1.7539\n",
      "global round: 31  client: 16  local train loss: 1.7274\n",
      "global round: 31  client: 52  local train loss: 2.1232\n",
      "global round: 31  client: 81  local train loss: 1.8005\n",
      "global round: 31  client: 79  local train loss: 1.6671\n",
      "global round: 31  avg train loss:0.1647  global test loss: 1.7314  global test accu: 0.7316\n",
      "================================================================================================================\n",
      "global round: 32  client: 30  local train loss: 1.6455\n",
      "global round: 32  client: 94  local train loss: 1.7401\n",
      "global round: 32  client: 42  local train loss: 1.6827\n",
      "global round: 32  client: 75  local train loss: 1.6997\n",
      "global round: 32  client: 13  local train loss: 1.8262\n",
      "global round: 32  client: 55  local train loss: 1.7525\n",
      "global round: 32  client: 92  local train loss: 1.6416\n",
      "global round: 32  client: 70  local train loss: 1.6725\n",
      "global round: 32  client: 16  local train loss: 1.6388\n",
      "global round: 32  client: 44  local train loss: 1.6417\n",
      "global round: 32  avg train loss:0.1540  global test loss: 1.7111  global test accu: 0.7358\n",
      "================================================================================================================\n",
      "global round: 33  client: 54  local train loss: 1.7482\n",
      "global round: 33  client: 23  local train loss: 1.6247\n",
      "global round: 33  client: 01  local train loss: 1.7629\n",
      "global round: 33  client: 11  local train loss: 1.6489\n",
      "global round: 33  client: 66  local train loss: 1.6466\n",
      "global round: 33  client: 29  local train loss: 1.6888\n",
      "global round: 33  client: 55  local train loss: 1.6158\n",
      "global round: 33  client: 02  local train loss: 1.6947\n",
      "global round: 33  client: 93  local train loss: 1.8031\n",
      "global round: 33  client: 06  local train loss: 1.6221\n",
      "global round: 33  avg train loss:0.1532  global test loss: 1.6921  global test accu: 0.7401\n",
      "================================================================================================================\n",
      "global round: 34  client: 52  local train loss: 1.6040\n",
      "global round: 34  client: 28  local train loss: 1.6646\n",
      "global round: 34  client: 67  local train loss: 2.1371\n",
      "global round: 34  client: 59  local train loss: 1.7066\n",
      "global round: 34  client: 12  local train loss: 1.8947\n",
      "global round: 34  client: 49  local train loss: 1.7423\n",
      "global round: 34  client: 78  local train loss: 1.6798\n",
      "global round: 34  client: 43  local train loss: 1.6994\n",
      "global round: 34  client: 99  local train loss: 1.6108\n",
      "global round: 34  client: 53  local train loss: 1.7220\n",
      "global round: 34  avg train loss:0.1587  global test loss: 1.6804  global test accu: 0.7438\n",
      "================================================================================================================\n",
      "global round: 35  client: 11  local train loss: 1.5716\n",
      "global round: 35  client: 35  local train loss: 1.7851\n",
      "global round: 35  client: 86  local train loss: 1.6680\n",
      "global round: 35  client: 66  local train loss: 1.5974\n",
      "global round: 35  client: 01  local train loss: 1.6129\n",
      "global round: 35  client: 51  local train loss: 1.6566\n",
      "global round: 35  client: 84  local train loss: 1.7647\n",
      "global round: 35  client: 61  local train loss: 1.7781\n",
      "global round: 35  client: 53  local train loss: 1.6110\n",
      "global round: 35  client: 20  local train loss: 1.9205\n",
      "global round: 35  avg train loss:0.1542  global test loss: 1.6650  global test accu: 0.7478\n",
      "================================================================================================================\n",
      "global round: 36  client: 24  local train loss: 1.6296\n",
      "global round: 36  client: 46  local train loss: 1.6267\n",
      "global round: 36  client: 92  local train loss: 1.6223\n",
      "global round: 36  client: 72  local train loss: 1.7183\n",
      "global round: 36  client: 31  local train loss: 1.6638\n",
      "global round: 36  client: 58  local train loss: 1.6178\n",
      "global round: 36  client: 19  local train loss: 1.6256\n",
      "global round: 36  client: 11  local train loss: 1.5563\n",
      "global round: 36  client: 95  local train loss: 1.6446\n",
      "global round: 36  client: 84  local train loss: 1.5385\n",
      "global round: 36  avg train loss:0.1477  global test loss: 1.6456  global test accu: 0.7506\n",
      "================================================================================================================\n",
      "global round: 37  client: 70  local train loss: 1.5822\n",
      "global round: 37  client: 61  local train loss: 1.5864\n",
      "global round: 37  client: 92  local train loss: 1.5647\n",
      "global round: 37  client: 30  local train loss: 1.5830\n",
      "global round: 37  client: 08  local train loss: 1.6293\n",
      "global round: 37  client: 87  local train loss: 1.6250\n",
      "global round: 37  client: 46  local train loss: 1.5473\n",
      "global round: 37  client: 28  local train loss: 1.5976\n",
      "global round: 37  client: 59  local train loss: 1.5820\n",
      "global round: 37  client: 11  local train loss: 1.5375\n",
      "global round: 37  avg train loss:0.1440  global test loss: 1.6236  global test accu: 0.7547\n",
      "================================================================================================================\n",
      "global round: 38  client: 74  local train loss: 1.7107\n",
      "global round: 38  client: 60  local train loss: 1.9871\n",
      "global round: 38  client: 82  local train loss: 1.6956\n",
      "global round: 38  client: 29  local train loss: 1.6189\n",
      "global round: 38  client: 73  local train loss: 1.6796\n",
      "global round: 38  client: 55  local train loss: 1.6079\n",
      "global round: 38  client: 27  local train loss: 1.6100\n",
      "global round: 38  client: 15  local train loss: 1.6985\n",
      "global round: 38  client: 30  local train loss: 1.5193\n",
      "global round: 38  client: 64  local train loss: 1.6671\n",
      "global round: 38  avg train loss:0.1527  global test loss: 1.6124  global test accu: 0.7568\n",
      "================================================================================================================\n",
      "global round: 39  client: 53  local train loss: 1.6020\n",
      "global round: 39  client: 25  local train loss: 1.6999\n",
      "global round: 39  client: 83  local train loss: 1.6285\n",
      "global round: 39  client: 19  local train loss: 1.5418\n",
      "global round: 39  client: 85  local train loss: 1.8298\n",
      "global round: 39  client: 91  local train loss: 1.6147\n",
      "global round: 39  client: 71  local train loss: 1.9633\n",
      "global round: 39  client: 20  local train loss: 1.5941\n",
      "global round: 39  client: 32  local train loss: 1.6676\n",
      "global round: 39  client: 10  local train loss: 1.7318\n",
      "global round: 39  avg train loss:0.1534  global test loss: 1.6024  global test accu: 0.7592\n",
      "================================================================================================================\n",
      "global round: 40  client: 83  local train loss: 1.5352\n",
      "global round: 40  client: 46  local train loss: 1.5337\n",
      "global round: 40  client: 21  local train loss: 1.7909\n",
      "global round: 40  client: 00  local train loss: 1.8685\n",
      "global round: 40  client: 73  local train loss: 1.5075\n",
      "global round: 40  client: 95  local train loss: 1.5431\n",
      "global round: 40  client: 68  local train loss: 1.5846\n",
      "global round: 40  client: 03  local train loss: 1.6777\n",
      "global round: 40  client: 36  local train loss: 1.6242\n",
      "global round: 40  client: 48  local train loss: 1.7958\n",
      "global round: 40  avg train loss:0.1496  global test loss: 1.5907  global test accu: 0.7590\n",
      "================================================================================================================\n",
      "global round: 41  client: 69  local train loss: 1.7995\n",
      "global round: 41  client: 38  local train loss: 1.7358\n",
      "global round: 41  client: 06  local train loss: 1.5974\n",
      "global round: 41  client: 47  local train loss: 1.6948\n",
      "global round: 41  client: 46  local train loss: 1.4996\n",
      "global round: 41  client: 59  local train loss: 1.5434\n",
      "global round: 41  client: 00  local train loss: 1.4843\n",
      "global round: 41  client: 72  local train loss: 1.5770\n",
      "global round: 41  client: 21  local train loss: 1.5292\n",
      "global round: 41  client: 94  local train loss: 1.6180\n",
      "global round: 41  avg train loss:0.1462  global test loss: 1.5755  global test accu: 0.7619\n",
      "================================================================================================================\n",
      "global round: 42  client: 63  local train loss: 1.6766\n",
      "global round: 42  client: 08  local train loss: 1.5618\n",
      "global round: 42  client: 98  local train loss: 1.6445\n",
      "global round: 42  client: 45  local train loss: 1.8309\n",
      "global round: 42  client: 85  local train loss: 1.5236\n",
      "global round: 42  client: 22  local train loss: 2.1265\n",
      "global round: 42  client: 11  local train loss: 1.5187\n",
      "global round: 42  client: 33  local train loss: 1.6434\n",
      "global round: 42  client: 37  local train loss: 1.6408\n",
      "global round: 42  client: 28  local train loss: 1.5472\n",
      "global round: 42  avg train loss:0.1519  global test loss: 1.5677  global test accu: 0.7634\n",
      "================================================================================================================\n",
      "global round: 43  client: 09  local train loss: 1.7989\n",
      "global round: 43  client: 05  local train loss: 1.7608\n",
      "global round: 43  client: 19  local train loss: 1.5090\n",
      "global round: 43  client: 06  local train loss: 1.4973\n",
      "global round: 43  client: 84  local train loss: 1.5309\n",
      "global round: 43  client: 18  local train loss: 1.6954\n",
      "global round: 43  client: 47  local train loss: 1.5172\n",
      "global round: 43  client: 36  local train loss: 1.4846\n",
      "global round: 43  client: 94  local train loss: 1.5111\n",
      "global round: 43  client: 12  local train loss: 1.5873\n",
      "global round: 43  avg train loss:0.1445  global test loss: 1.5533  global test accu: 0.7651\n",
      "================================================================================================================\n",
      "global round: 44  client: 60  local train loss: 1.5328\n",
      "global round: 44  client: 68  local train loss: 1.4723\n",
      "global round: 44  client: 86  local train loss: 1.5697\n",
      "global round: 44  client: 19  local train loss: 1.4734\n",
      "global round: 44  client: 72  local train loss: 1.5295\n",
      "global round: 44  client: 73  local train loss: 1.4921\n",
      "global round: 44  client: 87  local train loss: 1.5265\n",
      "global round: 44  client: 83  local train loss: 1.5199\n",
      "global round: 44  client: 67  local train loss: 1.5521\n",
      "global round: 44  client: 33  local train loss: 1.4871\n",
      "global round: 44  avg train loss:0.1378  global test loss: 1.5336  global test accu: 0.7681\n",
      "================================================================================================================\n",
      "global round: 45  client: 21  local train loss: 1.5157\n",
      "global round: 45  client: 95  local train loss: 1.4989\n",
      "global round: 45  client: 03  local train loss: 1.5030\n",
      "global round: 45  client: 91  local train loss: 1.5149\n",
      "global round: 45  client: 40  local train loss: 2.0638\n",
      "global round: 45  client: 30  local train loss: 1.5006\n",
      "global round: 45  client: 63  local train loss: 1.5065\n",
      "global round: 45  client: 77  local train loss: 2.1550\n",
      "global round: 45  client: 55  local train loss: 1.5478\n",
      "global round: 45  client: 97  local train loss: 1.6625\n",
      "global round: 45  avg train loss:0.1497  global test loss: 1.5279  global test accu: 0.7687\n",
      "================================================================================================================\n",
      "global round: 46  client: 17  local train loss: 1.7070\n",
      "global round: 46  client: 32  local train loss: 1.5194\n",
      "global round: 46  client: 42  local train loss: 1.5955\n",
      "global round: 46  client: 22  local train loss: 1.4618\n",
      "global round: 46  client: 47  local train loss: 1.5006\n",
      "global round: 46  client: 07  local train loss: 1.6842\n",
      "global round: 46  client: 00  local train loss: 1.4742\n",
      "global round: 46  client: 56  local train loss: 1.6689\n",
      "global round: 46  client: 27  local train loss: 1.5043\n",
      "global round: 46  client: 77  local train loss: 1.4605\n",
      "global round: 46  avg train loss:0.1416  global test loss: 1.5141  global test accu: 0.7702\n",
      "================================================================================================================\n",
      "global round: 47  client: 06  local train loss: 1.4853\n",
      "global round: 47  client: 70  local train loss: 1.5068\n",
      "global round: 47  client: 80  local train loss: 1.6441\n",
      "global round: 47  client: 31  local train loss: 1.5673\n",
      "global round: 47  client: 75  local train loss: 1.6137\n",
      "global round: 47  client: 66  local train loss: 1.5845\n",
      "global round: 47  client: 72  local train loss: 1.4973\n",
      "global round: 47  client: 90  local train loss: 1.6672\n",
      "global round: 47  client: 33  local train loss: 1.4598\n",
      "global round: 47  client: 97  local train loss: 1.4465\n",
      "global round: 47  avg train loss:0.1407  global test loss: 1.5007  global test accu: 0.7716\n",
      "================================================================================================================\n",
      "global round: 48  client: 62  local train loss: 1.7576\n",
      "global round: 48  client: 55  local train loss: 1.4722\n",
      "global round: 48  client: 69  local train loss: 1.4905\n",
      "global round: 48  client: 93  local train loss: 1.5885\n",
      "global round: 48  client: 03  local train loss: 1.4485\n",
      "global round: 48  client: 83  local train loss: 1.4840\n",
      "global round: 48  client: 32  local train loss: 1.4457\n",
      "global round: 48  client: 54  local train loss: 1.6098\n",
      "global round: 48  client: 80  local train loss: 1.4595\n",
      "global round: 48  client: 27  local train loss: 1.4383\n",
      "global round: 48  avg train loss:0.1381  global test loss: 1.4860  global test accu: 0.7739\n",
      "================================================================================================================\n",
      "global round: 49  client: 33  local train loss: 1.4395\n",
      "global round: 49  client: 16  local train loss: 1.6184\n",
      "global round: 49  client: 46  local train loss: 1.4849\n",
      "global round: 49  client: 70  local train loss: 1.4058\n",
      "global round: 49  client: 87  local train loss: 1.4583\n",
      "global round: 49  client: 66  local train loss: 1.4565\n",
      "global round: 49  client: 36  local train loss: 1.4560\n",
      "global round: 49  client: 60  local train loss: 1.4845\n",
      "global round: 49  client: 41  local train loss: 1.6520\n",
      "global round: 49  client: 48  local train loss: 1.5307\n",
      "global round: 49  avg train loss:0.1362  global test loss: 1.4712  global test accu: 0.7751\n",
      "================================================================================================================\n",
      "global round: 50  client: 58  local train loss: 1.5459\n",
      "global round: 50  client: 77  local train loss: 1.4713\n",
      "global round: 50  client: 88  local train loss: 1.7305\n",
      "global round: 50  client: 03  local train loss: 1.4197\n",
      "global round: 50  client: 20  local train loss: 1.5467\n",
      "global round: 50  client: 01  local train loss: 1.5933\n",
      "global round: 50  client: 71  local train loss: 1.5105\n",
      "global round: 50  client: 45  local train loss: 1.4950\n",
      "global round: 50  client: 81  local train loss: 1.6049\n",
      "global round: 50  client: 79  local train loss: 1.6177\n",
      "global round: 50  avg train loss:0.1412  global test loss: 1.4617  global test accu: 0.7762\n",
      "================================================================================================================\n",
      "global round: 51  client: 09  local train loss: 1.4579\n",
      "global round: 51  client: 49  local train loss: 1.5851\n",
      "global round: 51  client: 77  local train loss: 1.4373\n",
      "global round: 51  client: 30  local train loss: 1.4438\n",
      "global round: 51  client: 41  local train loss: 1.4418\n",
      "global round: 51  client: 51  local train loss: 1.5608\n",
      "global round: 51  client: 15  local train loss: 1.5429\n",
      "global round: 51  client: 87  local train loss: 1.4082\n",
      "global round: 51  client: 93  local train loss: 1.4249\n",
      "global round: 51  client: 11  local train loss: 1.4752\n",
      "global round: 51  avg train loss:0.1343  global test loss: 1.4470  global test accu: 0.7782\n",
      "================================================================================================================\n",
      "global round: 52  client: 46  local train loss: 1.4092\n",
      "global round: 52  client: 07  local train loss: 1.4440\n",
      "global round: 52  client: 76  local train loss: 1.9588\n",
      "global round: 52  client: 03  local train loss: 1.4040\n",
      "global round: 52  client: 98  local train loss: 1.4900\n",
      "global round: 52  client: 33  local train loss: 1.4111\n",
      "global round: 52  client: 81  local train loss: 1.3898\n",
      "global round: 52  client: 65  local train loss: 1.8130\n",
      "global round: 52  client: 80  local train loss: 1.4460\n",
      "global round: 52  client: 86  local train loss: 1.4673\n",
      "global round: 52  avg train loss:0.1385  global test loss: 1.4374  global test accu: 0.7792\n",
      "================================================================================================================\n",
      "global round: 53  client: 14  local train loss: 1.8725\n",
      "global round: 53  client: 65  local train loss: 1.4324\n",
      "global round: 53  client: 81  local train loss: 1.3780\n",
      "global round: 53  client: 83  local train loss: 1.4473\n",
      "global round: 53  client: 79  local train loss: 1.4054\n",
      "global round: 53  client: 22  local train loss: 1.4272\n",
      "global round: 53  client: 17  local train loss: 1.4711\n",
      "global round: 53  client: 96  local train loss: 1.7201\n",
      "global round: 53  client: 28  local train loss: 1.5066\n",
      "global round: 53  client: 49  local train loss: 1.4155\n",
      "global round: 53  avg train loss:0.1371  global test loss: 1.4266  global test accu: 0.7809\n",
      "================================================================================================================\n",
      "global round: 54  client: 06  local train loss: 1.4510\n",
      "global round: 54  client: 45  local train loss: 1.4190\n",
      "global round: 54  client: 59  local train loss: 1.5055\n",
      "global round: 54  client: 16  local train loss: 1.4311\n",
      "global round: 54  client: 61  local train loss: 1.5531\n",
      "global round: 54  client: 37  local train loss: 1.4922\n",
      "global round: 54  client: 86  local train loss: 1.4002\n",
      "global round: 54  client: 93  local train loss: 1.3957\n",
      "global round: 54  client: 32  local train loss: 1.4306\n",
      "global round: 54  client: 48  local train loss: 1.4402\n",
      "global round: 54  avg train loss:0.1320  global test loss: 1.4119  global test accu: 0.7836\n",
      "================================================================================================================\n",
      "global round: 55  client: 93  local train loss: 1.3693\n",
      "global round: 55  client: 13  local train loss: 1.6209\n",
      "global round: 55  client: 04  local train loss: 1.6409\n",
      "global round: 55  client: 53  local train loss: 1.5557\n",
      "global round: 55  client: 26  local train loss: 1.6129\n",
      "global round: 55  client: 64  local train loss: 1.5254\n",
      "global round: 55  client: 73  local train loss: 1.4469\n",
      "global round: 55  client: 35  local train loss: 1.5849\n",
      "global round: 55  client: 30  local train loss: 1.3787\n",
      "global round: 55  client: 78  local train loss: 1.6053\n",
      "global round: 55  avg train loss:0.1395  global test loss: 1.4064  global test accu: 0.7845\n",
      "================================================================================================================\n",
      "global round: 56  client: 87  local train loss: 1.3902\n",
      "global round: 56  client: 20  local train loss: 1.4512\n",
      "global round: 56  client: 64  local train loss: 1.3696\n",
      "global round: 56  client: 14  local train loss: 1.3552\n",
      "global round: 56  client: 74  local train loss: 1.5113\n",
      "global round: 56  client: 73  local train loss: 1.3348\n",
      "global round: 56  client: 63  local train loss: 1.4838\n",
      "global round: 56  client: 00  local train loss: 1.4277\n",
      "global round: 56  client: 45  local train loss: 1.3785\n",
      "global round: 56  client: 54  local train loss: 1.4497\n",
      "global round: 56  avg train loss:0.1287  global test loss: 1.3908  global test accu: 0.7866\n",
      "================================================================================================================\n",
      "global round: 57  client: 20  local train loss: 1.3967\n",
      "global round: 57  client: 37  local train loss: 1.3744\n",
      "global round: 57  client: 27  local train loss: 1.4065\n",
      "global round: 57  client: 78  local train loss: 1.3808\n",
      "global round: 57  client: 83  local train loss: 1.3986\n",
      "global round: 57  client: 59  local train loss: 1.3746\n",
      "global round: 57  client: 28  local train loss: 1.3951\n",
      "global round: 57  client: 94  local train loss: 1.4955\n",
      "global round: 57  client: 42  local train loss: 1.4264\n",
      "global round: 57  client: 95  local train loss: 1.4518\n",
      "global round: 57  avg train loss:0.1282  global test loss: 1.3758  global test accu: 0.7880\n",
      "================================================================================================================\n",
      "global round: 58  client: 29  local train loss: 1.5541\n",
      "global round: 58  client: 85  local train loss: 1.4941\n",
      "global round: 58  client: 55  local train loss: 1.4531\n",
      "global round: 58  client: 62  local train loss: 1.3966\n",
      "global round: 58  client: 50  local train loss: 1.6569\n",
      "global round: 58  client: 69  local train loss: 1.4174\n",
      "global round: 58  client: 16  local train loss: 1.3815\n",
      "global round: 58  client: 84  local train loss: 1.4547\n",
      "global round: 58  client: 64  local train loss: 1.3527\n",
      "global round: 58  client: 83  local train loss: 1.3658\n",
      "global round: 58  avg train loss:0.1321  global test loss: 1.3666  global test accu: 0.7883\n",
      "================================================================================================================\n",
      "global round: 59  client: 94  local train loss: 1.3544\n",
      "global round: 59  client: 51  local train loss: 1.3877\n",
      "global round: 59  client: 93  local train loss: 1.3674\n",
      "global round: 59  client: 87  local train loss: 1.3394\n",
      "global round: 59  client: 64  local train loss: 1.3405\n",
      "global round: 59  client: 52  local train loss: 1.5874\n",
      "global round: 59  client: 65  local train loss: 1.4211\n",
      "global round: 59  client: 43  local train loss: 1.5737\n",
      "global round: 59  client: 48  local train loss: 1.3945\n",
      "global round: 59  client: 22  local train loss: 1.3711\n",
      "global round: 59  avg train loss:0.1285  global test loss: 1.3545  global test accu: 0.7897\n",
      "================================================================================================================\n",
      "global round: 60  client: 61  local train loss: 1.3954\n",
      "global round: 60  client: 71  local train loss: 1.4104\n",
      "global round: 60  client: 68  local train loss: 1.4309\n",
      "global round: 60  client: 45  local train loss: 1.3576\n",
      "global round: 60  client: 22  local train loss: 1.3175\n",
      "global round: 60  client: 21  local train loss: 1.4832\n",
      "global round: 60  client: 15  local train loss: 1.4142\n",
      "global round: 60  client: 36  local train loss: 1.3909\n",
      "global round: 60  client: 86  local train loss: 1.3711\n",
      "global round: 60  client: 69  local train loss: 1.3132\n",
      "global round: 60  avg train loss:0.1262  global test loss: 1.3414  global test accu: 0.7908\n",
      "================================================================================================================\n",
      "global round: 61  client: 02  local train loss: 1.5827\n",
      "global round: 61  client: 86  local train loss: 1.3170\n",
      "global round: 61  client: 84  local train loss: 1.3028\n",
      "global round: 61  client: 19  local train loss: 1.4528\n",
      "global round: 61  client: 25  local train loss: 1.5322\n",
      "global round: 61  client: 20  local train loss: 1.3874\n",
      "global round: 61  client: 13  local train loss: 1.3803\n",
      "global round: 61  client: 10  local train loss: 1.5022\n",
      "global round: 61  client: 41  local train loss: 1.4303\n",
      "global round: 61  client: 04  local train loss: 1.3752\n",
      "global round: 61  avg train loss:0.1297  global test loss: 1.3327  global test accu: 0.7916\n",
      "================================================================================================================\n",
      "global round: 62  client: 32  local train loss: 1.3718\n",
      "global round: 62  client: 54  local train loss: 1.3760\n",
      "global round: 62  client: 11  local train loss: 1.3786\n",
      "global round: 62  client: 80  local train loss: 1.4038\n",
      "global round: 62  client: 79  local train loss: 1.3768\n",
      "global round: 62  client: 16  local train loss: 1.3466\n",
      "global round: 62  client: 01  local train loss: 1.4315\n",
      "global round: 62  client: 42  local train loss: 1.3242\n",
      "global round: 62  client: 58  local train loss: 1.3941\n",
      "global round: 62  client: 40  local train loss: 1.4514\n",
      "global round: 62  avg train loss:0.1260  global test loss: 1.3213  global test accu: 0.7940\n",
      "================================================================================================================\n",
      "global round: 63  client: 87  local train loss: 1.3235\n",
      "global round: 63  client: 15  local train loss: 1.3328\n",
      "global round: 63  client: 77  local train loss: 1.4319\n",
      "global round: 63  client: 30  local train loss: 1.3394\n",
      "global round: 63  client: 21  local train loss: 1.3428\n",
      "global round: 63  client: 53  local train loss: 1.4030\n",
      "global round: 63  client: 03  local train loss: 1.3875\n",
      "global round: 63  client: 85  local train loss: 1.3390\n",
      "global round: 63  client: 56  local train loss: 1.4556\n",
      "global round: 63  client: 14  local train loss: 1.3318\n",
      "global round: 63  avg train loss:0.1244  global test loss: 1.3089  global test accu: 0.7960\n",
      "================================================================================================================\n",
      "global round: 64  client: 02  local train loss: 1.3052\n",
      "global round: 64  client: 83  local train loss: 1.3668\n",
      "global round: 64  client: 49  local train loss: 1.4035\n",
      "global round: 64  client: 10  local train loss: 1.2971\n",
      "global round: 64  client: 04  local train loss: 1.3156\n",
      "global round: 64  client: 99  local train loss: 1.5705\n",
      "global round: 64  client: 69  local train loss: 1.2937\n",
      "global round: 64  client: 78  local train loss: 1.3630\n",
      "global round: 64  client: 45  local train loss: 1.3246\n",
      "global round: 64  client: 55  local train loss: 1.3488\n",
      "global round: 64  avg train loss:0.1235  global test loss: 1.2967  global test accu: 0.7976\n",
      "================================================================================================================\n",
      "global round: 65  client: 70  local train loss: 1.3825\n",
      "global round: 65  client: 84  local train loss: 1.2868\n",
      "global round: 65  client: 40  local train loss: 1.3080\n",
      "global round: 65  client: 59  local train loss: 1.3492\n",
      "global round: 65  client: 65  local train loss: 1.3757\n",
      "global round: 65  client: 24  local train loss: 1.5459\n",
      "global round: 65  client: 80  local train loss: 1.3219\n",
      "global round: 65  client: 16  local train loss: 1.3182\n",
      "global round: 65  client: 17  local train loss: 1.4084\n",
      "global round: 65  client: 30  local train loss: 1.2683\n",
      "global round: 65  avg train loss:0.1233  global test loss: 1.2857  global test accu: 0.7987\n",
      "================================================================================================================\n",
      "global round: 66  client: 14  local train loss: 1.2699\n",
      "global round: 66  client: 20  local train loss: 1.3573\n",
      "global round: 66  client: 71  local train loss: 1.3176\n",
      "global round: 66  client: 04  local train loss: 1.2983\n",
      "global round: 66  client: 15  local train loss: 1.3063\n",
      "global round: 66  client: 86  local train loss: 1.3222\n",
      "global round: 66  client: 40  local train loss: 1.2855\n",
      "global round: 66  client: 10  local train loss: 1.2820\n",
      "global round: 66  client: 89  local train loss: 1.6531\n",
      "global round: 66  client: 31  local train loss: 1.4564\n",
      "global round: 66  avg train loss:0.1232  global test loss: 1.2752  global test accu: 0.7998\n",
      "================================================================================================================\n",
      "global round: 67  client: 73  local train loss: 1.3352\n",
      "global round: 67  client: 53  local train loss: 1.3304\n",
      "global round: 67  client: 38  local train loss: 1.4998\n",
      "global round: 67  client: 68  local train loss: 1.2798\n",
      "global round: 67  client: 45  local train loss: 1.3003\n",
      "global round: 67  client: 75  local train loss: 1.4543\n",
      "global round: 67  client: 36  local train loss: 1.2862\n",
      "global round: 67  client: 17  local train loss: 1.3100\n",
      "global round: 67  client: 63  local train loss: 1.3843\n",
      "global round: 67  client: 95  local train loss: 1.3401\n",
      "global round: 67  avg train loss:0.1229  global test loss: 1.2655  global test accu: 0.8011\n",
      "================================================================================================================\n",
      "global round: 68  client: 17  local train loss: 1.2914\n",
      "global round: 68  client: 59  local train loss: 1.2773\n",
      "global round: 68  client: 88  local train loss: 1.4347\n",
      "global round: 68  client: 61  local train loss: 1.3359\n",
      "global round: 68  client: 92  local train loss: 1.5523\n",
      "global round: 68  client: 34  local train loss: 1.8427\n",
      "global round: 68  client: 46  local train loss: 1.3856\n",
      "global round: 68  client: 55  local train loss: 1.2911\n",
      "global round: 68  client: 47  local train loss: 1.4757\n",
      "global round: 68  client: 80  local train loss: 1.2886\n",
      "global round: 68  avg train loss:0.1289  global test loss: 1.2617  global test accu: 0.8019\n",
      "================================================================================================================\n",
      "global round: 69  client: 51  local train loss: 1.3299\n",
      "global round: 69  client: 96  local train loss: 1.3735\n",
      "global round: 69  client: 14  local train loss: 1.2397\n",
      "global round: 69  client: 99  local train loss: 1.2706\n",
      "global round: 69  client: 27  local train loss: 1.3323\n",
      "global round: 69  client: 43  local train loss: 1.3124\n",
      "global round: 69  client: 60  local train loss: 1.4422\n",
      "global round: 69  client: 38  local train loss: 1.2609\n",
      "global round: 69  client: 19  local train loss: 1.3021\n",
      "global round: 69  client: 18  local train loss: 1.4694\n",
      "global round: 69  avg train loss:0.1212  global test loss: 1.2526  global test accu: 0.8035\n",
      "================================================================================================================\n",
      "global round: 70  client: 94  local train loss: 1.3331\n",
      "global round: 70  client: 89  local train loss: 1.2217\n",
      "global round: 70  client: 29  local train loss: 1.3625\n",
      "global round: 70  client: 68  local train loss: 1.2151\n",
      "global round: 70  client: 09  local train loss: 1.3907\n",
      "global round: 70  client: 57  local train loss: 1.9270\n",
      "global round: 70  client: 50  local train loss: 1.3667\n",
      "global round: 70  client: 08  local train loss: 1.5117\n",
      "global round: 70  client: 48  local train loss: 1.3470\n",
      "global round: 70  client: 82  local train loss: 1.5486\n",
      "global round: 70  avg train loss:0.1293  global test loss: 1.2512  global test accu: 0.8041\n",
      "================================================================================================================\n",
      "global round: 71  client: 68  local train loss: 1.2067\n",
      "global round: 71  client: 60  local train loss: 1.2682\n",
      "global round: 71  client: 84  local train loss: 1.2411\n",
      "global round: 71  client: 08  local train loss: 1.2781\n",
      "global round: 71  client: 74  local train loss: 1.3389\n",
      "global round: 71  client: 48  local train loss: 1.2858\n",
      "global round: 71  client: 87  local train loss: 1.2904\n",
      "global round: 71  client: 83  local train loss: 1.2985\n",
      "global round: 71  client: 59  local train loss: 1.2640\n",
      "global round: 71  client: 30  local train loss: 1.2517\n",
      "global round: 71  avg train loss:0.1157  global test loss: 1.2369  global test accu: 0.8056\n",
      "================================================================================================================\n",
      "global round: 72  client: 83  local train loss: 1.2701\n",
      "global round: 72  client: 37  local train loss: 1.3471\n",
      "global round: 72  client: 19  local train loss: 1.2343\n",
      "global round: 72  client: 22  local train loss: 1.3027\n",
      "global round: 72  client: 36  local train loss: 1.2234\n",
      "global round: 72  client: 13  local train loss: 1.3343\n",
      "global round: 72  client: 75  local train loss: 1.2659\n",
      "global round: 72  client: 44  local train loss: 1.6178\n",
      "global round: 72  client: 16  local train loss: 1.2851\n",
      "global round: 72  client: 61  local train loss: 1.2741\n",
      "global round: 72  avg train loss:0.1196  global test loss: 1.2273  global test accu: 0.8065\n",
      "================================================================================================================\n",
      "global round: 73  client: 01  local train loss: 1.3192\n",
      "global round: 73  client: 47  local train loss: 1.2800\n",
      "global round: 73  client: 59  local train loss: 1.2454\n",
      "global round: 73  client: 58  local train loss: 1.2918\n",
      "global round: 73  client: 07  local train loss: 1.3982\n",
      "global round: 73  client: 88  local train loss: 1.2731\n",
      "global round: 73  client: 66  local train loss: 1.4259\n",
      "global round: 73  client: 27  local train loss: 1.2395\n",
      "global round: 73  client: 34  local train loss: 1.2728\n",
      "global round: 73  client: 81  local train loss: 1.3638\n",
      "global round: 73  avg train loss:0.1192  global test loss: 1.2183  global test accu: 0.8084\n",
      "================================================================================================================\n",
      "global round: 74  client: 76  local train loss: 1.4033\n",
      "global round: 74  client: 53  local train loss: 1.3012\n",
      "global round: 74  client: 21  local train loss: 1.3304\n",
      "global round: 74  client: 84  local train loss: 1.2098\n",
      "global round: 74  client: 87  local train loss: 1.2406\n",
      "global round: 74  client: 28  local train loss: 1.3448\n",
      "global round: 74  client: 51  local train loss: 1.2563\n",
      "global round: 74  client: 55  local train loss: 1.2735\n",
      "global round: 74  client: 91  local train loss: 1.4474\n",
      "global round: 74  client: 18  local train loss: 1.2373\n",
      "global round: 74  avg train loss:0.1186  global test loss: 1.2095  global test accu: 0.8093\n",
      "================================================================================================================\n",
      "global round: 75  client: 55  local train loss: 1.2290\n",
      "global round: 75  client: 65  local train loss: 1.3230\n",
      "global round: 75  client: 30  local train loss: 1.2216\n",
      "global round: 75  client: 67  local train loss: 1.4485\n",
      "global round: 75  client: 27  local train loss: 1.2033\n",
      "global round: 75  client: 51  local train loss: 1.2282\n",
      "global round: 75  client: 89  local train loss: 1.2029\n",
      "global round: 75  client: 31  local train loss: 1.2894\n",
      "global round: 75  client: 75  local train loss: 1.2493\n",
      "global round: 75  client: 87  local train loss: 1.2127\n",
      "global round: 75  avg train loss:0.1146  global test loss: 1.1981  global test accu: 0.8104\n",
      "================================================================================================================\n",
      "global round: 76  client: 35  local train loss: 1.3803\n",
      "global round: 76  client: 68  local train loss: 1.1933\n",
      "global round: 76  client: 16  local train loss: 1.2509\n",
      "global round: 76  client: 01  local train loss: 1.2372\n",
      "global round: 76  client: 87  local train loss: 1.2045\n",
      "global round: 76  client: 50  local train loss: 1.2656\n",
      "global round: 76  client: 45  local train loss: 1.2701\n",
      "global round: 76  client: 14  local train loss: 1.2252\n",
      "global round: 76  client: 27  local train loss: 1.1915\n",
      "global round: 76  client: 85  local train loss: 1.3041\n",
      "global round: 76  avg train loss:0.1138  global test loss: 1.1867  global test accu: 0.8117\n",
      "================================================================================================================\n",
      "global round: 77  client: 52  local train loss: 1.3276\n",
      "global round: 77  client: 10  local train loss: 1.2590\n",
      "global round: 77  client: 83  local train loss: 1.2551\n",
      "global round: 77  client: 70  local train loss: 1.2411\n",
      "global round: 77  client: 96  local train loss: 1.2528\n",
      "global round: 77  client: 35  local train loss: 1.2164\n",
      "global round: 77  client: 65  local train loss: 1.2578\n",
      "global round: 77  client: 81  local train loss: 1.2013\n",
      "global round: 77  client: 26  local train loss: 1.3429\n",
      "global round: 77  client: 87  local train loss: 1.1903\n",
      "global round: 77  avg train loss:0.1140  global test loss: 1.1767  global test accu: 0.8130\n",
      "================================================================================================================\n",
      "global round: 78  client: 91  local train loss: 1.2026\n",
      "global round: 78  client: 13  local train loss: 1.2574\n",
      "global round: 78  client: 48  local train loss: 1.2701\n",
      "global round: 78  client: 24  local train loss: 1.2538\n",
      "global round: 78  client: 52  local train loss: 1.1913\n",
      "global round: 78  client: 64  local train loss: 1.3311\n",
      "global round: 78  client: 82  local train loss: 1.2691\n",
      "global round: 78  client: 42  local train loss: 1.2955\n",
      "global round: 78  client: 58  local train loss: 1.2222\n",
      "global round: 78  client: 03  local train loss: 1.2892\n",
      "global round: 78  avg train loss:0.1144  global test loss: 1.1679  global test accu: 0.8138\n",
      "================================================================================================================\n",
      "global round: 79  client: 74  local train loss: 1.2206\n",
      "global round: 79  client: 64  local train loss: 1.1875\n",
      "global round: 79  client: 40  local train loss: 1.2828\n",
      "global round: 79  client: 89  local train loss: 1.1686\n",
      "global round: 79  client: 00  local train loss: 1.3209\n",
      "global round: 79  client: 51  local train loss: 1.2135\n",
      "global round: 79  client: 02  local train loss: 1.2873\n",
      "global round: 79  client: 10  local train loss: 1.1948\n",
      "global round: 79  client: 35  local train loss: 1.2112\n",
      "global round: 79  client: 82  local train loss: 1.2114\n",
      "global round: 79  avg train loss:0.1118  global test loss: 1.1577  global test accu: 0.8145\n",
      "================================================================================================================\n",
      "global round: 80  client: 60  local train loss: 1.2628\n",
      "global round: 80  client: 19  local train loss: 1.2219\n",
      "global round: 80  client: 07  local train loss: 1.2235\n",
      "global round: 80  client: 33  local train loss: 1.3868\n",
      "global round: 80  client: 48  local train loss: 1.2195\n",
      "global round: 80  client: 51  local train loss: 1.1901\n",
      "global round: 80  client: 02  local train loss: 1.1899\n",
      "global round: 80  client: 75  local train loss: 1.2222\n",
      "global round: 80  client: 61  local train loss: 1.2481\n",
      "global round: 80  client: 82  local train loss: 1.2054\n",
      "global round: 80  avg train loss:0.1125  global test loss: 1.1478  global test accu: 0.8149\n",
      "================================================================================================================\n",
      "global round: 81  client: 09  local train loss: 1.2272\n",
      "global round: 81  client: 75  local train loss: 1.1895\n",
      "global round: 81  client: 16  local train loss: 1.2167\n",
      "global round: 81  client: 70  local train loss: 1.1498\n",
      "global round: 81  client: 61  local train loss: 1.1863\n",
      "global round: 81  client: 10  local train loss: 1.1761\n",
      "global round: 81  client: 68  local train loss: 1.1613\n",
      "global round: 81  client: 22  local train loss: 1.2229\n",
      "global round: 81  client: 73  local train loss: 1.2389\n",
      "global round: 81  client: 07  local train loss: 1.1744\n",
      "global round: 81  avg train loss:0.1086  global test loss: 1.1365  global test accu: 0.8159\n",
      "================================================================================================================\n",
      "global round: 82  client: 85  local train loss: 1.2102\n",
      "global round: 82  client: 02  local train loss: 1.1799\n",
      "global round: 82  client: 51  local train loss: 1.1833\n",
      "global round: 82  client: 33  local train loss: 1.1645\n",
      "global round: 82  client: 86  local train loss: 1.2708\n",
      "global round: 82  client: 05  local train loss: 1.5063\n",
      "global round: 82  client: 67  local train loss: 1.1845\n",
      "global round: 82  client: 59  local train loss: 1.2262\n",
      "global round: 82  client: 39  local train loss: 1.7324\n",
      "global round: 82  client: 72  local train loss: 1.4584\n",
      "global round: 82  avg train loss:0.1192  global test loss: 1.1354  global test accu: 0.8165\n",
      "================================================================================================================\n",
      "global round: 83  client: 94  local train loss: 1.2550\n",
      "global round: 83  client: 54  local train loss: 1.3217\n",
      "global round: 83  client: 20  local train loss: 1.3086\n",
      "global round: 83  client: 09  local train loss: 1.1455\n",
      "global round: 83  client: 95  local train loss: 1.2493\n",
      "global round: 83  client: 27  local train loss: 1.1825\n",
      "global round: 83  client: 73  local train loss: 1.1360\n",
      "global round: 83  client: 31  local train loss: 1.2281\n",
      "global round: 83  client: 66  local train loss: 1.2429\n",
      "global round: 83  client: 92  local train loss: 1.2797\n",
      "global round: 83  avg train loss:0.1123  global test loss: 1.1281  global test accu: 0.8169\n",
      "================================================================================================================\n",
      "global round: 84  client: 23  local train loss: 1.5810\n",
      "global round: 84  client: 07  local train loss: 1.1655\n",
      "global round: 84  client: 99  local train loss: 1.2383\n",
      "global round: 84  client: 43  local train loss: 1.2438\n",
      "global round: 84  client: 51  local train loss: 1.1638\n",
      "global round: 84  client: 86  local train loss: 1.1626\n",
      "global round: 84  client: 45  local train loss: 1.2125\n",
      "global round: 84  client: 81  local train loss: 1.1752\n",
      "global round: 84  client: 20  local train loss: 1.2021\n",
      "global round: 84  client: 63  local train loss: 1.2869\n",
      "global round: 84  avg train loss:0.1130  global test loss: 1.1218  global test accu: 0.8172\n",
      "================================================================================================================\n",
      "global round: 85  client: 41  local train loss: 1.3493\n",
      "global round: 85  client: 76  local train loss: 1.2348\n",
      "global round: 85  client: 61  local train loss: 1.1795\n",
      "global round: 85  client: 66  local train loss: 1.1864\n",
      "global round: 85  client: 54  local train loss: 1.1793\n",
      "global round: 85  client: 14  local train loss: 1.1807\n",
      "global round: 85  client: 62  local train loss: 1.3019\n",
      "global round: 85  client: 77  local train loss: 1.3291\n",
      "global round: 85  client: 11  local train loss: 1.2822\n",
      "global round: 85  client: 85  local train loss: 1.1660\n",
      "global round: 85  avg train loss:0.1126  global test loss: 1.1156  global test accu: 0.8189\n",
      "================================================================================================================\n",
      "global round: 86  client: 10  local train loss: 1.1615\n",
      "global round: 86  client: 14  local train loss: 1.1214\n",
      "global round: 86  client: 15  local train loss: 1.2768\n",
      "global round: 86  client: 51  local train loss: 1.1542\n",
      "global round: 86  client: 39  local train loss: 1.1609\n",
      "global round: 86  client: 01  local train loss: 1.2128\n",
      "global round: 86  client: 56  local train loss: 1.3034\n",
      "global round: 86  client: 53  local train loss: 1.2492\n",
      "global round: 86  client: 36  local train loss: 1.1969\n",
      "global round: 86  client: 23  local train loss: 1.1402\n",
      "global round: 86  avg train loss:0.1089  global test loss: 1.1068  global test accu: 0.8192\n",
      "================================================================================================================\n",
      "global round: 87  client: 93  local train loss: 1.3191\n",
      "global round: 87  client: 72  local train loss: 1.1835\n",
      "global round: 87  client: 89  local train loss: 1.1394\n",
      "global round: 87  client: 11  local train loss: 1.1339\n",
      "global round: 87  client: 74  local train loss: 1.1656\n",
      "global round: 87  client: 90  local train loss: 1.4590\n",
      "global round: 87  client: 57  local train loss: 1.2046\n",
      "global round: 87  client: 47  local train loss: 1.2583\n",
      "global round: 87  client: 80  local train loss: 1.2814\n",
      "global round: 87  client: 35  local train loss: 1.1985\n",
      "global round: 87  avg train loss:0.1122  global test loss: 1.1022  global test accu: 0.8196\n",
      "================================================================================================================\n",
      "global round: 88  client: 58  local train loss: 1.1749\n",
      "global round: 88  client: 41  local train loss: 1.1927\n",
      "global round: 88  client: 47  local train loss: 1.1570\n",
      "global round: 88  client: 09  local train loss: 1.1477\n",
      "global round: 88  client: 96  local train loss: 1.1958\n",
      "global round: 88  client: 10  local train loss: 1.1435\n",
      "global round: 88  client: 67  local train loss: 1.1377\n",
      "global round: 88  client: 42  local train loss: 1.1703\n",
      "global round: 88  client: 72  local train loss: 1.1496\n",
      "global round: 88  client: 43  local train loss: 1.1394\n",
      "global round: 88  avg train loss:0.1055  global test loss: 1.0913  global test accu: 0.8206\n",
      "================================================================================================================\n",
      "global round: 89  client: 15  local train loss: 1.1634\n",
      "global round: 89  client: 66  local train loss: 1.1648\n",
      "global round: 89  client: 05  local train loss: 1.1761\n",
      "global round: 89  client: 95  local train loss: 1.1431\n",
      "global round: 89  client: 94  local train loss: 1.1556\n",
      "global round: 89  client: 32  local train loss: 1.2992\n",
      "global round: 89  client: 46  local train loss: 1.2487\n",
      "global round: 89  client: 22  local train loss: 1.1533\n",
      "global round: 89  client: 99  local train loss: 1.1344\n",
      "global round: 89  client: 98  local train loss: 1.3758\n",
      "global round: 89  avg train loss:0.1092  global test loss: 1.0851  global test accu: 0.8205\n",
      "================================================================================================================\n",
      "global round: 90  client: 72  local train loss: 1.1501\n",
      "global round: 90  client: 74  local train loss: 1.1206\n",
      "global round: 90  client: 25  local train loss: 1.3231\n",
      "global round: 90  client: 59  local train loss: 1.1676\n",
      "global round: 90  client: 48  local train loss: 1.2060\n",
      "global round: 90  client: 62  local train loss: 1.1286\n",
      "global round: 90  client: 80  local train loss: 1.1574\n",
      "global round: 90  client: 53  local train loss: 1.1746\n",
      "global round: 90  client: 57  local train loss: 1.0968\n",
      "global round: 90  client: 08  local train loss: 1.2603\n",
      "global round: 90  avg train loss:0.1071  global test loss: 1.0767  global test accu: 0.8223\n",
      "================================================================================================================\n",
      "global round: 91  client: 02  local train loss: 1.1664\n",
      "global round: 91  client: 13  local train loss: 1.2108\n",
      "global round: 91  client: 22  local train loss: 1.1152\n",
      "global round: 91  client: 50  local train loss: 1.2278\n",
      "global round: 91  client: 15  local train loss: 1.1477\n",
      "global round: 91  client: 80  local train loss: 1.1400\n",
      "global round: 91  client: 91  local train loss: 1.1735\n",
      "global round: 91  client: 86  local train loss: 1.1540\n",
      "global round: 91  client: 72  local train loss: 1.1343\n",
      "global round: 91  client: 75  local train loss: 1.1820\n",
      "global round: 91  avg train loss:0.1059  global test loss: 1.0676  global test accu: 0.8227\n",
      "================================================================================================================\n",
      "global round: 92  client: 50  local train loss: 1.1353\n",
      "global round: 92  client: 05  local train loss: 1.1474\n",
      "global round: 92  client: 63  local train loss: 1.1820\n",
      "global round: 92  client: 60  local train loss: 1.1918\n",
      "global round: 92  client: 71  local train loss: 1.2675\n",
      "global round: 92  client: 21  local train loss: 1.2567\n",
      "global round: 92  client: 00  local train loss: 1.1488\n",
      "global round: 92  client: 20  local train loss: 1.1944\n",
      "global round: 92  client: 68  local train loss: 1.1128\n",
      "global round: 92  client: 45  local train loss: 1.1576\n",
      "global round: 92  avg train loss:0.1072  global test loss: 1.0608  global test accu: 0.8239\n",
      "================================================================================================================\n",
      "global round: 93  client: 71  local train loss: 1.1049\n",
      "global round: 93  client: 80  local train loss: 1.1351\n",
      "global round: 93  client: 39  local train loss: 1.1345\n",
      "global round: 93  client: 24  local train loss: 1.1767\n",
      "global round: 93  client: 74  local train loss: 1.1024\n",
      "global round: 93  client: 37  local train loss: 1.2298\n",
      "global round: 93  client: 12  local train loss: 1.4870\n",
      "global round: 93  client: 53  local train loss: 1.1502\n",
      "global round: 93  client: 03  local train loss: 1.1777\n",
      "global round: 93  client: 90  local train loss: 1.1568\n",
      "global round: 93  avg train loss:0.1078  global test loss: 1.0554  global test accu: 0.8242\n",
      "================================================================================================================\n",
      "global round: 94  client: 61  local train loss: 1.1631\n",
      "global round: 94  client: 11  local train loss: 1.1210\n",
      "global round: 94  client: 28  local train loss: 1.2214\n",
      "global round: 94  client: 33  local train loss: 1.1538\n",
      "global round: 94  client: 78  local train loss: 1.3005\n",
      "global round: 94  client: 72  local train loss: 1.1251\n",
      "global round: 94  client: 34  local train loss: 1.2497\n",
      "global round: 94  client: 59  local train loss: 1.1211\n",
      "global round: 94  client: 02  local train loss: 1.1215\n",
      "global round: 94  client: 43  local train loss: 1.1250\n",
      "global round: 94  avg train loss:0.1064  global test loss: 1.0492  global test accu: 0.8250\n",
      "================================================================================================================\n",
      "global round: 95  client: 73  local train loss: 1.1337\n",
      "global round: 95  client: 08  local train loss: 1.1460\n",
      "global round: 95  client: 62  local train loss: 1.0990\n",
      "global round: 95  client: 35  local train loss: 1.1478\n",
      "global round: 95  client: 55  local train loss: 1.2248\n",
      "global round: 95  client: 14  local train loss: 1.1185\n",
      "global round: 95  client: 78  local train loss: 1.1070\n",
      "global round: 95  client: 20  local train loss: 1.1664\n",
      "global round: 95  client: 99  local train loss: 1.1129\n",
      "global round: 95  client: 60  local train loss: 1.1344\n",
      "global round: 95  avg train loss:0.1035  global test loss: 1.0405  global test accu: 0.8271\n",
      "================================================================================================================\n",
      "global round: 96  client: 50  local train loss: 1.1282\n",
      "global round: 96  client: 61  local train loss: 1.1026\n",
      "global round: 96  client: 86  local train loss: 1.1215\n",
      "global round: 96  client: 24  local train loss: 1.0852\n",
      "global round: 96  client: 00  local train loss: 1.0766\n",
      "global round: 96  client: 13  local train loss: 1.1309\n",
      "global round: 96  client: 22  local train loss: 1.1070\n",
      "global round: 96  client: 55  local train loss: 1.0964\n",
      "global round: 96  client: 01  local train loss: 1.1558\n",
      "global round: 96  client: 65  local train loss: 1.2491\n",
      "global round: 96  avg train loss:0.1023  global test loss: 1.0313  global test accu: 0.8279\n",
      "================================================================================================================\n",
      "global round: 97  client: 93  local train loss: 1.1420\n",
      "global round: 97  client: 11  local train loss: 1.0656\n",
      "global round: 97  client: 32  local train loss: 1.1289\n",
      "global round: 97  client: 02  local train loss: 1.1121\n",
      "global round: 97  client: 63  local train loss: 1.1315\n",
      "global round: 97  client: 31  local train loss: 1.1843\n",
      "global round: 97  client: 36  local train loss: 1.1128\n",
      "global round: 97  client: 38  local train loss: 1.2576\n",
      "global round: 97  client: 55  local train loss: 1.0840\n",
      "global round: 97  client: 68  local train loss: 1.0538\n",
      "global round: 97  avg train loss:0.1025  global test loss: 1.0242  global test accu: 0.8283\n",
      "================================================================================================================\n",
      "global round: 98  client: 26  local train loss: 1.1647\n",
      "global round: 98  client: 04  local train loss: 1.2726\n",
      "global round: 98  client: 69  local train loss: 1.2702\n",
      "global round: 98  client: 59  local train loss: 1.1070\n",
      "global round: 98  client: 76  local train loss: 1.1742\n",
      "global round: 98  client: 31  local train loss: 1.1059\n",
      "global round: 98  client: 54  local train loss: 1.1716\n",
      "global round: 98  client: 40  local train loss: 1.1939\n",
      "global round: 98  client: 44  local train loss: 1.2619\n",
      "global round: 98  client: 71  local train loss: 1.1069\n",
      "global round: 98  avg train loss:0.1075  global test loss: 1.0217  global test accu: 0.8285\n",
      "================================================================================================================\n",
      "global round: 99  client: 50  local train loss: 1.1095\n",
      "global round: 99  client: 40  local train loss: 1.0830\n",
      "global round: 99  client: 22  local train loss: 1.0762\n",
      "global round: 99  client: 51  local train loss: 1.1491\n",
      "global round: 99  client: 07  local train loss: 1.1570\n",
      "global round: 99  client: 39  local train loss: 1.1003\n",
      "global round: 99  client: 81  local train loss: 1.1381\n",
      "global round: 99  client: 89  local train loss: 1.0905\n",
      "global round: 99  client: 88  local train loss: 1.2488\n",
      "global round: 99  client: 91  local train loss: 1.0867\n",
      "global round: 99  avg train loss:0.1022  global test loss: 1.0152  global test accu: 0.8286\n",
      "================================================================================================================\n",
      "global round: 100  client: 70  local train loss: 1.1251\n",
      "global round: 100  client: 91  local train loss: 1.0473\n",
      "global round: 100  client: 56  local train loss: 1.1409\n",
      "global round: 100  client: 69  local train loss: 1.0523\n",
      "global round: 100  client: 78  local train loss: 1.1008\n",
      "global round: 100  client: 41  local train loss: 1.1739\n",
      "global round: 100  client: 19  local train loss: 1.1548\n",
      "global round: 100  client: 73  local train loss: 1.0650\n",
      "global round: 100  client: 63  local train loss: 1.0991\n",
      "global round: 100  client: 44  local train loss: 1.1018\n",
      "global round: 100  avg train loss:0.1006  global test loss: 1.0076  global test accu: 0.8298\n",
      "================================================================================================================\n",
      "global round: 101  client: 15  local train loss: 1.1228\n",
      "global round: 101  client: 19  local train loss: 1.0539\n",
      "global round: 101  client: 66  local train loss: 1.1380\n",
      "global round: 101  client: 01  local train loss: 1.0932\n",
      "global round: 101  client: 03  local train loss: 1.0891\n",
      "global round: 101  client: 92  local train loss: 1.1789\n",
      "global round: 101  client: 76  local train loss: 1.0951\n",
      "global round: 101  client: 98  local train loss: 1.1137\n",
      "global round: 101  client: 85  local train loss: 1.1600\n",
      "global round: 101  client: 28  local train loss: 1.1082\n",
      "global round: 101  avg train loss:0.1014  global test loss: 1.0007  global test accu: 0.8306\n",
      "================================================================================================================\n",
      "global round: 102  client: 88  local train loss: 1.0986\n",
      "global round: 102  client: 16  local train loss: 1.1739\n",
      "global round: 102  client: 31  local train loss: 1.1022\n",
      "global round: 102  client: 12  local train loss: 1.1028\n",
      "global round: 102  client: 10  local train loss: 1.1196\n",
      "global round: 102  client: 81  local train loss: 1.0393\n",
      "global round: 102  client: 07  local train loss: 1.0747\n",
      "global round: 102  client: 35  local train loss: 1.1043\n",
      "global round: 102  client: 92  local train loss: 1.0991\n",
      "global round: 102  client: 51  local train loss: 1.0864\n",
      "global round: 102  avg train loss:0.1000  global test loss: 0.9928  global test accu: 0.8316\n",
      "================================================================================================================\n",
      "global round: 103  client: 73  local train loss: 1.0390\n",
      "global round: 103  client: 51  local train loss: 1.0680\n",
      "global round: 103  client: 01  local train loss: 1.0654\n",
      "global round: 103  client: 20  local train loss: 1.1370\n",
      "global round: 103  client: 54  local train loss: 1.1051\n",
      "global round: 103  client: 70  local train loss: 1.0184\n",
      "global round: 103  client: 71  local train loss: 1.0854\n",
      "global round: 103  client: 87  local train loss: 1.1902\n",
      "global round: 103  client: 37  local train loss: 1.1078\n",
      "global round: 103  client: 03  local train loss: 1.0498\n",
      "global round: 103  avg train loss:0.0988  global test loss: 0.9851  global test accu: 0.8323\n",
      "================================================================================================================\n",
      "global round: 104  client: 01  local train loss: 1.0548\n",
      "global round: 104  client: 88  local train loss: 1.0605\n",
      "global round: 104  client: 15  local train loss: 1.0700\n",
      "global round: 104  client: 75  local train loss: 1.1250\n",
      "global round: 104  client: 53  local train loss: 1.1321\n",
      "global round: 104  client: 58  local train loss: 1.1122\n",
      "global round: 104  client: 51  local train loss: 1.0622\n",
      "global round: 104  client: 66  local train loss: 1.0735\n",
      "global round: 104  client: 74  local train loss: 1.0931\n",
      "global round: 104  client: 91  local train loss: 1.0469\n",
      "global round: 104  avg train loss:0.0985  global test loss: 0.9774  global test accu: 0.8346\n",
      "================================================================================================================\n",
      "global round: 105  client: 12  local train loss: 1.0578\n",
      "global round: 105  client: 71  local train loss: 1.0385\n",
      "global round: 105  client: 94  local train loss: 1.1300\n",
      "global round: 105  client: 72  local train loss: 1.1132\n",
      "global round: 105  client: 05  local train loss: 1.1274\n",
      "global round: 105  client: 20  local train loss: 1.0891\n",
      "global round: 105  client: 97  local train loss: 1.4302\n",
      "global round: 105  client: 40  local train loss: 1.0826\n",
      "global round: 105  client: 45  local train loss: 1.1162\n",
      "global round: 105  client: 38  local train loss: 1.0816\n",
      "global round: 105  avg train loss:0.1024  global test loss: 0.9737  global test accu: 0.8353\n",
      "================================================================================================================\n",
      "global round: 106  client: 77  local train loss: 1.1858\n",
      "global round: 106  client: 11  local train loss: 1.0564\n",
      "global round: 106  client: 68  local train loss: 1.0222\n",
      "global round: 106  client: 78  local train loss: 1.0767\n",
      "global round: 106  client: 69  local train loss: 1.0502\n",
      "global round: 106  client: 22  local train loss: 1.0681\n",
      "global round: 106  client: 91  local train loss: 1.0251\n",
      "global round: 106  client: 84  local train loss: 1.1920\n",
      "global round: 106  client: 35  local train loss: 1.0805\n",
      "global round: 106  client: 58  local train loss: 1.0425\n",
      "global round: 106  avg train loss:0.0982  global test loss: 0.9678  global test accu: 0.8361\n",
      "================================================================================================================\n",
      "global round: 107  client: 73  local train loss: 1.0238\n",
      "global round: 107  client: 38  local train loss: 1.0539\n",
      "global round: 107  client: 71  local train loss: 1.0481\n",
      "global round: 107  client: 33  local train loss: 1.0799\n",
      "global round: 107  client: 15  local train loss: 1.0627\n",
      "global round: 107  client: 22  local train loss: 1.0217\n",
      "global round: 107  client: 23  local train loss: 1.1229\n",
      "global round: 107  client: 95  local train loss: 1.1243\n",
      "global round: 107  client: 45  local train loss: 1.0447\n",
      "global round: 107  client: 11  local train loss: 1.0046\n",
      "global round: 107  avg train loss:0.0962  global test loss: 0.9604  global test accu: 0.8368\n",
      "================================================================================================================\n",
      "global round: 108  client: 34  local train loss: 1.1166\n",
      "global round: 108  client: 96  local train loss: 1.1344\n",
      "global round: 108  client: 12  local train loss: 1.0598\n",
      "global round: 108  client: 99  local train loss: 1.0761\n",
      "global round: 108  client: 16  local train loss: 1.0627\n",
      "global round: 108  client: 49  local train loss: 1.3004\n",
      "global round: 108  client: 39  local train loss: 1.0722\n",
      "global round: 108  client: 61  local train loss: 1.0924\n",
      "global round: 108  client: 84  local train loss: 1.0020\n",
      "global round: 108  client: 11  local train loss: 1.0108\n",
      "global round: 108  avg train loss:0.0993  global test loss: 0.9562  global test accu: 0.8379\n",
      "================================================================================================================\n",
      "global round: 109  client: 23  local train loss: 1.0278\n",
      "global round: 109  client: 05  local train loss: 1.0610\n",
      "global round: 109  client: 86  local train loss: 1.0906\n",
      "global round: 109  client: 95  local train loss: 1.0150\n",
      "global round: 109  client: 29  local train loss: 1.2827\n",
      "global round: 109  client: 54  local train loss: 1.0766\n",
      "global round: 109  client: 53  local train loss: 1.0744\n",
      "global round: 109  client: 21  local train loss: 1.1438\n",
      "global round: 109  client: 51  local train loss: 1.0504\n",
      "global round: 109  client: 81  local train loss: 1.0234\n",
      "global round: 109  avg train loss:0.0986  global test loss: 0.9509  global test accu: 0.8386\n",
      "================================================================================================================\n",
      "global round: 110  client: 57  local train loss: 1.0807\n",
      "global round: 110  client: 64  local train loss: 1.1861\n",
      "global round: 110  client: 45  local train loss: 1.0320\n",
      "global round: 110  client: 21  local train loss: 1.0587\n",
      "global round: 110  client: 43  local train loss: 1.0908\n",
      "global round: 110  client: 11  local train loss: 1.0037\n",
      "global round: 110  client: 77  local train loss: 1.0678\n",
      "global round: 110  client: 34  local train loss: 1.0416\n",
      "global round: 110  client: 36  local train loss: 1.0445\n",
      "global round: 110  client: 42  local train loss: 1.1162\n",
      "global round: 110  avg train loss:0.0975  global test loss: 0.9460  global test accu: 0.8388\n",
      "================================================================================================================\n",
      "global round: 111  client: 04  local train loss: 1.0834\n",
      "global round: 111  client: 62  local train loss: 1.0659\n",
      "global round: 111  client: 93  local train loss: 1.0861\n",
      "global round: 111  client: 09  local train loss: 1.1184\n",
      "global round: 111  client: 54  local train loss: 1.0451\n",
      "global round: 111  client: 13  local train loss: 1.0979\n",
      "global round: 111  client: 76  local train loss: 1.0896\n",
      "global round: 111  client: 01  local train loss: 1.0497\n",
      "global round: 111  client: 05  local train loss: 1.0477\n",
      "global round: 111  client: 57  local train loss: 0.9751\n",
      "global round: 111  avg train loss:0.0969  global test loss: 0.9405  global test accu: 0.8392\n",
      "================================================================================================================\n",
      "global round: 112  client: 35  local train loss: 1.0531\n",
      "global round: 112  client: 32  local train loss: 1.0813\n",
      "global round: 112  client: 98  local train loss: 1.0434\n",
      "global round: 112  client: 36  local train loss: 0.9782\n",
      "global round: 112  client: 37  local train loss: 1.0408\n",
      "global round: 112  client: 08  local train loss: 1.1084\n",
      "global round: 112  client: 76  local train loss: 1.0486\n",
      "global round: 112  client: 89  local train loss: 1.0189\n",
      "global round: 112  client: 50  local train loss: 1.0997\n",
      "global round: 112  client: 63  local train loss: 1.0865\n",
      "global round: 112  avg train loss:0.0960  global test loss: 0.9350  global test accu: 0.8401\n",
      "================================================================================================================\n",
      "global round: 113  client: 16  local train loss: 1.0435\n",
      "global round: 113  client: 39  local train loss: 1.0288\n",
      "global round: 113  client: 67  local train loss: 1.0990\n",
      "global round: 113  client: 03  local train loss: 1.0281\n",
      "global round: 113  client: 82  local train loss: 1.1884\n",
      "global round: 113  client: 30  local train loss: 1.1840\n",
      "global round: 113  client: 52  local train loss: 1.1910\n",
      "global round: 113  client: 07  local train loss: 1.0613\n",
      "global round: 113  client: 95  local train loss: 1.0171\n",
      "global round: 113  client: 68  local train loss: 0.9870\n",
      "global round: 113  avg train loss:0.0984  global test loss: 0.9332  global test accu: 0.8403\n",
      "================================================================================================================\n",
      "global round: 114  client: 84  local train loss: 0.9864\n",
      "global round: 114  client: 57  local train loss: 0.9736\n",
      "global round: 114  client: 93  local train loss: 1.0209\n",
      "global round: 114  client: 20  local train loss: 1.0871\n",
      "global round: 114  client: 89  local train loss: 0.9635\n",
      "global round: 114  client: 71  local train loss: 1.0279\n",
      "global round: 114  client: 18  local train loss: 1.2061\n",
      "global round: 114  client: 48  local train loss: 1.1543\n",
      "global round: 114  client: 76  local train loss: 1.0291\n",
      "global round: 114  client: 83  local train loss: 1.2045\n",
      "global round: 114  avg train loss:0.0968  global test loss: 0.9292  global test accu: 0.8405\n",
      "================================================================================================================\n",
      "global round: 115  client: 04  local train loss: 1.0201\n",
      "global round: 115  client: 17  local train loss: 1.2920\n",
      "global round: 115  client: 66  local train loss: 1.0586\n",
      "global round: 115  client: 25  local train loss: 1.1350\n",
      "global round: 115  client: 91  local train loss: 1.0307\n",
      "global round: 115  client: 97  local train loss: 1.0232\n",
      "global round: 115  client: 68  local train loss: 0.9533\n",
      "global round: 115  client: 89  local train loss: 0.9657\n",
      "global round: 115  client: 78  local train loss: 1.0454\n",
      "global round: 115  client: 06  local train loss: 1.3808\n",
      "global round: 115  avg train loss:0.0991  global test loss: 0.9277  global test accu: 0.8405\n",
      "================================================================================================================\n",
      "global round: 116  client: 73  local train loss: 1.0027\n",
      "global round: 116  client: 05  local train loss: 1.0303\n",
      "global round: 116  client: 96  local train loss: 1.0250\n",
      "global round: 116  client: 13  local train loss: 1.0384\n",
      "global round: 116  client: 16  local train loss: 1.0218\n",
      "global round: 116  client: 74  local train loss: 1.0282\n",
      "global round: 116  client: 06  local train loss: 1.0217\n",
      "global round: 116  client: 75  local train loss: 1.0556\n",
      "global round: 116  client: 55  local train loss: 1.0867\n",
      "global round: 116  client: 63  local train loss: 1.0326\n",
      "global round: 116  avg train loss:0.0940  global test loss: 0.9205  global test accu: 0.8414\n",
      "================================================================================================================\n",
      "global round: 117  client: 65  local train loss: 1.1428\n",
      "global round: 117  client: 49  local train loss: 1.0438\n",
      "global round: 117  client: 74  local train loss: 0.9806\n",
      "global round: 117  client: 41  local train loss: 1.1079\n",
      "global round: 117  client: 08  local train loss: 1.0335\n",
      "global round: 117  client: 09  local train loss: 0.9915\n",
      "global round: 117  client: 86  local train loss: 1.0265\n",
      "global round: 117  client: 55  local train loss: 1.0129\n",
      "global round: 117  client: 67  local train loss: 0.9737\n",
      "global round: 117  client: 69  local train loss: 1.0107\n",
      "global round: 117  avg train loss:0.0939  global test loss: 0.9141  global test accu: 0.8421\n",
      "================================================================================================================\n",
      "global round: 118  client: 04  local train loss: 1.0110\n",
      "global round: 118  client: 28  local train loss: 1.0654\n",
      "global round: 118  client: 88  local train loss: 1.0721\n",
      "global round: 118  client: 22  local train loss: 1.0223\n",
      "global round: 118  client: 73  local train loss: 0.9620\n",
      "global round: 118  client: 98  local train loss: 1.0094\n",
      "global round: 118  client: 80  local train loss: 1.1254\n",
      "global round: 118  client: 97  local train loss: 0.9998\n",
      "global round: 118  client: 40  local train loss: 1.0426\n",
      "global round: 118  client: 07  local train loss: 1.0038\n",
      "global round: 118  avg train loss:0.0938  global test loss: 0.9086  global test accu: 0.8426\n",
      "================================================================================================================\n",
      "global round: 119  client: 72  local train loss: 1.0514\n",
      "global round: 119  client: 30  local train loss: 0.9779\n",
      "global round: 119  client: 16  local train loss: 1.0134\n",
      "global round: 119  client: 87  local train loss: 1.0431\n",
      "global round: 119  client: 40  local train loss: 0.9964\n",
      "global round: 119  client: 84  local train loss: 0.9697\n",
      "global round: 119  client: 47  local train loss: 1.1620\n",
      "global round: 119  client: 48  local train loss: 1.0547\n",
      "global round: 119  client: 88  local train loss: 1.0111\n",
      "global round: 119  client: 63  local train loss: 1.0234\n",
      "global round: 119  avg train loss:0.0937  global test loss: 0.9029  global test accu: 0.8436\n",
      "================================================================================================================\n",
      "global round: 120  client: 49  local train loss: 1.0175\n",
      "global round: 120  client: 23  local train loss: 1.0224\n",
      "global round: 120  client: 51  local train loss: 1.0227\n",
      "global round: 120  client: 48  local train loss: 1.0412\n",
      "global round: 120  client: 82  local train loss: 1.0347\n",
      "global round: 120  client: 07  local train loss: 0.9898\n",
      "global round: 120  client: 41  local train loss: 1.0480\n",
      "global round: 120  client: 17  local train loss: 1.0330\n",
      "global round: 120  client: 87  local train loss: 0.9872\n",
      "global round: 120  client: 77  local train loss: 1.0616\n",
      "global round: 120  avg train loss:0.0933  global test loss: 0.8961  global test accu: 0.8441\n",
      "================================================================================================================\n",
      "global round: 121  client: 71  local train loss: 1.0071\n",
      "global round: 121  client: 25  local train loss: 1.0176\n",
      "global round: 121  client: 00  local train loss: 1.0490\n",
      "global round: 121  client: 94  local train loss: 1.0247\n",
      "global round: 121  client: 85  local train loss: 1.0685\n",
      "global round: 121  client: 88  local train loss: 1.0088\n",
      "global round: 121  client: 26  local train loss: 1.0489\n",
      "global round: 121  client: 14  local train loss: 1.0657\n",
      "global round: 121  client: 48  local train loss: 1.0275\n",
      "global round: 121  client: 77  local train loss: 1.0351\n",
      "global round: 121  avg train loss:0.0941  global test loss: 0.8923  global test accu: 0.8445\n",
      "================================================================================================================\n",
      "global round: 122  client: 51  local train loss: 0.9953\n",
      "global round: 122  client: 85  local train loss: 0.9868\n",
      "global round: 122  client: 30  local train loss: 0.9561\n",
      "global round: 122  client: 60  local train loss: 1.1068\n",
      "global round: 122  client: 80  local train loss: 1.0192\n",
      "global round: 122  client: 78  local train loss: 1.0159\n",
      "global round: 122  client: 69  local train loss: 0.9711\n",
      "global round: 122  client: 47  local train loss: 1.0259\n",
      "global round: 122  client: 00  local train loss: 0.9443\n",
      "global round: 122  client: 93  local train loss: 1.0113\n",
      "global round: 122  avg train loss:0.0912  global test loss: 0.8860  global test accu: 0.8454\n",
      "================================================================================================================\n",
      "global round: 123  client: 43  local train loss: 1.0122\n",
      "global round: 123  client: 55  local train loss: 0.9990\n",
      "global round: 123  client: 82  local train loss: 0.9955\n",
      "global round: 123  client: 30  local train loss: 0.9463\n",
      "global round: 123  client: 00  local train loss: 0.9295\n",
      "global round: 123  client: 54  local train loss: 1.0399\n",
      "global round: 123  client: 91  local train loss: 0.9853\n",
      "global round: 123  client: 65  local train loss: 1.0555\n",
      "global round: 123  client: 39  local train loss: 1.0083\n",
      "global round: 123  client: 07  local train loss: 0.9836\n",
      "global round: 123  avg train loss:0.0905  global test loss: 0.8799  global test accu: 0.8460\n",
      "================================================================================================================\n",
      "global round: 124  client: 15  local train loss: 1.0366\n",
      "global round: 124  client: 64  local train loss: 1.0353\n",
      "global round: 124  client: 59  local train loss: 1.0797\n",
      "global round: 124  client: 47  local train loss: 1.0039\n",
      "global round: 124  client: 49  local train loss: 0.9936\n",
      "global round: 124  client: 90  local train loss: 1.1259\n",
      "global round: 124  client: 60  local train loss: 0.9797\n",
      "global round: 124  client: 69  local train loss: 0.9448\n",
      "global round: 124  client: 81  local train loss: 0.9937\n",
      "global round: 124  client: 75  local train loss: 1.0166\n",
      "global round: 124  avg train loss:0.0928  global test loss: 0.8761  global test accu: 0.8466\n",
      "================================================================================================================\n",
      "global round: 125  client: 58  local train loss: 1.0213\n",
      "global round: 125  client: 18  local train loss: 0.9813\n",
      "global round: 125  client: 33  local train loss: 1.0191\n",
      "global round: 125  client: 74  local train loss: 0.9781\n",
      "global round: 125  client: 13  local train loss: 1.0199\n",
      "global round: 125  client: 64  local train loss: 0.9813\n",
      "global round: 125  client: 71  local train loss: 0.9778\n",
      "global round: 125  client: 82  local train loss: 0.9868\n",
      "global round: 125  client: 84  local train loss: 0.9518\n",
      "global round: 125  client: 95  local train loss: 0.9967\n",
      "global round: 125  avg train loss:0.0901  global test loss: 0.8712  global test accu: 0.8467\n",
      "================================================================================================================\n",
      "global round: 126  client: 02  local train loss: 1.0875\n",
      "global round: 126  client: 41  local train loss: 1.0352\n",
      "global round: 126  client: 40  local train loss: 0.9955\n",
      "global round: 126  client: 84  local train loss: 0.9149\n",
      "global round: 126  client: 85  local train loss: 0.9834\n",
      "global round: 126  client: 42  local train loss: 0.9912\n",
      "global round: 126  client: 28  local train loss: 0.9985\n",
      "global round: 126  client: 61  local train loss: 1.0337\n",
      "global round: 126  client: 35  local train loss: 1.0276\n",
      "global round: 126  client: 66  local train loss: 1.0252\n",
      "global round: 126  avg train loss:0.0918  global test loss: 0.8672  global test accu: 0.8470\n",
      "================================================================================================================\n",
      "global round: 127  client: 25  local train loss: 0.9862\n",
      "global round: 127  client: 79  local train loss: 1.2924\n",
      "global round: 127  client: 57  local train loss: 0.9631\n",
      "global round: 127  client: 20  local train loss: 1.0439\n",
      "global round: 127  client: 96  local train loss: 0.9994\n",
      "global round: 127  client: 44  local train loss: 1.0961\n",
      "global round: 127  client: 72  local train loss: 0.9925\n",
      "global round: 127  client: 14  local train loss: 0.9308\n",
      "global round: 127  client: 47  local train loss: 0.9988\n",
      "global round: 127  client: 86  local train loss: 1.0075\n",
      "global round: 127  avg train loss:0.0937  global test loss: 0.8654  global test accu: 0.8474\n",
      "================================================================================================================\n",
      "global round: 128  client: 23  local train loss: 0.9703\n",
      "global round: 128  client: 94  local train loss: 0.9696\n",
      "global round: 128  client: 67  local train loss: 0.9677\n",
      "global round: 128  client: 11  local train loss: 0.9882\n",
      "global round: 128  client: 16  local train loss: 1.0094\n",
      "global round: 128  client: 08  local train loss: 1.0159\n",
      "global round: 128  client: 82  local train loss: 0.9884\n",
      "global round: 128  client: 00  local train loss: 0.9211\n",
      "global round: 128  client: 06  local train loss: 1.0286\n",
      "global round: 128  client: 83  local train loss: 1.0302\n",
      "global round: 128  avg train loss:0.0899  global test loss: 0.8606  global test accu: 0.8477\n",
      "================================================================================================================\n",
      "global round: 129  client: 83  local train loss: 0.9723\n",
      "global round: 129  client: 93  local train loss: 0.9673\n",
      "global round: 129  client: 67  local train loss: 0.9194\n",
      "global round: 129  client: 51  local train loss: 0.9850\n",
      "global round: 129  client: 43  local train loss: 0.9506\n",
      "global round: 129  client: 29  local train loss: 1.0557\n",
      "global round: 129  client: 61  local train loss: 0.9606\n",
      "global round: 129  client: 20  local train loss: 0.9979\n",
      "global round: 129  client: 05  local train loss: 1.0248\n",
      "global round: 129  client: 47  local train loss: 0.9911\n",
      "global round: 129  avg train loss:0.0893  global test loss: 0.8546  global test accu: 0.8488\n",
      "================================================================================================================\n",
      "global round: 130  client: 31  local train loss: 1.0794\n",
      "global round: 130  client: 96  local train loss: 0.9562\n",
      "global round: 130  client: 48  local train loss: 1.0269\n",
      "global round: 130  client: 49  local train loss: 0.9777\n",
      "global round: 130  client: 29  local train loss: 0.9866\n",
      "global round: 130  client: 05  local train loss: 0.9734\n",
      "global round: 130  client: 88  local train loss: 0.9934\n",
      "global round: 130  client: 94  local train loss: 0.9419\n",
      "global round: 130  client: 80  local train loss: 0.9951\n",
      "global round: 130  client: 13  local train loss: 0.9866\n",
      "global round: 130  avg train loss:0.0902  global test loss: 0.8491  global test accu: 0.8498\n",
      "================================================================================================================\n",
      "global round: 131  client: 76  local train loss: 1.0293\n",
      "global round: 131  client: 65  local train loss: 1.0301\n",
      "global round: 131  client: 49  local train loss: 0.9597\n",
      "global round: 131  client: 66  local train loss: 0.9733\n",
      "global round: 131  client: 47  local train loss: 0.9844\n",
      "global round: 131  client: 56  local train loss: 1.0595\n",
      "global round: 131  client: 35  local train loss: 0.9686\n",
      "global round: 131  client: 84  local train loss: 0.9131\n",
      "global round: 131  client: 21  local train loss: 1.0511\n",
      "global round: 131  client: 14  local train loss: 0.9254\n",
      "global round: 131  avg train loss:0.0900  global test loss: 0.8448  global test accu: 0.8503\n",
      "================================================================================================================\n",
      "global round: 132  client: 32  local train loss: 1.0164\n",
      "global round: 132  client: 80  local train loss: 0.9730\n",
      "global round: 132  client: 76  local train loss: 0.9653\n",
      "global round: 132  client: 50  local train loss: 1.0315\n",
      "global round: 132  client: 88  local train loss: 0.9602\n",
      "global round: 132  client: 93  local train loss: 0.9484\n",
      "global round: 132  client: 89  local train loss: 0.9632\n",
      "global round: 132  client: 49  local train loss: 0.9482\n",
      "global round: 132  client: 75  local train loss: 0.9774\n",
      "global round: 132  client: 69  local train loss: 0.9325\n",
      "global round: 132  avg train loss:0.0883  global test loss: 0.8399  global test accu: 0.8506\n",
      "================================================================================================================\n",
      "global round: 133  client: 83  local train loss: 0.9774\n",
      "global round: 133  client: 01  local train loss: 1.0188\n",
      "global round: 133  client: 58  local train loss: 0.9559\n",
      "global round: 133  client: 29  local train loss: 0.9863\n",
      "global round: 133  client: 81  local train loss: 0.9364\n",
      "global round: 133  client: 06  local train loss: 0.9698\n",
      "global round: 133  client: 19  local train loss: 1.0400\n",
      "global round: 133  client: 41  local train loss: 1.0109\n",
      "global round: 133  client: 17  local train loss: 1.0314\n",
      "global round: 133  client: 46  local train loss: 1.1157\n",
      "global round: 133  avg train loss:0.0913  global test loss: 0.8377  global test accu: 0.8510\n",
      "================================================================================================================\n",
      "global round: 134  client: 34  local train loss: 1.0460\n",
      "global round: 134  client: 29  local train loss: 0.9642\n",
      "global round: 134  client: 90  local train loss: 0.9982\n",
      "global round: 134  client: 91  local train loss: 0.9409\n",
      "global round: 134  client: 57  local train loss: 0.9111\n",
      "global round: 134  client: 31  local train loss: 0.9769\n",
      "global round: 134  client: 06  local train loss: 0.9665\n",
      "global round: 134  client: 16  local train loss: 0.9651\n",
      "global round: 134  client: 52  local train loss: 1.0150\n",
      "global round: 134  client: 20  local train loss: 0.9873\n",
      "global round: 134  avg train loss:0.0888  global test loss: 0.8330  global test accu: 0.8515\n",
      "================================================================================================================\n",
      "global round: 135  client: 87  local train loss: 0.9743\n",
      "global round: 135  client: 89  local train loss: 0.8952\n",
      "global round: 135  client: 14  local train loss: 0.9102\n",
      "global round: 135  client: 49  local train loss: 0.9466\n",
      "global round: 135  client: 92  local train loss: 1.0798\n",
      "global round: 135  client: 91  local train loss: 0.9100\n",
      "global round: 135  client: 50  local train loss: 0.9535\n",
      "global round: 135  client: 32  local train loss: 0.9413\n",
      "global round: 135  client: 36  local train loss: 0.9728\n",
      "global round: 135  client: 93  local train loss: 0.9352\n",
      "global round: 135  avg train loss:0.0865  global test loss: 0.8286  global test accu: 0.8517\n",
      "================================================================================================================\n",
      "global round: 136  client: 45  local train loss: 1.0230\n",
      "global round: 136  client: 15  local train loss: 0.9691\n",
      "global round: 136  client: 98  local train loss: 0.9746\n",
      "global round: 136  client: 60  local train loss: 0.9726\n",
      "global round: 136  client: 51  local train loss: 0.9612\n",
      "global round: 136  client: 40  local train loss: 0.9649\n",
      "global round: 136  client: 82  local train loss: 0.9708\n",
      "global round: 136  client: 75  local train loss: 0.9621\n",
      "global round: 136  client: 21  local train loss: 0.9824\n",
      "global round: 136  client: 68  local train loss: 0.9522\n",
      "global round: 136  avg train loss:0.0885  global test loss: 0.8252  global test accu: 0.8518\n",
      "================================================================================================================\n",
      "global round: 137  client: 89  local train loss: 0.8875\n",
      "global round: 137  client: 24  local train loss: 1.0744\n",
      "global round: 137  client: 46  local train loss: 0.9187\n",
      "global round: 137  client: 66  local train loss: 0.9572\n",
      "global round: 137  client: 98  local train loss: 0.9063\n",
      "global round: 137  client: 62  local train loss: 0.9915\n",
      "global round: 137  client: 04  local train loss: 0.9968\n",
      "global round: 137  client: 74  local train loss: 0.9391\n",
      "global round: 137  client: 63  local train loss: 1.0132\n",
      "global round: 137  client: 19  local train loss: 0.9249\n",
      "global round: 137  avg train loss:0.0874  global test loss: 0.8224  global test accu: 0.8520\n",
      "================================================================================================================\n",
      "global round: 138  client: 68  local train loss: 0.8723\n",
      "global round: 138  client: 31  local train loss: 0.9615\n",
      "global round: 138  client: 82  local train loss: 0.9547\n",
      "global round: 138  client: 61  local train loss: 0.9538\n",
      "global round: 138  client: 65  local train loss: 1.0024\n",
      "global round: 138  client: 13  local train loss: 0.9764\n",
      "global round: 138  client: 79  local train loss: 0.9548\n",
      "global round: 138  client: 95  local train loss: 0.9530\n",
      "global round: 138  client: 00  local train loss: 0.9194\n",
      "global round: 138  client: 75  local train loss: 0.9457\n",
      "global round: 138  avg train loss:0.0863  global test loss: 0.8172  global test accu: 0.8519\n",
      "================================================================================================================\n",
      "global round: 139  client: 75  local train loss: 0.9262\n",
      "global round: 139  client: 24  local train loss: 0.9186\n",
      "global round: 139  client: 88  local train loss: 0.9459\n",
      "global round: 139  client: 00  local train loss: 0.8754\n",
      "global round: 139  client: 63  local train loss: 0.9354\n",
      "global round: 139  client: 56  local train loss: 0.9336\n",
      "global round: 139  client: 92  local train loss: 0.9519\n",
      "global round: 139  client: 37  local train loss: 1.0050\n",
      "global round: 139  client: 20  local train loss: 0.9699\n",
      "global round: 139  client: 89  local train loss: 0.8851\n",
      "global round: 139  avg train loss:0.0850  global test loss: 0.8118  global test accu: 0.8525\n",
      "================================================================================================================\n",
      "global round: 140  client: 78  local train loss: 0.9785\n",
      "global round: 140  client: 52  local train loss: 0.9324\n",
      "global round: 140  client: 23  local train loss: 0.9476\n",
      "global round: 140  client: 95  local train loss: 0.9107\n",
      "global round: 140  client: 64  local train loss: 0.9755\n",
      "global round: 140  client: 79  local train loss: 0.9174\n",
      "global round: 140  client: 20  local train loss: 0.9502\n",
      "global round: 140  client: 71  local train loss: 0.9520\n",
      "global round: 140  client: 48  local train loss: 0.9925\n",
      "global round: 140  client: 56  local train loss: 0.9124\n",
      "global round: 140  avg train loss:0.0861  global test loss: 0.8076  global test accu: 0.8527\n",
      "================================================================================================================\n",
      "global round: 141  client: 02  local train loss: 0.9730\n",
      "global round: 141  client: 39  local train loss: 0.9706\n",
      "global round: 141  client: 10  local train loss: 1.0546\n",
      "global round: 141  client: 62  local train loss: 0.9084\n",
      "global round: 141  client: 73  local train loss: 0.9558\n",
      "global round: 141  client: 61  local train loss: 0.9288\n",
      "global round: 141  client: 15  local train loss: 0.9304\n",
      "global round: 141  client: 31  local train loss: 0.9429\n",
      "global round: 141  client: 81  local train loss: 0.9037\n",
      "global round: 141  client: 48  local train loss: 0.9626\n",
      "global round: 141  avg train loss:0.0866  global test loss: 0.8047  global test accu: 0.8533\n",
      "================================================================================================================\n",
      "global round: 142  client: 66  local train loss: 0.9371\n",
      "global round: 142  client: 62  local train loss: 0.8896\n",
      "global round: 142  client: 44  local train loss: 0.9841\n",
      "global round: 142  client: 89  local train loss: 0.8681\n",
      "global round: 142  client: 43  local train loss: 0.9397\n",
      "global round: 142  client: 80  local train loss: 0.9577\n",
      "global round: 142  client: 69  local train loss: 0.9006\n",
      "global round: 142  client: 12  local train loss: 1.0414\n",
      "global round: 142  client: 19  local train loss: 0.8997\n",
      "global round: 142  client: 95  local train loss: 0.9095\n",
      "global round: 142  avg train loss:0.0848  global test loss: 0.8010  global test accu: 0.8538\n",
      "================================================================================================================\n",
      "global round: 143  client: 64  local train loss: 0.9174\n",
      "global round: 143  client: 87  local train loss: 0.9292\n",
      "global round: 143  client: 97  local train loss: 0.9761\n",
      "global round: 143  client: 16  local train loss: 0.9412\n",
      "global round: 143  client: 34  local train loss: 0.9505\n",
      "global round: 143  client: 79  local train loss: 0.9169\n",
      "global round: 143  client: 40  local train loss: 0.9337\n",
      "global round: 143  client: 63  local train loss: 0.9391\n",
      "global round: 143  client: 43  local train loss: 0.8926\n",
      "global round: 143  client: 91  local train loss: 0.9079\n",
      "global round: 143  avg train loss:0.0846  global test loss: 0.7967  global test accu: 0.8537\n",
      "================================================================================================================\n",
      "global round: 144  client: 90  local train loss: 0.9693\n",
      "global round: 144  client: 04  local train loss: 0.9248\n",
      "global round: 144  client: 65  local train loss: 0.9730\n",
      "global round: 144  client: 57  local train loss: 0.8857\n",
      "global round: 144  client: 73  local train loss: 0.8747\n",
      "global round: 144  client: 25  local train loss: 0.9739\n",
      "global round: 144  client: 17  local train loss: 0.9767\n",
      "global round: 144  client: 49  local train loss: 0.9413\n",
      "global round: 144  client: 22  local train loss: 0.9718\n",
      "global round: 144  client: 82  local train loss: 0.9428\n",
      "global round: 144  avg train loss:0.0858  global test loss: 0.7932  global test accu: 0.8540\n",
      "================================================================================================================\n",
      "global round: 145  client: 86  local train loss: 0.9626\n",
      "global round: 145  client: 76  local train loss: 0.9650\n",
      "global round: 145  client: 48  local train loss: 0.9522\n",
      "global round: 145  client: 57  local train loss: 0.8510\n",
      "global round: 145  client: 69  local train loss: 0.8731\n",
      "global round: 145  client: 91  local train loss: 0.8812\n",
      "global round: 145  client: 08  local train loss: 0.9714\n",
      "global round: 145  client: 88  local train loss: 0.9233\n",
      "global round: 145  client: 65  local train loss: 0.9614\n",
      "global round: 145  client: 45  local train loss: 0.9207\n",
      "global round: 145  avg train loss:0.0842  global test loss: 0.7887  global test accu: 0.8545\n",
      "================================================================================================================\n",
      "global round: 146  client: 63  local train loss: 0.9286\n",
      "global round: 146  client: 64  local train loss: 0.9178\n",
      "global round: 146  client: 91  local train loss: 0.8671\n",
      "global round: 146  client: 49  local train loss: 0.9002\n",
      "global round: 146  client: 38  local train loss: 1.0341\n",
      "global round: 146  client: 94  local train loss: 0.9342\n",
      "global round: 146  client: 84  local train loss: 0.9000\n",
      "global round: 146  client: 81  local train loss: 0.8733\n",
      "global round: 146  client: 37  local train loss: 0.9021\n",
      "global round: 146  client: 19  local train loss: 0.8897\n",
      "global round: 146  avg train loss:0.0832  global test loss: 0.7848  global test accu: 0.8546\n",
      "================================================================================================================\n",
      "global round: 147  client: 71  local train loss: 0.9098\n",
      "global round: 147  client: 15  local train loss: 0.9148\n",
      "global round: 147  client: 52  local train loss: 0.9168\n",
      "global round: 147  client: 04  local train loss: 0.9065\n",
      "global round: 147  client: 00  local train loss: 0.8767\n",
      "global round: 147  client: 47  local train loss: 0.9732\n",
      "global round: 147  client: 14  local train loss: 0.8865\n",
      "global round: 147  client: 93  local train loss: 0.9342\n",
      "global round: 147  client: 08  local train loss: 0.9196\n",
      "global round: 147  client: 59  local train loss: 0.9691\n",
      "global round: 147  avg train loss:0.0837  global test loss: 0.7812  global test accu: 0.8559\n",
      "================================================================================================================\n",
      "global round: 148  client: 03  local train loss: 0.9735\n",
      "global round: 148  client: 54  local train loss: 0.9949\n",
      "global round: 148  client: 76  local train loss: 0.9271\n",
      "global round: 148  client: 50  local train loss: 0.9544\n",
      "global round: 148  client: 04  local train loss: 0.8919\n",
      "global round: 148  client: 12  local train loss: 0.9143\n",
      "global round: 148  client: 79  local train loss: 0.9047\n",
      "global round: 148  client: 11  local train loss: 0.9241\n",
      "global round: 148  client: 67  local train loss: 0.9059\n",
      "global round: 148  client: 74  local train loss: 0.9051\n",
      "global round: 148  avg train loss:0.0845  global test loss: 0.7790  global test accu: 0.8565\n",
      "================================================================================================================\n",
      "global round: 149  client: 76  local train loss: 0.9110\n",
      "global round: 149  client: 78  local train loss: 0.9107\n",
      "global round: 149  client: 74  local train loss: 0.8633\n",
      "global round: 149  client: 73  local train loss: 0.8660\n",
      "global round: 149  client: 41  local train loss: 0.9879\n",
      "global round: 149  client: 08  local train loss: 0.9139\n",
      "global round: 149  client: 25  local train loss: 0.9115\n",
      "global round: 149  client: 49  local train loss: 0.8999\n",
      "global round: 149  client: 68  local train loss: 0.8649\n",
      "global round: 149  client: 01  local train loss: 0.9353\n",
      "global round: 149  avg train loss:0.0824  global test loss: 0.7744  global test accu: 0.8568\n",
      "================================================================================================================\n",
      "global round: 150  client: 58  local train loss: 0.9273\n",
      "global round: 150  client: 62  local train loss: 0.8848\n",
      "global round: 150  client: 70  local train loss: 1.0090\n",
      "global round: 150  client: 84  local train loss: 0.8516\n",
      "global round: 150  client: 01  local train loss: 0.8825\n",
      "global round: 150  client: 89  local train loss: 0.8635\n",
      "global round: 150  client: 10  local train loss: 0.9077\n",
      "global round: 150  client: 13  local train loss: 0.9391\n",
      "global round: 150  client: 53  local train loss: 1.0528\n",
      "global round: 150  client: 39  local train loss: 0.9129\n",
      "global round: 150  avg train loss:0.0839  global test loss: 0.7728  global test accu: 0.8571\n",
      "================================================================================================================\n",
      "global round: 151  client: 74  local train loss: 0.8630\n",
      "global round: 151  client: 58  local train loss: 0.8838\n",
      "global round: 151  client: 54  local train loss: 0.9263\n",
      "global round: 151  client: 29  local train loss: 0.9640\n",
      "global round: 151  client: 26  local train loss: 0.9468\n",
      "global round: 151  client: 85  local train loss: 0.9615\n",
      "global round: 151  client: 22  local train loss: 0.8947\n",
      "global round: 151  client: 00  local train loss: 0.8386\n",
      "global round: 151  client: 82  local train loss: 0.9236\n",
      "global round: 151  client: 24  local train loss: 0.9017\n",
      "global round: 151  avg train loss:0.0828  global test loss: 0.7697  global test accu: 0.8570\n",
      "================================================================================================================\n",
      "global round: 152  client: 59  local train loss: 0.9022\n",
      "global round: 152  client: 40  local train loss: 0.9034\n",
      "global round: 152  client: 42  local train loss: 0.9386\n",
      "global round: 152  client: 28  local train loss: 0.9676\n",
      "global round: 152  client: 81  local train loss: 0.8510\n",
      "global round: 152  client: 16  local train loss: 0.9178\n",
      "global round: 152  client: 45  local train loss: 0.8902\n",
      "global round: 152  client: 70  local train loss: 0.8463\n",
      "global round: 152  client: 96  local train loss: 0.9454\n",
      "global round: 152  client: 50  local train loss: 0.9268\n",
      "global round: 152  avg train loss:0.0826  global test loss: 0.7666  global test accu: 0.8574\n",
      "================================================================================================================\n",
      "global round: 153  client: 96  local train loss: 0.8684\n",
      "global round: 153  client: 48  local train loss: 0.9398\n",
      "global round: 153  client: 70  local train loss: 0.8338\n",
      "global round: 153  client: 81  local train loss: 0.8371\n",
      "global round: 153  client: 51  local train loss: 0.9336\n",
      "global round: 153  client: 78  local train loss: 0.8869\n",
      "global round: 153  client: 17  local train loss: 0.9307\n",
      "global round: 153  client: 15  local train loss: 0.8954\n",
      "global round: 153  client: 43  local train loss: 0.8971\n",
      "global round: 153  client: 84  local train loss: 0.8374\n",
      "global round: 153  avg train loss:0.0805  global test loss: 0.7620  global test accu: 0.8580\n",
      "================================================================================================================\n",
      "global round: 154  client: 00  local train loss: 0.8405\n",
      "global round: 154  client: 44  local train loss: 0.9336\n",
      "global round: 154  client: 96  local train loss: 0.8677\n",
      "global round: 154  client: 74  local train loss: 0.8638\n",
      "global round: 154  client: 55  local train loss: 0.9717\n",
      "global round: 154  client: 97  local train loss: 0.8842\n",
      "global round: 154  client: 52  local train loss: 0.8944\n",
      "global round: 154  client: 68  local train loss: 0.8278\n",
      "global round: 154  client: 77  local train loss: 1.0250\n",
      "global round: 154  client: 19  local train loss: 0.8786\n",
      "global round: 154  avg train loss:0.0817  global test loss: 0.7591  global test accu: 0.8584\n",
      "================================================================================================================\n",
      "global round: 155  client: 76  local train loss: 0.9183\n",
      "global round: 155  client: 20  local train loss: 0.9563\n",
      "global round: 155  client: 81  local train loss: 0.8321\n",
      "global round: 155  client: 33  local train loss: 0.9529\n",
      "global round: 155  client: 79  local train loss: 0.8846\n",
      "global round: 155  client: 61  local train loss: 0.9130\n",
      "global round: 155  client: 27  local train loss: 1.1411\n",
      "global round: 155  client: 73  local train loss: 0.8482\n",
      "global round: 155  client: 72  local train loss: 0.9634\n",
      "global round: 155  client: 67  local train loss: 0.8441\n",
      "global round: 155  avg train loss:0.0841  global test loss: 0.7584  global test accu: 0.8584\n",
      "================================================================================================================\n",
      "global round: 156  client: 98  local train loss: 0.9115\n",
      "global round: 156  client: 93  local train loss: 0.8871\n",
      "global round: 156  client: 37  local train loss: 0.8715\n",
      "global round: 156  client: 03  local train loss: 0.8667\n",
      "global round: 156  client: 56  local train loss: 0.9093\n",
      "global round: 156  client: 39  local train loss: 0.8816\n",
      "global round: 156  client: 55  local train loss: 0.8643\n",
      "global round: 156  client: 81  local train loss: 0.8284\n",
      "global round: 156  client: 99  local train loss: 1.0119\n",
      "global round: 156  client: 14  local train loss: 0.8548\n",
      "global round: 156  avg train loss:0.0808  global test loss: 0.7556  global test accu: 0.8584\n",
      "================================================================================================================\n",
      "global round: 157  client: 95  local train loss: 0.8974\n",
      "global round: 157  client: 51  local train loss: 0.8885\n",
      "global round: 157  client: 12  local train loss: 0.9049\n",
      "global round: 157  client: 11  local train loss: 0.8566\n",
      "global round: 157  client: 28  local train loss: 0.8735\n",
      "global round: 157  client: 75  local train loss: 0.9197\n",
      "global round: 157  client: 21  local train loss: 0.9647\n",
      "global round: 157  client: 14  local train loss: 0.8211\n",
      "global round: 157  client: 08  local train loss: 0.9108\n",
      "global round: 157  client: 73  local train loss: 0.8289\n",
      "global round: 157  avg train loss:0.0806  global test loss: 0.7519  global test accu: 0.8590\n",
      "================================================================================================================\n",
      "global round: 158  client: 36  local train loss: 0.8966\n",
      "global round: 158  client: 90  local train loss: 0.9292\n",
      "global round: 158  client: 92  local train loss: 0.9411\n",
      "global round: 158  client: 16  local train loss: 0.8810\n",
      "global round: 158  client: 40  local train loss: 0.8871\n",
      "global round: 158  client: 64  local train loss: 0.8990\n",
      "global round: 158  client: 10  local train loss: 0.8941\n",
      "global round: 158  client: 21  local train loss: 0.9069\n",
      "global round: 158  client: 03  local train loss: 0.8408\n",
      "global round: 158  client: 75  local train loss: 0.8769\n",
      "global round: 158  avg train loss:0.0814  global test loss: 0.7486  global test accu: 0.8590\n",
      "================================================================================================================\n",
      "global round: 159  client: 57  local train loss: 0.8509\n",
      "global round: 159  client: 99  local train loss: 0.8526\n",
      "global round: 159  client: 43  local train loss: 0.8669\n",
      "global round: 159  client: 20  local train loss: 0.9113\n",
      "global round: 159  client: 28  local train loss: 0.8697\n",
      "global round: 159  client: 70  local train loss: 0.8343\n",
      "global round: 159  client: 03  local train loss: 0.8456\n",
      "global round: 159  client: 16  local train loss: 0.8754\n",
      "global round: 159  client: 19  local train loss: 0.8506\n",
      "global round: 159  client: 91  local train loss: 0.8775\n",
      "global round: 159  avg train loss:0.0785  global test loss: 0.7440  global test accu: 0.8592\n",
      "================================================================================================================\n",
      "global round: 160  client: 76  local train loss: 0.9064\n",
      "global round: 160  client: 86  local train loss: 0.9073\n",
      "global round: 160  client: 39  local train loss: 0.8771\n",
      "global round: 160  client: 03  local train loss: 0.8301\n",
      "global round: 160  client: 61  local train loss: 0.8791\n",
      "global round: 160  client: 71  local train loss: 0.8893\n",
      "global round: 160  client: 16  local train loss: 0.8676\n",
      "global round: 160  client: 40  local train loss: 0.8736\n",
      "global round: 160  client: 09  local train loss: 0.9862\n",
      "global round: 160  client: 34  local train loss: 0.9259\n",
      "global round: 160  avg train loss:0.0813  global test loss: 0.7412  global test accu: 0.8597\n",
      "================================================================================================================\n",
      "global round: 161  client: 53  local train loss: 0.9121\n",
      "global round: 161  client: 72  local train loss: 0.8791\n",
      "global round: 161  client: 57  local train loss: 0.8033\n",
      "global round: 161  client: 32  local train loss: 0.9380\n",
      "global round: 161  client: 12  local train loss: 0.8792\n",
      "global round: 161  client: 36  local train loss: 0.8299\n",
      "global round: 161  client: 51  local train loss: 0.8846\n",
      "global round: 161  client: 85  local train loss: 0.8809\n",
      "global round: 161  client: 99  local train loss: 0.8446\n",
      "global round: 161  client: 86  local train loss: 0.8661\n",
      "global round: 161  avg train loss:0.0793  global test loss: 0.7373  global test accu: 0.8599\n",
      "================================================================================================================\n",
      "global round: 162  client: 67  local train loss: 0.8275\n",
      "global round: 162  client: 61  local train loss: 0.8574\n",
      "global round: 162  client: 64  local train loss: 0.8799\n",
      "global round: 162  client: 78  local train loss: 0.8689\n",
      "global round: 162  client: 44  local train loss: 0.9045\n",
      "global round: 162  client: 27  local train loss: 0.8513\n",
      "global round: 162  client: 76  local train loss: 0.8883\n",
      "global round: 162  client: 83  local train loss: 0.9624\n",
      "global round: 162  client: 99  local train loss: 0.8311\n",
      "global round: 162  client: 35  local train loss: 0.9595\n",
      "global round: 162  avg train loss:0.0803  global test loss: 0.7343  global test accu: 0.8600\n",
      "================================================================================================================\n",
      "global round: 163  client: 07  local train loss: 0.9685\n",
      "global round: 163  client: 17  local train loss: 0.9113\n",
      "global round: 163  client: 01  local train loss: 0.8801\n",
      "global round: 163  client: 98  local train loss: 0.8583\n",
      "global round: 163  client: 42  local train loss: 0.8594\n",
      "global round: 163  client: 29  local train loss: 0.9161\n",
      "global round: 163  client: 85  local train loss: 0.8614\n",
      "global round: 163  client: 24  local train loss: 0.8686\n",
      "global round: 163  client: 84  local train loss: 0.8285\n",
      "global round: 163  client: 55  local train loss: 0.8657\n",
      "global round: 163  avg train loss:0.0802  global test loss: 0.7319  global test accu: 0.8601\n",
      "================================================================================================================\n",
      "global round: 164  client: 15  local train loss: 0.8780\n",
      "global round: 164  client: 04  local train loss: 0.9045\n",
      "global round: 164  client: 32  local train loss: 0.8598\n",
      "global round: 164  client: 33  local train loss: 0.8628\n",
      "global round: 164  client: 52  local train loss: 0.8892\n",
      "global round: 164  client: 02  local train loss: 0.9333\n",
      "global round: 164  client: 74  local train loss: 0.8434\n",
      "global round: 164  client: 81  local train loss: 0.8398\n",
      "global round: 164  client: 51  local train loss: 0.8663\n",
      "global round: 164  client: 56  local train loss: 0.8712\n",
      "global round: 164  avg train loss:0.0795  global test loss: 0.7290  global test accu: 0.8602\n",
      "================================================================================================================\n",
      "global round: 165  client: 94  local train loss: 0.8735\n",
      "global round: 165  client: 19  local train loss: 0.8335\n",
      "global round: 165  client: 74  local train loss: 0.8258\n",
      "global round: 165  client: 27  local train loss: 0.8430\n",
      "global round: 165  client: 66  local train loss: 0.9179\n",
      "global round: 165  client: 15  local train loss: 0.8424\n",
      "global round: 165  client: 03  local train loss: 0.8355\n",
      "global round: 165  client: 62  local train loss: 0.8652\n",
      "global round: 165  client: 86  local train loss: 0.8685\n",
      "global round: 165  client: 87  local train loss: 0.9084\n",
      "global round: 165  avg train loss:0.0783  global test loss: 0.7261  global test accu: 0.8602\n",
      "================================================================================================================\n",
      "global round: 166  client: 01  local train loss: 0.8484\n",
      "global round: 166  client: 51  local train loss: 0.8579\n",
      "global round: 166  client: 37  local train loss: 0.8538\n",
      "global round: 166  client: 49  local train loss: 0.8947\n",
      "global round: 166  client: 30  local train loss: 0.9407\n",
      "global round: 166  client: 99  local train loss: 0.8465\n",
      "global round: 166  client: 26  local train loss: 0.8402\n",
      "global round: 166  client: 06  local train loss: 0.9518\n",
      "global round: 166  client: 05  local train loss: 0.9652\n",
      "global round: 166  client: 59  local train loss: 0.8866\n",
      "global round: 166  avg train loss:0.0808  global test loss: 0.7251  global test accu: 0.8608\n",
      "================================================================================================================\n",
      "global round: 167  client: 45  local train loss: 0.8822\n",
      "global round: 167  client: 88  local train loss: 0.9159\n",
      "global round: 167  client: 29  local train loss: 0.8851\n",
      "global round: 167  client: 20  local train loss: 0.9092\n",
      "global round: 167  client: 55  local train loss: 0.8496\n",
      "global round: 167  client: 37  local train loss: 0.8274\n",
      "global round: 167  client: 97  local train loss: 0.8577\n",
      "global round: 167  client: 63  local train loss: 0.9120\n",
      "global round: 167  client: 22  local train loss: 0.8581\n",
      "global round: 167  client: 32  local train loss: 0.8540\n",
      "global round: 167  avg train loss:0.0796  global test loss: 0.7221  global test accu: 0.8613\n",
      "================================================================================================================\n",
      "global round: 168  client: 62  local train loss: 0.8283\n",
      "global round: 168  client: 91  local train loss: 0.8428\n",
      "global round: 168  client: 99  local train loss: 0.8209\n",
      "global round: 168  client: 82  local train loss: 0.9032\n",
      "global round: 168  client: 59  local train loss: 0.8666\n",
      "global round: 168  client: 38  local train loss: 0.8975\n",
      "global round: 168  client: 48  local train loss: 0.9222\n",
      "global round: 168  client: 57  local train loss: 0.8027\n",
      "global round: 168  client: 23  local train loss: 0.8991\n",
      "global round: 168  client: 20  local train loss: 0.8795\n",
      "global round: 168  avg train loss:0.0788  global test loss: 0.7193  global test accu: 0.8615\n",
      "================================================================================================================\n",
      "global round: 169  client: 32  local train loss: 0.8476\n",
      "global round: 169  client: 29  local train loss: 0.8787\n",
      "global round: 169  client: 88  local train loss: 0.8495\n",
      "global round: 169  client: 44  local train loss: 0.8768\n",
      "global round: 169  client: 95  local train loss: 0.8605\n",
      "global round: 169  client: 37  local train loss: 0.8316\n",
      "global round: 169  client: 43  local train loss: 0.8474\n",
      "global round: 169  client: 20  local train loss: 0.8836\n",
      "global round: 169  client: 62  local train loss: 0.8179\n",
      "global round: 169  client: 28  local train loss: 0.8621\n",
      "global round: 169  avg train loss:0.0778  global test loss: 0.7153  global test accu: 0.8619\n",
      "================================================================================================================\n",
      "global round: 170  client: 57  local train loss: 0.7840\n",
      "global round: 170  client: 70  local train loss: 0.8108\n",
      "global round: 170  client: 00  local train loss: 0.8248\n",
      "global round: 170  client: 72  local train loss: 0.8605\n",
      "global round: 170  client: 32  local train loss: 0.8455\n",
      "global round: 170  client: 36  local train loss: 0.8171\n",
      "global round: 170  client: 68  local train loss: 0.8177\n",
      "global round: 170  client: 46  local train loss: 0.9142\n",
      "global round: 170  client: 96  local train loss: 0.8616\n",
      "global round: 170  client: 24  local train loss: 0.8407\n",
      "global round: 170  avg train loss:0.0762  global test loss: 0.7128  global test accu: 0.8618\n",
      "================================================================================================================\n",
      "global round: 171  client: 06  local train loss: 0.8719\n",
      "global round: 171  client: 42  local train loss: 0.8296\n",
      "global round: 171  client: 19  local train loss: 0.8301\n",
      "global round: 171  client: 35  local train loss: 0.8613\n",
      "global round: 171  client: 04  local train loss: 0.8476\n",
      "global round: 171  client: 79  local train loss: 0.8687\n",
      "global round: 171  client: 33  local train loss: 0.8350\n",
      "global round: 171  client: 75  local train loss: 0.8812\n",
      "global round: 171  client: 80  local train loss: 0.9248\n",
      "global round: 171  client: 05  local train loss: 0.8628\n",
      "global round: 171  avg train loss:0.0783  global test loss: 0.7102  global test accu: 0.8625\n",
      "================================================================================================================\n",
      "global round: 172  client: 74  local train loss: 0.8216\n",
      "global round: 172  client: 37  local train loss: 0.8174\n",
      "global round: 172  client: 13  local train loss: 0.9031\n",
      "global round: 172  client: 39  local train loss: 0.8548\n",
      "global round: 172  client: 45  local train loss: 0.8334\n",
      "global round: 172  client: 93  local train loss: 0.8774\n",
      "global round: 172  client: 21  local train loss: 0.8960\n",
      "global round: 172  client: 70  local train loss: 0.7829\n",
      "global round: 172  client: 18  local train loss: 0.9425\n",
      "global round: 172  client: 89  local train loss: 0.8355\n",
      "global round: 172  avg train loss:0.0779  global test loss: 0.7087  global test accu: 0.8623\n",
      "================================================================================================================\n",
      "global round: 173  client: 17  local train loss: 0.8903\n",
      "global round: 173  client: 98  local train loss: 0.8244\n",
      "global round: 173  client: 47  local train loss: 0.9195\n",
      "global round: 173  client: 16  local train loss: 0.8671\n",
      "global round: 173  client: 27  local train loss: 0.8336\n",
      "global round: 173  client: 55  local train loss: 0.8419\n",
      "global round: 173  client: 96  local train loss: 0.8215\n",
      "global round: 173  client: 33  local train loss: 0.8226\n",
      "global round: 173  client: 60  local train loss: 0.9341\n",
      "global round: 173  client: 72  local train loss: 0.8357\n",
      "global round: 173  avg train loss:0.0781  global test loss: 0.7062  global test accu: 0.8631\n",
      "================================================================================================================\n",
      "global round: 174  client: 68  local train loss: 0.7729\n",
      "global round: 174  client: 15  local train loss: 0.8403\n",
      "global round: 174  client: 61  local train loss: 0.8539\n",
      "global round: 174  client: 81  local train loss: 0.8140\n",
      "global round: 174  client: 69  local train loss: 0.8633\n",
      "global round: 174  client: 94  local train loss: 0.8316\n",
      "global round: 174  client: 76  local train loss: 0.8773\n",
      "global round: 174  client: 78  local train loss: 0.8529\n",
      "global round: 174  client: 29  local train loss: 0.8717\n",
      "global round: 174  client: 24  local train loss: 0.8204\n",
      "global round: 174  avg train loss:0.0763  global test loss: 0.7033  global test accu: 0.8636\n",
      "================================================================================================================\n",
      "global round: 175  client: 80  local train loss: 0.8554\n",
      "global round: 175  client: 79  local train loss: 0.8355\n",
      "global round: 175  client: 70  local train loss: 0.7974\n",
      "global round: 175  client: 61  local train loss: 0.8185\n",
      "global round: 175  client: 83  local train loss: 0.8756\n",
      "global round: 175  client: 26  local train loss: 0.8115\n",
      "global round: 175  client: 63  local train loss: 0.8654\n",
      "global round: 175  client: 07  local train loss: 0.8467\n",
      "global round: 175  client: 43  local train loss: 0.8245\n",
      "global round: 175  client: 87  local train loss: 0.8545\n",
      "global round: 175  avg train loss:0.0762  global test loss: 0.6999  global test accu: 0.8639\n",
      "================================================================================================================\n",
      "global round: 176  client: 68  local train loss: 0.7689\n",
      "global round: 176  client: 18  local train loss: 0.8198\n",
      "global round: 176  client: 86  local train loss: 0.8589\n",
      "global round: 176  client: 22  local train loss: 0.8220\n",
      "global round: 176  client: 74  local train loss: 0.8022\n",
      "global round: 176  client: 07  local train loss: 0.8255\n",
      "global round: 176  client: 73  local train loss: 0.8256\n",
      "global round: 176  client: 98  local train loss: 0.8201\n",
      "global round: 176  client: 43  local train loss: 0.8128\n",
      "global round: 176  client: 23  local train loss: 0.8377\n",
      "global round: 176  avg train loss:0.0745  global test loss: 0.6965  global test accu: 0.8644\n",
      "================================================================================================================\n",
      "global round: 177  client: 68  local train loss: 0.7693\n",
      "global round: 177  client: 85  local train loss: 0.8516\n",
      "global round: 177  client: 64  local train loss: 0.8693\n",
      "global round: 177  client: 32  local train loss: 0.8373\n",
      "global round: 177  client: 48  local train loss: 0.8942\n",
      "global round: 177  client: 15  local train loss: 0.8384\n",
      "global round: 177  client: 91  local train loss: 0.8281\n",
      "global round: 177  client: 56  local train loss: 0.8403\n",
      "global round: 177  client: 25  local train loss: 0.9035\n",
      "global round: 177  client: 41  local train loss: 0.9511\n",
      "global round: 177  avg train loss:0.0780  global test loss: 0.6946  global test accu: 0.8640\n",
      "================================================================================================================\n",
      "global round: 178  client: 12  local train loss: 0.8651\n",
      "global round: 178  client: 82  local train loss: 0.8613\n",
      "global round: 178  client: 20  local train loss: 0.8848\n",
      "global round: 178  client: 17  local train loss: 0.8769\n",
      "global round: 178  client: 11  local train loss: 0.8423\n",
      "global round: 178  client: 26  local train loss: 0.7769\n",
      "global round: 178  client: 59  local train loss: 0.8527\n",
      "global round: 178  client: 99  local train loss: 0.8313\n",
      "global round: 178  client: 22  local train loss: 0.8087\n",
      "global round: 178  client: 74  local train loss: 0.8072\n",
      "global round: 178  avg train loss:0.0764  global test loss: 0.6918  global test accu: 0.8647\n",
      "================================================================================================================\n",
      "global round: 179  client: 45  local train loss: 0.8274\n",
      "global round: 179  client: 09  local train loss: 0.8390\n",
      "global round: 179  client: 35  local train loss: 0.8451\n",
      "global round: 179  client: 22  local train loss: 0.7907\n",
      "global round: 179  client: 96  local train loss: 0.8221\n",
      "global round: 179  client: 68  local train loss: 0.7625\n",
      "global round: 179  client: 93  local train loss: 0.8402\n",
      "global round: 179  client: 32  local train loss: 0.8283\n",
      "global round: 179  client: 46  local train loss: 0.8259\n",
      "global round: 179  client: 88  local train loss: 0.8491\n",
      "global round: 179  avg train loss:0.0748  global test loss: 0.6886  global test accu: 0.8648\n",
      "================================================================================================================\n",
      "global round: 180  client: 77  local train loss: 0.9170\n",
      "global round: 180  client: 14  local train loss: 0.8319\n",
      "global round: 180  client: 70  local train loss: 0.7713\n",
      "global round: 180  client: 82  local train loss: 0.8365\n",
      "global round: 180  client: 55  local train loss: 0.8300\n",
      "global round: 180  client: 07  local train loss: 0.8249\n",
      "global round: 180  client: 33  local train loss: 0.8259\n",
      "global round: 180  client: 86  local train loss: 0.8277\n",
      "global round: 180  client: 75  local train loss: 0.8488\n",
      "global round: 180  client: 87  local train loss: 0.8284\n",
      "global round: 180  avg train loss:0.0758  global test loss: 0.6861  global test accu: 0.8650\n",
      "================================================================================================================\n",
      "global round: 181  client: 04  local train loss: 0.8356\n",
      "global round: 181  client: 82  local train loss: 0.8338\n",
      "global round: 181  client: 52  local train loss: 0.8513\n",
      "global round: 181  client: 43  local train loss: 0.8221\n",
      "global round: 181  client: 42  local train loss: 0.8093\n",
      "global round: 181  client: 89  local train loss: 0.7893\n",
      "global round: 181  client: 22  local train loss: 0.7986\n",
      "global round: 181  client: 08  local train loss: 0.8874\n",
      "global round: 181  client: 60  local train loss: 0.8365\n",
      "global round: 181  client: 24  local train loss: 0.8092\n",
      "global round: 181  avg train loss:0.0752  global test loss: 0.6836  global test accu: 0.8655\n",
      "================================================================================================================\n",
      "global round: 182  client: 40  local train loss: 0.8724\n",
      "global round: 182  client: 26  local train loss: 0.7772\n",
      "global round: 182  client: 70  local train loss: 0.7650\n",
      "global round: 182  client: 86  local train loss: 0.8232\n",
      "global round: 182  client: 72  local train loss: 0.8326\n",
      "global round: 182  client: 15  local train loss: 0.8137\n",
      "global round: 182  client: 28  local train loss: 0.8228\n",
      "global round: 182  client: 20  local train loss: 0.8597\n",
      "global round: 182  client: 48  local train loss: 0.8712\n",
      "global round: 182  client: 11  local train loss: 0.7958\n",
      "global round: 182  avg train loss:0.0749  global test loss: 0.6806  global test accu: 0.8659\n",
      "================================================================================================================\n",
      "global round: 183  client: 50  local train loss: 0.9122\n",
      "global round: 183  client: 24  local train loss: 0.7803\n",
      "global round: 183  client: 61  local train loss: 0.8269\n",
      "global round: 183  client: 59  local train loss: 0.8274\n",
      "global round: 183  client: 44  local train loss: 0.8634\n",
      "global round: 183  client: 92  local train loss: 0.8901\n",
      "global round: 183  client: 41  local train loss: 0.8737\n",
      "global round: 183  client: 28  local train loss: 0.8061\n",
      "global round: 183  client: 91  local train loss: 0.8065\n",
      "global round: 183  client: 21  local train loss: 0.8755\n",
      "global round: 183  avg train loss:0.0769  global test loss: 0.6786  global test accu: 0.8661\n",
      "================================================================================================================\n",
      "global round: 184  client: 18  local train loss: 0.8093\n",
      "global round: 184  client: 09  local train loss: 0.8014\n",
      "global round: 184  client: 50  local train loss: 0.8234\n",
      "global round: 184  client: 98  local train loss: 0.8106\n",
      "global round: 184  client: 72  local train loss: 0.8148\n",
      "global round: 184  client: 17  local train loss: 0.8560\n",
      "global round: 184  client: 52  local train loss: 0.8234\n",
      "global round: 184  client: 80  local train loss: 0.8345\n",
      "global round: 184  client: 48  local train loss: 0.8683\n",
      "global round: 184  client: 33  local train loss: 0.8048\n",
      "global round: 184  avg train loss:0.0750  global test loss: 0.6753  global test accu: 0.8669\n",
      "================================================================================================================\n",
      "global round: 185  client: 61  local train loss: 0.8107\n",
      "global round: 185  client: 51  local train loss: 0.8552\n",
      "global round: 185  client: 95  local train loss: 0.8289\n",
      "global round: 185  client: 34  local train loss: 0.8784\n",
      "global round: 185  client: 85  local train loss: 0.8263\n",
      "global round: 185  client: 52  local train loss: 0.8141\n",
      "global round: 185  client: 64  local train loss: 0.8207\n",
      "global round: 185  client: 75  local train loss: 0.8297\n",
      "global round: 185  client: 04  local train loss: 0.8101\n",
      "global round: 185  client: 20  local train loss: 0.8485\n",
      "global round: 185  avg train loss:0.0757  global test loss: 0.6730  global test accu: 0.8669\n",
      "================================================================================================================\n",
      "global round: 186  client: 03  local train loss: 0.8114\n",
      "global round: 186  client: 87  local train loss: 0.8078\n",
      "global round: 186  client: 05  local train loss: 0.8532\n",
      "global round: 186  client: 72  local train loss: 0.8014\n",
      "global round: 186  client: 68  local train loss: 0.7456\n",
      "global round: 186  client: 98  local train loss: 0.7842\n",
      "global round: 186  client: 91  local train loss: 0.7859\n",
      "global round: 186  client: 61  local train loss: 0.7932\n",
      "global round: 186  client: 38  local train loss: 0.8515\n",
      "global round: 186  client: 93  local train loss: 0.8142\n",
      "global round: 186  avg train loss:0.0732  global test loss: 0.6703  global test accu: 0.8674\n",
      "================================================================================================================\n",
      "global round: 187  client: 04  local train loss: 0.8080\n",
      "global round: 187  client: 31  local train loss: 0.9343\n",
      "global round: 187  client: 43  local train loss: 0.8008\n",
      "global round: 187  client: 91  local train loss: 0.7701\n",
      "global round: 187  client: 13  local train loss: 0.8503\n",
      "global round: 187  client: 71  local train loss: 0.8540\n",
      "global round: 187  client: 16  local train loss: 0.8322\n",
      "global round: 187  client: 47  local train loss: 0.8729\n",
      "global round: 187  client: 10  local train loss: 0.8800\n",
      "global round: 187  client: 19  local train loss: 0.8131\n",
      "global round: 187  avg train loss:0.0765  global test loss: 0.6698  global test accu: 0.8671\n",
      "================================================================================================================\n",
      "global round: 188  client: 81  local train loss: 0.7932\n",
      "global round: 188  client: 36  local train loss: 0.7998\n",
      "global round: 188  client: 65  local train loss: 0.9557\n",
      "global round: 188  client: 06  local train loss: 0.8498\n",
      "global round: 188  client: 26  local train loss: 0.7712\n",
      "global round: 188  client: 20  local train loss: 0.8327\n",
      "global round: 188  client: 53  local train loss: 0.8926\n",
      "global round: 188  client: 71  local train loss: 0.8014\n",
      "global round: 188  client: 31  local train loss: 0.8291\n",
      "global round: 188  client: 02  local train loss: 0.8695\n",
      "global round: 188  avg train loss:0.0763  global test loss: 0.6687  global test accu: 0.8671\n",
      "================================================================================================================\n",
      "global round: 189  client: 80  local train loss: 0.8290\n",
      "global round: 189  client: 12  local train loss: 0.8299\n",
      "global round: 189  client: 75  local train loss: 0.8128\n",
      "global round: 189  client: 84  local train loss: 0.8107\n",
      "global round: 189  client: 10  local train loss: 0.8083\n",
      "global round: 189  client: 81  local train loss: 0.7610\n",
      "global round: 189  client: 52  local train loss: 0.8116\n",
      "global round: 189  client: 42  local train loss: 0.7857\n",
      "global round: 189  client: 36  local train loss: 0.7668\n",
      "global round: 189  client: 88  local train loss: 0.8252\n",
      "global round: 189  avg train loss:0.0731  global test loss: 0.6657  global test accu: 0.8674\n",
      "================================================================================================================\n",
      "global round: 190  client: 08  local train loss: 0.8301\n",
      "global round: 190  client: 34  local train loss: 0.8108\n",
      "global round: 190  client: 02  local train loss: 0.8201\n",
      "global round: 190  client: 78  local train loss: 0.8177\n",
      "global round: 190  client: 50  local train loss: 0.8294\n",
      "global round: 190  client: 95  local train loss: 0.7867\n",
      "global round: 190  client: 39  local train loss: 0.8425\n",
      "global round: 190  client: 65  local train loss: 0.8556\n",
      "global round: 190  client: 40  local train loss: 0.8289\n",
      "global round: 190  client: 38  local train loss: 0.8056\n",
      "global round: 190  avg train loss:0.0748  global test loss: 0.6631  global test accu: 0.8675\n",
      "================================================================================================================\n",
      "global round: 191  client: 69  local train loss: 0.7897\n",
      "global round: 191  client: 37  local train loss: 0.8117\n",
      "global round: 191  client: 59  local train loss: 0.8260\n",
      "global round: 191  client: 92  local train loss: 0.8276\n",
      "global round: 191  client: 83  local train loss: 0.8547\n",
      "global round: 191  client: 50  local train loss: 0.8280\n",
      "global round: 191  client: 82  local train loss: 0.8182\n",
      "global round: 191  client: 10  local train loss: 0.8054\n",
      "global round: 191  client: 75  local train loss: 0.8116\n",
      "global round: 191  client: 02  local train loss: 0.8088\n",
      "global round: 191  avg train loss:0.0744  global test loss: 0.6607  global test accu: 0.8674\n",
      "================================================================================================================\n",
      "global round: 192  client: 17  local train loss: 0.8516\n",
      "global round: 192  client: 73  local train loss: 0.7849\n",
      "global round: 192  client: 67  local train loss: 0.8092\n",
      "global round: 192  client: 31  local train loss: 0.8362\n",
      "global round: 192  client: 39  local train loss: 0.7918\n",
      "global round: 192  client: 88  local train loss: 0.7982\n",
      "global round: 192  client: 95  local train loss: 0.7928\n",
      "global round: 192  client: 27  local train loss: 0.8193\n",
      "global round: 192  client: 96  local train loss: 0.8061\n",
      "global round: 192  client: 63  local train loss: 0.8384\n",
      "global round: 192  avg train loss:0.0739  global test loss: 0.6588  global test accu: 0.8676\n",
      "================================================================================================================\n",
      "global round: 193  client: 23  local train loss: 0.8153\n",
      "global round: 193  client: 95  local train loss: 0.7869\n",
      "global round: 193  client: 50  local train loss: 0.8202\n",
      "global round: 193  client: 66  local train loss: 0.8615\n",
      "global round: 193  client: 77  local train loss: 0.8579\n",
      "global round: 193  client: 12  local train loss: 0.8089\n",
      "global round: 193  client: 64  local train loss: 0.8151\n",
      "global round: 193  client: 84  local train loss: 0.7555\n",
      "global round: 193  client: 54  local train loss: 0.9082\n",
      "global round: 193  client: 38  local train loss: 0.8063\n",
      "global round: 193  avg train loss:0.0749  global test loss: 0.6573  global test accu: 0.8678\n",
      "================================================================================================================\n",
      "global round: 194  client: 58  local train loss: 0.8737\n",
      "global round: 194  client: 81  local train loss: 0.7539\n",
      "global round: 194  client: 28  local train loss: 0.8107\n",
      "global round: 194  client: 83  local train loss: 0.8217\n",
      "global round: 194  client: 39  local train loss: 0.7879\n",
      "global round: 194  client: 08  local train loss: 0.8162\n",
      "global round: 194  client: 50  local train loss: 0.8145\n",
      "global round: 194  client: 49  local train loss: 0.8461\n",
      "global round: 194  client: 38  local train loss: 0.7953\n",
      "global round: 194  client: 16  local train loss: 0.8076\n",
      "global round: 194  avg train loss:0.0739  global test loss: 0.6552  global test accu: 0.8677\n",
      "================================================================================================================\n",
      "global round: 195  client: 80  local train loss: 0.8190\n",
      "global round: 195  client: 67  local train loss: 0.7351\n",
      "global round: 195  client: 59  local train loss: 0.8154\n",
      "global round: 195  client: 14  local train loss: 0.7674\n",
      "global round: 195  client: 00  local train loss: 0.7897\n",
      "global round: 195  client: 99  local train loss: 0.7956\n",
      "global round: 195  client: 81  local train loss: 0.7430\n",
      "global round: 195  client: 70  local train loss: 0.7635\n",
      "global round: 195  client: 31  local train loss: 0.8166\n",
      "global round: 195  client: 10  local train loss: 0.7972\n",
      "global round: 195  avg train loss:0.0713  global test loss: 0.6528  global test accu: 0.8675\n",
      "================================================================================================================\n",
      "global round: 196  client: 46  local train loss: 0.7996\n",
      "global round: 196  client: 00  local train loss: 0.7436\n",
      "global round: 196  client: 55  local train loss: 0.8055\n",
      "global round: 196  client: 92  local train loss: 0.8164\n",
      "global round: 196  client: 47  local train loss: 0.8375\n",
      "global round: 196  client: 90  local train loss: 0.8962\n",
      "global round: 196  client: 34  local train loss: 0.8178\n",
      "global round: 196  client: 31  local train loss: 0.8060\n",
      "global round: 196  client: 56  local train loss: 0.8152\n",
      "global round: 196  client: 97  local train loss: 0.8330\n",
      "global round: 196  avg train loss:0.0743  global test loss: 0.6516  global test accu: 0.8680\n",
      "================================================================================================================\n",
      "global round: 197  client: 92  local train loss: 0.8136\n",
      "global round: 197  client: 61  local train loss: 0.7950\n",
      "global round: 197  client: 11  local train loss: 0.7851\n",
      "global round: 197  client: 45  local train loss: 0.8095\n",
      "global round: 197  client: 56  local train loss: 0.7754\n",
      "global round: 197  client: 64  local train loss: 0.8036\n",
      "global round: 197  client: 95  local train loss: 0.7803\n",
      "global round: 197  client: 98  local train loss: 0.7862\n",
      "global round: 197  client: 85  local train loss: 0.8158\n",
      "global round: 197  client: 86  local train loss: 0.8073\n",
      "global round: 197  avg train loss:0.0725  global test loss: 0.6493  global test accu: 0.8683\n",
      "================================================================================================================\n",
      "global round: 198  client: 18  local train loss: 0.7882\n",
      "global round: 198  client: 42  local train loss: 0.7707\n",
      "global round: 198  client: 99  local train loss: 0.7589\n",
      "global round: 198  client: 17  local train loss: 0.8367\n",
      "global round: 198  client: 05  local train loss: 0.8273\n",
      "global round: 198  client: 89  local train loss: 0.7625\n",
      "global round: 198  client: 94  local train loss: 0.8077\n",
      "global round: 198  client: 55  local train loss: 0.7778\n",
      "global round: 198  client: 84  local train loss: 0.7419\n",
      "global round: 198  client: 50  local train loss: 0.8147\n",
      "global round: 198  avg train loss:0.0717  global test loss: 0.6470  global test accu: 0.8683\n",
      "================================================================================================================\n",
      "global round: 199  client: 12  local train loss: 0.7980\n",
      "global round: 199  client: 83  local train loss: 0.8155\n",
      "global round: 199  client: 07  local train loss: 0.8176\n",
      "global round: 199  client: 99  local train loss: 0.7615\n",
      "global round: 199  client: 30  local train loss: 0.8279\n",
      "global round: 199  client: 64  local train loss: 0.7984\n",
      "global round: 199  client: 32  local train loss: 0.8129\n",
      "global round: 199  client: 45  local train loss: 0.7792\n",
      "global round: 199  client: 58  local train loss: 0.7759\n",
      "global round: 199  client: 25  local train loss: 0.8322\n",
      "global round: 199  avg train loss:0.0729  global test loss: 0.6451  global test accu: 0.8686\n",
      "================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# iid, client_equal_size\n",
    "histories, client = federated_learning(iid = True,\n",
    "                                       same_init = True,\n",
    "                                       client_equal_size = True,\n",
    "                                       num_global_round = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f757479-ddb3-4261-8436-1d7225c69878",
   "metadata": {},
   "source": [
    "### iid, client_equal_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7c07bc7-4e16-4024-954b-afe4356f9cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (16, 4)) \n",
    "\n",
    "num_global_round = len(histories[\"local_train_losses\"])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_global_round + 1), histories[\"local_train_losses\"], label = 'avg local train loss')\n",
    "plt.plot(range(1, num_global_round + 1), histories[\"global_test_losses\"], label = 'global test loss')\n",
    "plt.xlabel('global round')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_global_round + 1), histories[\"global_test_accus\"], label = 'global test accus')\n",
    "plt.xlabel('global round')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69feb4cf-169e-43fa-b3fc-ce5a2b4b416f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb604ed4071440bda2cfb3a427e141c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ga92nam\\AppData\\Local\\Temp\\ipykernel_17828\\4185283577.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(image), torch.tensor(label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global round: 00  client: 82  local train loss: 1.6480\n",
      "global round: 00  client: 51  local train loss: 1.5542\n",
      "global round: 00  client: 43  local train loss: 1.6832\n",
      "global round: 00  client: 39  local train loss: 1.8798\n",
      "global round: 00  client: 57  local train loss: 1.4933\n",
      "global round: 00  client: 91  local train loss: 1.4215\n",
      "global round: 00  client: 76  local train loss: 1.6412\n",
      "global round: 00  client: 09  local train loss: 1.6057\n",
      "global round: 00  client: 69  local train loss: 1.9087\n",
      "global round: 00  client: 46  local train loss: 1.4378\n",
      "global round: 00  avg train loss:0.1479  global test loss: 2.3160  global test accu: 0.0669\n",
      "================================================================================================================\n",
      "global round: 01  client: 19  local train loss: 1.5842\n",
      "global round: 01  client: 34  local train loss: 1.4058\n",
      "global round: 01  client: 85  local train loss: 1.7436\n",
      "global round: 01  client: 53  local train loss: 1.5801\n",
      "global round: 01  client: 58  local train loss: 1.2160\n",
      "global round: 01  client: 73  local train loss: 1.6427\n",
      "global round: 01  client: 83  local train loss: 1.4547\n",
      "global round: 01  client: 68  local train loss: 1.5763\n",
      "global round: 01  client: 66  local train loss: 1.4608\n",
      "global round: 01  client: 28  local train loss: 1.5563\n",
      "global round: 01  avg train loss:0.1384  global test loss: 2.3122  global test accu: 0.0835\n",
      "================================================================================================================\n",
      "global round: 02  client: 81  local train loss: 1.3313\n",
      "global round: 02  client: 24  local train loss: 1.4949\n",
      "global round: 02  client: 16  local train loss: 1.6895\n",
      "global round: 02  client: 35  local train loss: 1.6422\n",
      "global round: 02  client: 43  local train loss: 1.6970\n",
      "global round: 02  client: 53  local train loss: 1.5251\n",
      "global round: 02  client: 88  local train loss: 1.2424\n",
      "global round: 02  client: 39  local train loss: 1.8989\n",
      "global round: 02  client: 03  local train loss: 1.6502\n",
      "global round: 02  client: 77  local train loss: 1.8784\n",
      "global round: 02  avg train loss:0.1459  global test loss: 2.3090  global test accu: 0.0869\n",
      "================================================================================================================\n",
      "global round: 03  client: 12  local train loss: 1.7024\n",
      "global round: 03  client: 80  local train loss: 1.6496\n",
      "global round: 03  client: 70  local train loss: 1.5280\n",
      "global round: 03  client: 30  local train loss: 1.5033\n",
      "global round: 03  client: 05  local train loss: 1.5227\n",
      "global round: 03  client: 55  local train loss: 1.8785\n",
      "global round: 03  client: 60  local train loss: 1.7260\n",
      "global round: 03  client: 07  local train loss: 1.5390\n",
      "global round: 03  client: 43  local train loss: 1.6250\n",
      "global round: 03  client: 00  local train loss: 1.6726\n",
      "global round: 03  avg train loss:0.1486  global test loss: 2.3040  global test accu: 0.0851\n",
      "================================================================================================================\n",
      "global round: 04  client: 59  local train loss: 1.5473\n",
      "global round: 04  client: 89  local train loss: 1.6652\n",
      "global round: 04  client: 93  local train loss: 1.5819\n",
      "global round: 04  client: 18  local train loss: 1.7025\n",
      "global round: 04  client: 51  local train loss: 1.5573\n",
      "global round: 04  client: 84  local train loss: 1.6750\n",
      "global round: 04  client: 56  local train loss: 1.5754\n",
      "global round: 04  client: 19  local train loss: 1.6163\n",
      "global round: 04  client: 96  local train loss: 1.5636\n",
      "global round: 04  client: 14  local train loss: 1.4386\n",
      "global round: 04  avg train loss:0.1448  global test loss: 2.2982  global test accu: 0.0939\n",
      "================================================================================================================\n",
      "global round: 05  client: 26  local train loss: 1.8040\n",
      "global round: 05  client: 43  local train loss: 1.6016\n",
      "global round: 05  client: 45  local train loss: 1.6577\n",
      "global round: 05  client: 47  local train loss: 1.5303\n",
      "global round: 05  client: 14  local train loss: 1.3078\n",
      "global round: 05  client: 80  local train loss: 1.5653\n",
      "global round: 05  client: 63  local train loss: 1.8308\n",
      "global round: 05  client: 06  local train loss: 1.5687\n",
      "global round: 05  client: 13  local train loss: 1.8928\n",
      "global round: 05  client: 89  local train loss: 1.5321\n",
      "global round: 05  avg train loss:0.1481  global test loss: 2.2937  global test accu: 0.0942\n",
      "================================================================================================================\n",
      "global round: 06  client: 46  local train loss: 1.4355\n",
      "global round: 06  client: 35  local train loss: 1.5662\n",
      "global round: 06  client: 10  local train loss: 1.6159\n",
      "global round: 06  client: 40  local train loss: 1.5250\n",
      "global round: 06  client: 69  local train loss: 1.9066\n",
      "global round: 06  client: 76  local train loss: 1.6266\n",
      "global round: 06  client: 13  local train loss: 1.8071\n",
      "global round: 06  client: 01  local train loss: 1.7295\n",
      "global round: 06  client: 94  local train loss: 1.4288\n",
      "global round: 06  client: 70  local train loss: 1.4142\n",
      "global round: 06  avg train loss:0.1460  global test loss: 2.2894  global test accu: 0.1024\n",
      "================================================================================================================\n",
      "global round: 07  client: 28  local train loss: 1.5163\n",
      "global round: 07  client: 93  local train loss: 1.4454\n",
      "global round: 07  client: 58  local train loss: 1.2002\n",
      "global round: 07  client: 04  local train loss: 1.7907\n",
      "global round: 07  client: 42  local train loss: 1.4436\n",
      "global round: 07  client: 12  local train loss: 1.5971\n",
      "global round: 07  client: 22  local train loss: 1.8194\n",
      "global round: 07  client: 92  local train loss: 1.4266\n",
      "global round: 07  client: 11  local train loss: 1.7529\n",
      "global round: 07  client: 76  local train loss: 1.4727\n",
      "global round: 07  avg train loss:0.1406  global test loss: 2.2842  global test accu: 0.0996\n",
      "================================================================================================================\n",
      "global round: 08  client: 61  local train loss: 1.8097\n",
      "global round: 08  client: 36  local train loss: 1.5503\n",
      "global round: 08  client: 56  local train loss: 1.4414\n",
      "global round: 08  client: 55  local train loss: 1.8143\n",
      "global round: 08  client: 97  local train loss: 1.4450\n",
      "global round: 08  client: 77  local train loss: 1.8324\n",
      "global round: 08  client: 83  local train loss: 1.3939\n",
      "global round: 08  client: 16  local train loss: 1.6345\n",
      "global round: 08  client: 32  local train loss: 1.5369\n",
      "global round: 08  client: 63  local train loss: 1.7197\n",
      "global round: 08  avg train loss:0.1471  global test loss: 2.2788  global test accu: 0.1065\n",
      "================================================================================================================\n",
      "global round: 09  client: 93  local train loss: 1.4072\n",
      "global round: 09  client: 14  local train loss: 1.2935\n",
      "global round: 09  client: 73  local train loss: 1.6064\n",
      "global round: 09  client: 41  local train loss: 1.5172\n",
      "global round: 09  client: 40  local train loss: 1.3361\n",
      "global round: 09  client: 01  local train loss: 1.5649\n",
      "global round: 09  client: 57  local train loss: 1.4939\n",
      "global round: 09  client: 15  local train loss: 1.5822\n",
      "global round: 09  client: 32  local train loss: 1.3205\n",
      "global round: 09  client: 64  local train loss: 1.5479\n",
      "global round: 09  avg train loss:0.1334  global test loss: 2.2701  global test accu: 0.1342\n",
      "================================================================================================================\n",
      "global round: 10  client: 73  local train loss: 1.4424\n",
      "global round: 10  client: 91  local train loss: 1.4262\n",
      "global round: 10  client: 54  local train loss: 1.5641\n",
      "global round: 10  client: 43  local train loss: 1.5493\n",
      "global round: 10  client: 95  local train loss: 1.5927\n",
      "global round: 10  client: 66  local train loss: 1.4166\n",
      "global round: 10  client: 96  local train loss: 1.4451\n",
      "global round: 10  client: 05  local train loss: 1.4135\n",
      "global round: 10  client: 64  local train loss: 1.3215\n",
      "global round: 10  client: 01  local train loss: 1.5401\n",
      "global round: 10  avg train loss:0.1337  global test loss: 2.2621  global test accu: 0.1485\n",
      "================================================================================================================\n",
      "global round: 11  client: 50  local train loss: 1.6438\n",
      "global round: 11  client: 01  local train loss: 1.5193\n",
      "global round: 11  client: 43  local train loss: 1.4832\n",
      "global round: 11  client: 78  local train loss: 1.6571\n",
      "global round: 11  client: 21  local train loss: 1.4506\n",
      "global round: 11  client: 00  local train loss: 1.5765\n",
      "global round: 11  client: 73  local train loss: 1.4421\n",
      "global round: 11  client: 22  local train loss: 1.6578\n",
      "global round: 11  client: 47  local train loss: 1.3745\n",
      "global round: 11  client: 56  local train loss: 1.3898\n",
      "global round: 11  avg train loss:0.1381  global test loss: 2.2565  global test accu: 0.1519\n",
      "================================================================================================================\n",
      "global round: 12  client: 31  local train loss: 1.6364\n",
      "global round: 12  client: 68  local train loss: 1.5610\n",
      "global round: 12  client: 93  local train loss: 1.3737\n",
      "global round: 12  client: 70  local train loss: 1.3532\n",
      "global round: 12  client: 55  local train loss: 1.7376\n",
      "global round: 12  client: 33  local train loss: 1.6207\n",
      "global round: 12  client: 65  local train loss: 1.6301\n",
      "global round: 12  client: 83  local train loss: 1.2446\n",
      "global round: 12  client: 41  local train loss: 1.2960\n",
      "global round: 12  client: 61  local train loss: 1.6704\n",
      "global round: 12  avg train loss:0.1375  global test loss: 2.2515  global test accu: 0.1630\n",
      "================================================================================================================\n",
      "global round: 13  client: 37  local train loss: 1.3276\n",
      "global round: 13  client: 16  local train loss: 1.4772\n",
      "global round: 13  client: 90  local train loss: 1.6907\n",
      "global round: 13  client: 86  local train loss: 1.8295\n",
      "global round: 13  client: 39  local train loss: 1.8339\n",
      "global round: 13  client: 28  local train loss: 1.3643\n",
      "global round: 13  client: 95  local train loss: 1.3637\n",
      "global round: 13  client: 93  local train loss: 1.3161\n",
      "global round: 13  client: 35  local train loss: 1.4802\n",
      "global round: 13  client: 31  local train loss: 1.4009\n",
      "global round: 13  avg train loss:0.1371  global test loss: 2.2474  global test accu: 0.1698\n",
      "================================================================================================================\n",
      "global round: 14  client: 37  local train loss: 1.0017\n",
      "global round: 14  client: 85  local train loss: 1.7311\n",
      "global round: 14  client: 50  local train loss: 1.4553\n",
      "global round: 14  client: 58  local train loss: 1.0234\n",
      "global round: 14  client: 55  local train loss: 1.7033\n",
      "global round: 14  client: 48  local train loss: 1.6606\n",
      "global round: 14  client: 04  local train loss: 1.6493\n",
      "global round: 14  client: 28  local train loss: 1.2838\n",
      "global round: 14  client: 38  local train loss: 1.6557\n",
      "global round: 14  client: 12  local train loss: 1.5216\n",
      "global round: 14  avg train loss:0.1335  global test loss: 2.2440  global test accu: 0.1742\n",
      "================================================================================================================\n",
      "global round: 15  client: 27  local train loss: 1.6360\n",
      "global round: 15  client: 18  local train loss: 1.5699\n",
      "global round: 15  client: 10  local train loss: 1.4419\n",
      "global round: 15  client: 02  local train loss: 1.7568\n",
      "global round: 15  client: 59  local train loss: 1.3854\n",
      "global round: 15  client: 17  local train loss: 1.5761\n",
      "global round: 15  client: 73  local train loss: 1.4411\n",
      "global round: 15  client: 31  local train loss: 1.4011\n",
      "global round: 15  client: 64  local train loss: 1.3246\n",
      "global round: 15  client: 54  local train loss: 1.3243\n",
      "global round: 15  avg train loss:0.1351  global test loss: 2.2409  global test accu: 0.1765\n",
      "================================================================================================================\n",
      "global round: 16  client: 57  local train loss: 1.2556\n",
      "global round: 16  client: 43  local train loss: 1.4550\n",
      "global round: 16  client: 65  local train loss: 1.3940\n",
      "global round: 16  client: 32  local train loss: 1.3110\n",
      "global round: 16  client: 02  local train loss: 1.4972\n",
      "global round: 16  client: 37  local train loss: 0.9822\n",
      "global round: 16  client: 52  local train loss: 1.5746\n",
      "global round: 16  client: 08  local train loss: 1.7495\n",
      "global round: 16  client: 90  local train loss: 1.3876\n",
      "global round: 16  client: 50  local train loss: 1.4550\n",
      "global round: 16  avg train loss:0.1278  global test loss: 2.2327  global test accu: 0.1974\n",
      "================================================================================================================\n",
      "global round: 17  client: 32  local train loss: 1.2447\n",
      "global round: 17  client: 71  local train loss: 1.6314\n",
      "global round: 17  client: 49  local train loss: 1.6485\n",
      "global round: 17  client: 90  local train loss: 1.3766\n",
      "global round: 17  client: 28  local train loss: 1.2782\n",
      "global round: 17  client: 81  local train loss: 1.2813\n",
      "global round: 17  client: 39  local train loss: 1.6449\n",
      "global round: 17  client: 66  local train loss: 1.2293\n",
      "global round: 17  client: 92  local train loss: 1.2275\n",
      "global round: 17  client: 87  local train loss: 1.7430\n",
      "global round: 17  avg train loss:0.1300  global test loss: 2.2274  global test accu: 0.2042\n",
      "================================================================================================================\n",
      "global round: 18  client: 66  local train loss: 1.1914\n",
      "global round: 18  client: 15  local train loss: 1.3666\n",
      "global round: 18  client: 64  local train loss: 1.2683\n",
      "global round: 18  client: 05  local train loss: 1.2910\n",
      "global round: 18  client: 58  local train loss: 0.9414\n",
      "global round: 18  client: 60  local train loss: 1.6434\n",
      "global round: 18  client: 85  local train loss: 1.4662\n",
      "global round: 18  client: 16  local train loss: 1.4069\n",
      "global round: 18  client: 24  local train loss: 1.4396\n",
      "global round: 18  client: 92  local train loss: 1.0903\n",
      "global round: 18  avg train loss:0.1191  global test loss: 2.2229  global test accu: 0.2211\n",
      "================================================================================================================\n",
      "global round: 19  client: 41  local train loss: 1.2737\n",
      "global round: 19  client: 98  local train loss: 1.7352\n",
      "global round: 19  client: 55  local train loss: 1.6992\n",
      "global round: 19  client: 44  local train loss: 1.2207\n",
      "global round: 19  client: 33  local train loss: 1.3764\n",
      "global round: 19  client: 43  local train loss: 1.4103\n",
      "global round: 19  client: 92  local train loss: 1.0830\n",
      "global round: 19  client: 79  local train loss: 1.5426\n",
      "global round: 19  client: 82  local train loss: 1.6823\n",
      "global round: 19  client: 96  local train loss: 1.3724\n",
      "global round: 19  avg train loss:0.1309  global test loss: 2.2188  global test accu: 0.2309\n",
      "================================================================================================================\n",
      "global round: 20  client: 79  local train loss: 1.2349\n",
      "global round: 20  client: 93  local train loss: 1.2947\n",
      "global round: 20  client: 95  local train loss: 1.3427\n",
      "global round: 20  client: 87  local train loss: 1.4408\n",
      "global round: 20  client: 02  local train loss: 1.4950\n",
      "global round: 20  client: 19  local train loss: 1.4850\n",
      "global round: 20  client: 81  local train loss: 0.9232\n",
      "global round: 20  client: 39  local train loss: 1.6626\n",
      "global round: 20  client: 03  local train loss: 1.5767\n",
      "global round: 20  client: 72  local train loss: 1.5400\n",
      "global round: 20  avg train loss:0.1272  global test loss: 2.2138  global test accu: 0.2203\n",
      "================================================================================================================\n",
      "global round: 21  client: 88  local train loss: 1.1972\n",
      "global round: 21  client: 14  local train loss: 1.2139\n",
      "global round: 21  client: 09  local train loss: 1.5911\n",
      "global round: 21  client: 17  local train loss: 1.2834\n",
      "global round: 21  client: 19  local train loss: 1.2460\n",
      "global round: 21  client: 62  local train loss: 1.4538\n",
      "global round: 21  client: 04  local train loss: 1.5874\n",
      "global round: 21  client: 05  local train loss: 1.1846\n",
      "global round: 21  client: 25  local train loss: 1.5715\n",
      "global round: 21  client: 48  local train loss: 1.4109\n",
      "global round: 21  avg train loss:0.1249  global test loss: 2.2133  global test accu: 0.2390\n",
      "================================================================================================================\n",
      "global round: 22  client: 33  local train loss: 1.3640\n",
      "global round: 22  client: 48  local train loss: 1.3647\n",
      "global round: 22  client: 27  local train loss: 1.3487\n",
      "global round: 22  client: 44  local train loss: 0.8098\n",
      "global round: 22  client: 18  local train loss: 1.4056\n",
      "global round: 22  client: 99  local train loss: 1.4391\n",
      "global round: 22  client: 74  local train loss: 1.2453\n",
      "global round: 22  client: 59  local train loss: 1.2422\n",
      "global round: 22  client: 29  local train loss: 1.8257\n",
      "global round: 22  client: 13  local train loss: 1.8086\n",
      "global round: 22  avg train loss:0.1259  global test loss: 2.2128  global test accu: 0.2268\n",
      "================================================================================================================\n",
      "global round: 23  client: 38  local train loss: 1.3938\n",
      "global round: 23  client: 86  local train loss: 1.6069\n",
      "global round: 23  client: 80  local train loss: 1.5155\n",
      "global round: 23  client: 79  local train loss: 1.2384\n",
      "global round: 23  client: 90  local train loss: 1.3697\n",
      "global round: 23  client: 25  local train loss: 1.2367\n",
      "global round: 23  client: 76  local train loss: 1.4664\n",
      "global round: 23  client: 31  local train loss: 1.3721\n",
      "global round: 23  client: 63  local train loss: 1.6656\n",
      "global round: 23  client: 45  local train loss: 1.4879\n",
      "global round: 23  avg train loss:0.1305  global test loss: 2.2100  global test accu: 0.2135\n",
      "================================================================================================================\n",
      "global round: 24  client: 55  local train loss: 1.6769\n",
      "global round: 24  client: 87  local train loss: 1.4435\n",
      "global round: 24  client: 98  local train loss: 1.3956\n",
      "global round: 24  client: 19  local train loss: 1.2316\n",
      "global round: 24  client: 03  local train loss: 1.3796\n",
      "global round: 24  client: 39  local train loss: 1.6481\n",
      "global round: 24  client: 26  local train loss: 1.7131\n",
      "global round: 24  client: 93  local train loss: 1.2034\n",
      "global round: 24  client: 49  local train loss: 1.3964\n",
      "global round: 24  client: 43  local train loss: 1.4007\n",
      "global round: 24  avg train loss:0.1317  global test loss: 2.2056  global test accu: 0.1956\n",
      "================================================================================================================\n",
      "global round: 25  client: 07  local train loss: 1.4182\n",
      "global round: 25  client: 13  local train loss: 1.6439\n",
      "global round: 25  client: 60  local train loss: 1.4180\n",
      "global round: 25  client: 03  local train loss: 1.3332\n",
      "global round: 25  client: 06  local train loss: 1.4105\n",
      "global round: 25  client: 46  local train loss: 1.2532\n",
      "global round: 25  client: 33  local train loss: 1.3550\n",
      "global round: 25  client: 89  local train loss: 1.5081\n",
      "global round: 25  client: 87  local train loss: 1.4083\n",
      "global round: 25  client: 34  local train loss: 1.3616\n",
      "global round: 25  avg train loss:0.1283  global test loss: 2.2021  global test accu: 0.1772\n",
      "================================================================================================================\n",
      "global round: 26  client: 00  local train loss: 1.4495\n",
      "global round: 26  client: 46  local train loss: 1.0984\n",
      "global round: 26  client: 03  local train loss: 1.3302\n",
      "global round: 26  client: 85  local train loss: 1.4759\n",
      "global round: 26  client: 87  local train loss: 1.4233\n",
      "global round: 26  client: 95  local train loss: 1.2660\n",
      "global round: 26  client: 15  local train loss: 1.2682\n",
      "global round: 26  client: 06  local train loss: 1.2217\n",
      "global round: 26  client: 25  local train loss: 1.2618\n",
      "global round: 26  client: 05  local train loss: 1.1665\n",
      "global round: 26  avg train loss:0.1178  global test loss: 2.1943  global test accu: 0.1868\n",
      "================================================================================================================\n",
      "global round: 27  client: 11  local train loss: 1.5879\n",
      "global round: 27  client: 87  local train loss: 1.4031\n",
      "global round: 27  client: 57  local train loss: 1.1645\n",
      "global round: 27  client: 54  local train loss: 1.2870\n",
      "global round: 27  client: 35  local train loss: 1.4019\n",
      "global round: 27  client: 27  local train loss: 1.3270\n",
      "global round: 27  client: 69  local train loss: 1.8191\n",
      "global round: 27  client: 58  local train loss: 0.8792\n",
      "global round: 27  client: 04  local train loss: 1.5344\n",
      "global round: 27  client: 70  local train loss: 1.2486\n",
      "global round: 27  avg train loss:0.1241  global test loss: 2.1896  global test accu: 0.2272\n",
      "================================================================================================================\n",
      "global round: 28  client: 83  local train loss: 1.1869\n",
      "global round: 28  client: 18  local train loss: 1.3612\n",
      "global round: 28  client: 77  local train loss: 1.7406\n",
      "global round: 28  client: 98  local train loss: 1.3829\n",
      "global round: 28  client: 42  local train loss: 1.2642\n",
      "global round: 28  client: 97  local train loss: 1.2426\n",
      "global round: 28  client: 04  local train loss: 1.4717\n",
      "global round: 28  client: 87  local train loss: 1.3848\n",
      "global round: 28  client: 16  local train loss: 1.3472\n",
      "global round: 28  client: 21  local train loss: 1.2262\n",
      "global round: 28  avg train loss:0.1237  global test loss: 2.1875  global test accu: 0.2149\n",
      "================================================================================================================\n",
      "global round: 29  client: 06  local train loss: 1.2087\n",
      "global round: 29  client: 22  local train loss: 1.6349\n",
      "global round: 29  client: 18  local train loss: 1.3337\n",
      "global round: 29  client: 81  local train loss: 0.9024\n",
      "global round: 29  client: 68  local train loss: 1.3092\n",
      "global round: 29  client: 74  local train loss: 0.9080\n",
      "global round: 29  client: 21  local train loss: 1.1143\n",
      "global round: 29  client: 45  local train loss: 1.3488\n",
      "global round: 29  client: 13  local train loss: 1.6399\n",
      "global round: 29  client: 17  local train loss: 1.2747\n",
      "global round: 29  avg train loss:0.1152  global test loss: 2.1852  global test accu: 0.2202\n",
      "================================================================================================================\n",
      "global round: 30  client: 98  local train loss: 1.3408\n",
      "global round: 30  client: 42  local train loss: 1.1030\n",
      "global round: 30  client: 51  local train loss: 1.3916\n",
      "global round: 30  client: 46  local train loss: 1.1052\n",
      "global round: 30  client: 09  local train loss: 1.2795\n",
      "global round: 30  client: 31  local train loss: 1.3068\n",
      "global round: 30  client: 50  local train loss: 1.4336\n",
      "global round: 30  client: 70  local train loss: 1.1520\n",
      "global round: 30  client: 26  local train loss: 1.4740\n",
      "global round: 30  client: 21  local train loss: 1.1163\n",
      "global round: 30  avg train loss:0.1155  global test loss: 2.1841  global test accu: 0.2194\n",
      "================================================================================================================\n",
      "global round: 31  client: 60  local train loss: 1.4152\n",
      "global round: 31  client: 26  local train loss: 1.4719\n",
      "global round: 31  client: 75  local train loss: 1.5785\n",
      "global round: 31  client: 49  local train loss: 1.3691\n",
      "global round: 31  client: 76  local train loss: 1.3289\n",
      "global round: 31  client: 81  local train loss: 0.8528\n",
      "global round: 31  client: 10  local train loss: 1.3254\n",
      "global round: 31  client: 08  local train loss: 1.4885\n",
      "global round: 31  client: 66  local train loss: 1.1807\n",
      "global round: 31  client: 72  local train loss: 1.2825\n",
      "global round: 31  avg train loss:0.1209  global test loss: 2.1786  global test accu: 0.2148\n",
      "================================================================================================================\n",
      "global round: 32  client: 78  local train loss: 1.4603\n",
      "global round: 32  client: 75  local train loss: 1.1863\n",
      "global round: 32  client: 14  local train loss: 1.1085\n",
      "global round: 32  client: 86  local train loss: 1.5418\n",
      "global round: 32  client: 96  local train loss: 1.3087\n",
      "global round: 32  client: 17  local train loss: 1.2209\n",
      "global round: 32  client: 76  local train loss: 1.2544\n",
      "global round: 32  client: 37  local train loss: 0.9348\n",
      "global round: 32  client: 90  local train loss: 1.3255\n",
      "global round: 32  client: 82  local train loss: 1.3924\n",
      "global round: 32  avg train loss:0.1158  global test loss: 2.1735  global test accu: 0.2282\n",
      "================================================================================================================\n",
      "global round: 33  client: 39  local train loss: 1.6138\n",
      "global round: 33  client: 36  local train loss: 1.3312\n",
      "global round: 33  client: 71  local train loss: 1.3289\n",
      "global round: 33  client: 65  local train loss: 1.3488\n",
      "global round: 33  client: 76  local train loss: 1.2347\n",
      "global round: 33  client: 48  local train loss: 1.3519\n",
      "global round: 33  client: 27  local train loss: 1.3103\n",
      "global round: 33  client: 97  local train loss: 1.1009\n",
      "global round: 33  client: 79  local train loss: 1.2027\n",
      "global round: 33  client: 52  local train loss: 1.2852\n",
      "global round: 33  avg train loss:0.1192  global test loss: 2.1754  global test accu: 0.2157\n",
      "================================================================================================================\n",
      "global round: 34  client: 19  local train loss: 1.1664\n",
      "global round: 34  client: 18  local train loss: 1.3208\n",
      "global round: 34  client: 95  local train loss: 1.2656\n",
      "global round: 34  client: 53  local train loss: 1.4915\n",
      "global round: 34  client: 28  local train loss: 1.2343\n",
      "global round: 34  client: 72  local train loss: 1.2119\n",
      "global round: 34  client: 13  local train loss: 1.6369\n",
      "global round: 34  client: 82  local train loss: 1.2098\n",
      "global round: 34  client: 05  local train loss: 1.1553\n",
      "global round: 34  client: 76  local train loss: 1.2274\n",
      "global round: 34  avg train loss:0.1175  global test loss: 2.1712  global test accu: 0.2427\n",
      "================================================================================================================\n",
      "global round: 35  client: 95  local train loss: 1.2796\n",
      "global round: 35  client: 30  local train loss: 1.4102\n",
      "global round: 35  client: 48  local train loss: 1.2611\n",
      "global round: 35  client: 53  local train loss: 1.1429\n",
      "global round: 35  client: 06  local train loss: 1.2095\n",
      "global round: 35  client: 19  local train loss: 1.1036\n",
      "global round: 35  client: 52  local train loss: 1.2722\n",
      "global round: 35  client: 13  local train loss: 1.6291\n",
      "global round: 35  client: 02  local train loss: 1.4654\n",
      "global round: 35  client: 79  local train loss: 1.1298\n",
      "global round: 35  avg train loss:0.1173  global test loss: 2.1661  global test accu: 0.2655\n",
      "================================================================================================================\n",
      "global round: 36  client: 57  local train loss: 1.1461\n",
      "global round: 36  client: 37  local train loss: 0.8397\n",
      "global round: 36  client: 97  local train loss: 1.0645\n",
      "global round: 36  client: 33  local train loss: 1.3485\n",
      "global round: 36  client: 67  local train loss: 1.5527\n",
      "global round: 36  client: 96  local train loss: 1.2235\n",
      "global round: 36  client: 09  local train loss: 1.2339\n",
      "global round: 36  client: 87  local train loss: 1.3958\n",
      "global round: 36  client: 94  local train loss: 1.2364\n",
      "global round: 36  client: 01  local train loss: 1.4970\n",
      "global round: 36  avg train loss:0.1140  global test loss: 2.1595  global test accu: 0.3006\n",
      "================================================================================================================\n",
      "global round: 37  client: 95  local train loss: 1.2721\n",
      "global round: 37  client: 24  local train loss: 1.2368\n",
      "global round: 37  client: 27  local train loss: 1.2516\n",
      "global round: 37  client: 05  local train loss: 1.1095\n",
      "global round: 37  client: 80  local train loss: 1.3068\n",
      "global round: 37  client: 62  local train loss: 1.1626\n",
      "global round: 37  client: 11  local train loss: 1.4158\n",
      "global round: 37  client: 92  local train loss: 1.0707\n",
      "global round: 37  client: 93  local train loss: 1.2049\n",
      "global round: 37  client: 55  local train loss: 1.6242\n",
      "global round: 37  avg train loss:0.1150  global test loss: 2.1569  global test accu: 0.2801\n",
      "================================================================================================================\n",
      "global round: 38  client: 27  local train loss: 1.2309\n",
      "global round: 38  client: 05  local train loss: 1.0979\n",
      "global round: 38  client: 29  local train loss: 1.6067\n",
      "global round: 38  client: 90  local train loss: 1.2983\n",
      "global round: 38  client: 13  local train loss: 1.6132\n",
      "global round: 38  client: 51  local train loss: 1.1482\n",
      "global round: 38  client: 37  local train loss: 0.8341\n",
      "global round: 38  client: 08  local train loss: 1.4049\n",
      "global round: 38  client: 20  local train loss: 1.4570\n",
      "global round: 38  client: 32  local train loss: 1.2317\n",
      "global round: 38  avg train loss:0.1175  global test loss: 2.1503  global test accu: 0.3118\n",
      "================================================================================================================\n",
      "global round: 39  client: 41  local train loss: 1.2358\n",
      "global round: 39  client: 38  local train loss: 1.3708\n",
      "global round: 39  client: 75  local train loss: 1.1946\n",
      "global round: 39  client: 16  local train loss: 1.3017\n",
      "global round: 39  client: 62  local train loss: 1.0730\n",
      "global round: 39  client: 44  local train loss: 0.8037\n",
      "global round: 39  client: 69  local train loss: 1.6420\n",
      "global round: 39  client: 18  local train loss: 1.3180\n",
      "global round: 39  client: 09  local train loss: 1.1936\n",
      "global round: 39  client: 94  local train loss: 1.0217\n",
      "global round: 39  avg train loss:0.1105  global test loss: 2.1435  global test accu: 0.3259\n",
      "================================================================================================================\n",
      "global round: 40  client: 47  local train loss: 1.2690\n",
      "global round: 40  client: 96  local train loss: 1.2163\n",
      "global round: 40  client: 52  local train loss: 1.2660\n",
      "global round: 40  client: 09  local train loss: 1.1738\n",
      "global round: 40  client: 06  local train loss: 1.2126\n",
      "global round: 40  client: 26  local train loss: 1.4566\n",
      "global round: 40  client: 22  local train loss: 1.4610\n",
      "global round: 40  client: 28  local train loss: 1.1577\n",
      "global round: 40  client: 64  local train loss: 1.2117\n",
      "global round: 40  client: 50  local train loss: 1.3237\n",
      "global round: 40  avg train loss:0.1159  global test loss: 2.1357  global test accu: 0.3341\n",
      "================================================================================================================\n",
      "global round: 41  client: 61  local train loss: 1.6578\n",
      "global round: 41  client: 81  local train loss: 0.8499\n",
      "global round: 41  client: 36  local train loss: 1.1131\n",
      "global round: 41  client: 68  local train loss: 1.2128\n",
      "global round: 41  client: 51  local train loss: 1.1154\n",
      "global round: 41  client: 34  local train loss: 1.0935\n",
      "global round: 41  client: 25  local train loss: 1.2134\n",
      "global round: 41  client: 01  local train loss: 1.3061\n",
      "global round: 41  client: 48  local train loss: 1.2482\n",
      "global round: 41  client: 64  local train loss: 1.1490\n",
      "global round: 41  avg train loss:0.1087  global test loss: 2.1318  global test accu: 0.3548\n",
      "================================================================================================================\n",
      "global round: 42  client: 92  local train loss: 1.0180\n",
      "global round: 42  client: 85  local train loss: 1.4153\n",
      "global round: 42  client: 98  local train loss: 1.3171\n",
      "global round: 42  client: 89  local train loss: 1.3039\n",
      "global round: 42  client: 91  local train loss: 1.1265\n",
      "global round: 42  client: 78  local train loss: 1.2605\n",
      "global round: 42  client: 35  local train loss: 1.2901\n",
      "global round: 42  client: 75  local train loss: 1.1887\n",
      "global round: 42  client: 27  local train loss: 1.2168\n",
      "global round: 42  client: 16  local train loss: 1.2565\n",
      "global round: 42  avg train loss:0.1127  global test loss: 2.1295  global test accu: 0.3751\n",
      "================================================================================================================\n",
      "global round: 43  client: 42  local train loss: 1.0836\n",
      "global round: 43  client: 32  local train loss: 1.1396\n",
      "global round: 43  client: 97  local train loss: 1.0578\n",
      "global round: 43  client: 95  local train loss: 1.2611\n",
      "global round: 43  client: 02  local train loss: 1.3404\n",
      "global round: 43  client: 65  local train loss: 1.2473\n",
      "global round: 43  client: 89  local train loss: 1.2359\n",
      "global round: 43  client: 86  local train loss: 1.4162\n",
      "global round: 43  client: 54  local train loss: 1.1801\n",
      "global round: 43  client: 40  local train loss: 1.3138\n",
      "global round: 43  avg train loss:0.1116  global test loss: 2.1254  global test accu: 0.3644\n",
      "================================================================================================================\n",
      "global round: 44  client: 77  local train loss: 1.5702\n",
      "global round: 44  client: 44  local train loss: 0.7715\n",
      "global round: 44  client: 87  local train loss: 1.3309\n",
      "global round: 44  client: 22  local train loss: 1.3904\n",
      "global round: 44  client: 13  local train loss: 1.6123\n",
      "global round: 44  client: 08  local train loss: 1.4035\n",
      "global round: 44  client: 62  local train loss: 1.0767\n",
      "global round: 44  client: 94  local train loss: 1.0179\n",
      "global round: 44  client: 11  local train loss: 1.3968\n",
      "global round: 44  client: 25  local train loss: 1.1498\n",
      "global round: 44  avg train loss:0.1156  global test loss: 2.1182  global test accu: 0.4066\n",
      "================================================================================================================\n",
      "global round: 45  client: 76  local train loss: 1.2200\n",
      "global round: 45  client: 48  local train loss: 1.2684\n",
      "global round: 45  client: 31  local train loss: 1.2559\n",
      "global round: 45  client: 74  local train loss: 0.8465\n",
      "global round: 45  client: 03  local train loss: 1.3239\n",
      "global round: 45  client: 81  local train loss: 0.7805\n",
      "global round: 45  client: 91  local train loss: 0.9761\n",
      "global round: 45  client: 70  local train loss: 1.0990\n",
      "global round: 45  client: 32  local train loss: 1.1109\n",
      "global round: 45  client: 66  local train loss: 1.0888\n",
      "global round: 45  avg train loss:0.0997  global test loss: 2.1199  global test accu: 0.3239\n",
      "================================================================================================================\n",
      "global round: 46  client: 48  local train loss: 1.2450\n",
      "global round: 46  client: 67  local train loss: 1.1507\n",
      "global round: 46  client: 54  local train loss: 1.1392\n",
      "global round: 46  client: 42  local train loss: 1.0641\n",
      "global round: 46  client: 92  local train loss: 0.9919\n",
      "global round: 46  client: 66  local train loss: 1.0361\n",
      "global round: 46  client: 12  local train loss: 1.4111\n",
      "global round: 46  client: 08  local train loss: 1.3573\n",
      "global round: 46  client: 37  local train loss: 0.8241\n",
      "global round: 46  client: 61  local train loss: 1.4333\n",
      "global round: 46  avg train loss:0.1059  global test loss: 2.1140  global test accu: 0.3141\n",
      "================================================================================================================\n",
      "global round: 47  client: 16  local train loss: 1.2344\n",
      "global round: 47  client: 38  local train loss: 1.2863\n",
      "global round: 47  client: 74  local train loss: 0.7726\n",
      "global round: 47  client: 71  local train loss: 1.2417\n",
      "global round: 47  client: 80  local train loss: 1.2396\n",
      "global round: 47  client: 17  local train loss: 1.1890\n",
      "global round: 47  client: 97  local train loss: 1.0545\n",
      "global round: 47  client: 43  local train loss: 1.3549\n",
      "global round: 47  client: 19  local train loss: 1.0813\n",
      "global round: 47  client: 07  local train loss: 1.1746\n",
      "global round: 47  avg train loss:0.1057  global test loss: 2.1190  global test accu: 0.2850\n",
      "================================================================================================================\n",
      "global round: 48  client: 45  local train loss: 1.2957\n",
      "global round: 48  client: 34  local train loss: 0.9940\n",
      "global round: 48  client: 00  local train loss: 1.3341\n",
      "global round: 48  client: 89  local train loss: 1.2319\n",
      "global round: 48  client: 44  local train loss: 0.7567\n",
      "global round: 48  client: 60  local train loss: 1.3639\n",
      "global round: 48  client: 31  local train loss: 1.2039\n",
      "global round: 48  client: 35  local train loss: 1.2075\n",
      "global round: 48  client: 51  local train loss: 1.0985\n",
      "global round: 48  client: 85  local train loss: 1.3411\n",
      "global round: 48  avg train loss:0.1075  global test loss: 2.1183  global test accu: 0.3022\n",
      "================================================================================================================\n",
      "global round: 49  client: 00  local train loss: 1.2036\n",
      "global round: 49  client: 90  local train loss: 1.2864\n",
      "global round: 49  client: 97  local train loss: 0.9992\n",
      "global round: 49  client: 07  local train loss: 1.0304\n",
      "global round: 49  client: 29  local train loss: 1.5365\n",
      "global round: 49  client: 39  local train loss: 1.5835\n",
      "global round: 49  client: 94  local train loss: 0.9891\n",
      "global round: 49  client: 75  local train loss: 1.1562\n",
      "global round: 49  client: 74  local train loss: 0.7356\n",
      "global round: 49  client: 41  local train loss: 1.1318\n",
      "global round: 49  avg train loss:0.1059  global test loss: 2.1149  global test accu: 0.3008\n",
      "================================================================================================================\n",
      "global round: 50  client: 55  local train loss: 1.5713\n",
      "global round: 50  client: 09  local train loss: 1.1654\n",
      "global round: 50  client: 31  local train loss: 1.1801\n",
      "global round: 50  client: 81  local train loss: 0.7847\n",
      "global round: 50  client: 33  local train loss: 1.2974\n",
      "global round: 50  client: 69  local train loss: 1.6126\n",
      "global round: 50  client: 37  local train loss: 0.7798\n",
      "global round: 50  client: 68  local train loss: 1.2059\n",
      "global round: 50  client: 74  local train loss: 0.7263\n",
      "global round: 50  client: 17  local train loss: 1.1132\n",
      "global round: 50  avg train loss:0.1040  global test loss: 2.1119  global test accu: 0.2972\n",
      "================================================================================================================\n",
      "global round: 51  client: 20  local train loss: 1.0724\n",
      "global round: 51  client: 36  local train loss: 1.1256\n",
      "global round: 51  client: 84  local train loss: 1.5410\n",
      "global round: 51  client: 72  local train loss: 1.1639\n",
      "global round: 51  client: 33  local train loss: 1.2206\n",
      "global round: 51  client: 58  local train loss: 0.8355\n",
      "global round: 51  client: 19  local train loss: 1.0657\n",
      "global round: 51  client: 42  local train loss: 1.0173\n",
      "global round: 51  client: 92  local train loss: 0.9682\n",
      "global round: 51  client: 74  local train loss: 0.7200\n",
      "global round: 51  avg train loss:0.0975  global test loss: 2.1126  global test accu: 0.2948\n",
      "================================================================================================================\n",
      "global round: 52  client: 89  local train loss: 1.1547\n",
      "global round: 52  client: 38  local train loss: 1.2945\n",
      "global round: 52  client: 61  local train loss: 1.4223\n",
      "global round: 52  client: 88  local train loss: 0.8276\n",
      "global round: 52  client: 67  local train loss: 1.1506\n",
      "global round: 52  client: 06  local train loss: 1.1637\n",
      "global round: 52  client: 41  local train loss: 1.1328\n",
      "global round: 52  client: 83  local train loss: 1.1070\n",
      "global round: 52  client: 64  local train loss: 1.1412\n",
      "global round: 52  client: 93  local train loss: 1.1746\n",
      "global round: 52  avg train loss:0.1052  global test loss: 2.1029  global test accu: 0.3119\n",
      "================================================================================================================\n",
      "global round: 53  client: 22  local train loss: 1.3693\n",
      "global round: 53  client: 98  local train loss: 1.2612\n",
      "global round: 53  client: 65  local train loss: 1.2070\n",
      "global round: 53  client: 94  local train loss: 0.9592\n",
      "global round: 53  client: 69  local train loss: 1.6009\n",
      "global round: 53  client: 17  local train loss: 1.0783\n",
      "global round: 53  client: 62  local train loss: 1.0669\n",
      "global round: 53  client: 85  local train loss: 1.3170\n",
      "global round: 53  client: 96  local train loss: 1.1817\n",
      "global round: 53  client: 45  local train loss: 1.1828\n",
      "global round: 53  avg train loss:0.1111  global test loss: 2.0970  global test accu: 0.3514\n",
      "================================================================================================================\n",
      "global round: 54  client: 78  local train loss: 1.2783\n",
      "global round: 54  client: 84  local train loss: 1.1605\n",
      "global round: 54  client: 79  local train loss: 1.1177\n",
      "global round: 54  client: 32  local train loss: 1.0933\n",
      "global round: 54  client: 54  local train loss: 1.1309\n",
      "global round: 54  client: 57  local train loss: 1.1131\n",
      "global round: 54  client: 38  local train loss: 1.2583\n",
      "global round: 54  client: 93  local train loss: 1.1456\n",
      "global round: 54  client: 37  local train loss: 0.7907\n",
      "global round: 54  client: 22  local train loss: 1.3200\n",
      "global round: 54  avg train loss:0.1037  global test loss: 2.0877  global test accu: 0.3819\n",
      "================================================================================================================\n",
      "global round: 55  client: 80  local train loss: 1.1976\n",
      "global round: 55  client: 71  local train loss: 1.2024\n",
      "global round: 55  client: 46  local train loss: 1.0573\n",
      "global round: 55  client: 96  local train loss: 1.1462\n",
      "global round: 55  client: 91  local train loss: 0.9718\n",
      "global round: 55  client: 10  local train loss: 1.2521\n",
      "global round: 55  client: 21  local train loss: 1.0876\n",
      "global round: 55  client: 62  local train loss: 1.0063\n",
      "global round: 55  client: 17  local train loss: 1.0598\n",
      "global round: 55  client: 22  local train loss: 1.3176\n",
      "global round: 55  avg train loss:0.1027  global test loss: 2.0892  global test accu: 0.3552\n",
      "================================================================================================================\n",
      "global round: 56  client: 11  local train loss: 1.3484\n",
      "global round: 56  client: 60  local train loss: 1.2772\n",
      "global round: 56  client: 07  local train loss: 1.0099\n",
      "global round: 56  client: 22  local train loss: 1.3229\n",
      "global round: 56  client: 33  local train loss: 1.1988\n",
      "global round: 56  client: 63  local train loss: 1.5344\n",
      "global round: 56  client: 34  local train loss: 0.9967\n",
      "global round: 56  client: 56  local train loss: 1.3220\n",
      "global round: 56  client: 62  local train loss: 0.9851\n",
      "global round: 56  client: 32  local train loss: 1.0720\n",
      "global round: 56  avg train loss:0.1097  global test loss: 2.0846  global test accu: 0.3501\n",
      "================================================================================================================\n",
      "global round: 57  client: 36  local train loss: 1.0573\n",
      "global round: 57  client: 65  local train loss: 1.1904\n",
      "global round: 57  client: 03  local train loss: 1.2105\n",
      "global round: 57  client: 21  local train loss: 0.9880\n",
      "global round: 57  client: 90  local train loss: 1.2011\n",
      "global round: 57  client: 66  local train loss: 1.0195\n",
      "global round: 57  client: 82  local train loss: 1.2105\n",
      "global round: 57  client: 68  local train loss: 1.1818\n",
      "global round: 57  client: 77  local train loss: 1.5527\n",
      "global round: 57  client: 31  local train loss: 1.1740\n",
      "global round: 57  avg train loss:0.1071  global test loss: 2.0860  global test accu: 0.3327\n",
      "================================================================================================================\n",
      "global round: 58  client: 43  local train loss: 1.2345\n",
      "global round: 58  client: 37  local train loss: 0.7644\n",
      "global round: 58  client: 82  local train loss: 1.1497\n",
      "global round: 58  client: 42  local train loss: 0.9885\n",
      "global round: 58  client: 15  local train loss: 1.2497\n",
      "global round: 58  client: 78  local train loss: 1.2255\n",
      "global round: 58  client: 05  local train loss: 1.0865\n",
      "global round: 58  client: 62  local train loss: 0.9727\n",
      "global round: 58  client: 36  local train loss: 1.0315\n",
      "global round: 58  client: 08  local train loss: 1.3539\n",
      "global round: 58  avg train loss:0.1005  global test loss: 2.0819  global test accu: 0.3117\n",
      "================================================================================================================\n",
      "global round: 59  client: 74  local train loss: 0.7119\n",
      "global round: 59  client: 76  local train loss: 1.1942\n",
      "global round: 59  client: 64  local train loss: 1.1190\n",
      "global round: 59  client: 18  local train loss: 1.2871\n",
      "global round: 59  client: 90  local train loss: 1.1625\n",
      "global round: 59  client: 44  local train loss: 0.7600\n",
      "global round: 59  client: 54  local train loss: 1.1048\n",
      "global round: 59  client: 04  local train loss: 1.4696\n",
      "global round: 59  client: 50  local train loss: 1.2637\n",
      "global round: 59  client: 17  local train loss: 1.0499\n",
      "global round: 59  avg train loss:0.1011  global test loss: 2.0774  global test accu: 0.3208\n",
      "================================================================================================================\n",
      "global round: 60  client: 89  local train loss: 1.1641\n",
      "global round: 60  client: 63  local train loss: 1.2722\n",
      "global round: 60  client: 85  local train loss: 1.2532\n",
      "global round: 60  client: 73  local train loss: 1.3566\n",
      "global round: 60  client: 11  local train loss: 1.2625\n",
      "global round: 60  client: 75  local train loss: 1.1437\n",
      "global round: 60  client: 96  local train loss: 1.1373\n",
      "global round: 60  client: 54  local train loss: 1.1254\n",
      "global round: 60  client: 50  local train loss: 1.1969\n",
      "global round: 60  client: 84  local train loss: 1.1643\n",
      "global round: 60  avg train loss:0.1098  global test loss: 2.0712  global test accu: 0.3483\n",
      "================================================================================================================\n",
      "global round: 61  client: 53  local train loss: 1.1609\n",
      "global round: 61  client: 99  local train loss: 1.0966\n",
      "global round: 61  client: 07  local train loss: 0.9460\n",
      "global round: 61  client: 45  local train loss: 1.1503\n",
      "global round: 61  client: 38  local train loss: 1.2507\n",
      "global round: 61  client: 19  local train loss: 1.0617\n",
      "global round: 61  client: 81  local train loss: 0.7903\n",
      "global round: 61  client: 68  local train loss: 1.1813\n",
      "global round: 61  client: 42  local train loss: 0.9527\n",
      "global round: 61  client: 04  local train loss: 1.3393\n",
      "global round: 61  avg train loss:0.0994  global test loss: 2.0688  global test accu: 0.3488\n",
      "================================================================================================================\n",
      "global round: 62  client: 73  local train loss: 1.1693\n",
      "global round: 62  client: 03  local train loss: 1.1674\n",
      "global round: 62  client: 65  local train loss: 1.1750\n",
      "global round: 62  client: 13  local train loss: 1.6025\n",
      "global round: 62  client: 25  local train loss: 1.1519\n",
      "global round: 62  client: 19  local train loss: 1.0587\n",
      "global round: 62  client: 17  local train loss: 1.0519\n",
      "global round: 62  client: 33  local train loss: 1.1877\n",
      "global round: 62  client: 40  local train loss: 1.1056\n",
      "global round: 62  client: 53  local train loss: 1.0178\n",
      "global round: 62  avg train loss:0.1063  global test loss: 2.0681  global test accu: 0.3786\n",
      "================================================================================================================\n",
      "global round: 63  client: 05  local train loss: 1.0477\n",
      "global round: 63  client: 19  local train loss: 1.0362\n",
      "global round: 63  client: 06  local train loss: 1.1327\n",
      "global round: 63  client: 35  local train loss: 1.2029\n",
      "global round: 63  client: 89  local train loss: 1.1105\n",
      "global round: 63  client: 78  local train loss: 1.1855\n",
      "global round: 63  client: 42  local train loss: 0.9611\n",
      "global round: 63  client: 47  local train loss: 1.0523\n",
      "global round: 63  client: 50  local train loss: 1.1779\n",
      "global round: 63  client: 25  local train loss: 1.1299\n",
      "global round: 63  avg train loss:0.1003  global test loss: 2.0648  global test accu: 0.3818\n",
      "================================================================================================================\n",
      "global round: 64  client: 14  local train loss: 1.0400\n",
      "global round: 64  client: 04  local train loss: 1.3455\n",
      "global round: 64  client: 60  local train loss: 1.2304\n",
      "global round: 64  client: 42  local train loss: 0.9596\n",
      "global round: 64  client: 61  local train loss: 1.4404\n",
      "global round: 64  client: 49  local train loss: 1.2984\n",
      "global round: 64  client: 97  local train loss: 1.0052\n",
      "global round: 64  client: 40  local train loss: 1.0728\n",
      "global round: 64  client: 06  local train loss: 1.1096\n",
      "global round: 64  client: 37  local train loss: 0.7819\n",
      "global round: 64  avg train loss:0.1026  global test loss: 2.0599  global test accu: 0.4022\n",
      "================================================================================================================\n",
      "global round: 65  client: 67  local train loss: 1.1599\n",
      "global round: 65  client: 30  local train loss: 1.0573\n",
      "global round: 65  client: 45  local train loss: 1.1115\n",
      "global round: 65  client: 59  local train loss: 1.1965\n",
      "global round: 65  client: 46  local train loss: 0.9570\n",
      "global round: 65  client: 17  local train loss: 1.0023\n",
      "global round: 65  client: 80  local train loss: 1.2000\n",
      "global round: 65  client: 88  local train loss: 0.7746\n",
      "global round: 65  client: 27  local train loss: 1.2208\n",
      "global round: 65  client: 36  local train loss: 1.0199\n",
      "global round: 65  avg train loss:0.0973  global test loss: 2.0615  global test accu: 0.3919\n",
      "================================================================================================================\n",
      "global round: 66  client: 98  local train loss: 1.2224\n",
      "global round: 66  client: 44  local train loss: 0.7299\n",
      "global round: 66  client: 17  local train loss: 1.0114\n",
      "global round: 66  client: 04  local train loss: 1.3152\n",
      "global round: 66  client: 52  local train loss: 1.2256\n",
      "global round: 66  client: 77  local train loss: 1.5201\n",
      "global round: 66  client: 82  local train loss: 1.1373\n",
      "global round: 66  client: 73  local train loss: 1.1538\n",
      "global round: 66  client: 87  local train loss: 1.2935\n",
      "global round: 66  client: 16  local train loss: 1.2226\n",
      "global round: 66  avg train loss:0.1076  global test loss: 2.0539  global test accu: 0.4357\n",
      "================================================================================================================\n",
      "global round: 67  client: 49  local train loss: 1.1392\n",
      "global round: 67  client: 02  local train loss: 1.3066\n",
      "global round: 67  client: 12  local train loss: 1.2229\n",
      "global round: 67  client: 87  local train loss: 1.2436\n",
      "global round: 67  client: 69  local train loss: 1.5948\n",
      "global round: 67  client: 85  local train loss: 1.2452\n",
      "global round: 67  client: 10  local train loss: 1.1438\n",
      "global round: 67  client: 22  local train loss: 1.2922\n",
      "global round: 67  client: 37  local train loss: 0.7665\n",
      "global round: 67  client: 88  local train loss: 0.8009\n",
      "global round: 67  avg train loss:0.1069  global test loss: 2.0429  global test accu: 0.4868\n",
      "================================================================================================================\n",
      "global round: 68  client: 57  local train loss: 1.0574\n",
      "global round: 68  client: 27  local train loss: 1.1362\n",
      "global round: 68  client: 56  local train loss: 1.1313\n",
      "global round: 68  client: 85  local train loss: 1.2465\n",
      "global round: 68  client: 42  local train loss: 0.9576\n",
      "global round: 68  client: 99  local train loss: 0.9150\n",
      "global round: 68  client: 82  local train loss: 1.0887\n",
      "global round: 68  client: 19  local train loss: 1.0290\n",
      "global round: 68  client: 31  local train loss: 1.1638\n",
      "global round: 68  client: 53  local train loss: 1.0035\n",
      "global round: 68  avg train loss:0.0975  global test loss: 2.0419  global test accu: 0.4788\n",
      "================================================================================================================\n",
      "global round: 69  client: 97  local train loss: 0.9624\n",
      "global round: 69  client: 67  local train loss: 1.0762\n",
      "global round: 69  client: 68  local train loss: 1.1799\n",
      "global round: 69  client: 32  local train loss: 1.0460\n",
      "global round: 69  client: 53  local train loss: 0.9948\n",
      "global round: 69  client: 40  local train loss: 1.0808\n",
      "global round: 69  client: 82  local train loss: 1.0671\n",
      "global round: 69  client: 49  local train loss: 1.1354\n",
      "global round: 69  client: 87  local train loss: 1.2195\n",
      "global round: 69  client: 14  local train loss: 0.8972\n",
      "global round: 69  avg train loss:0.0969  global test loss: 2.0325  global test accu: 0.4860\n",
      "================================================================================================================\n",
      "global round: 70  client: 69  local train loss: 1.5454\n",
      "global round: 70  client: 56  local train loss: 1.1275\n",
      "global round: 70  client: 78  local train loss: 1.1738\n",
      "global round: 70  client: 46  local train loss: 0.9322\n",
      "global round: 70  client: 82  local train loss: 1.0495\n",
      "global round: 70  client: 17  local train loss: 1.0051\n",
      "global round: 70  client: 88  local train loss: 0.7774\n",
      "global round: 70  client: 47  local train loss: 1.0207\n",
      "global round: 70  client: 29  local train loss: 1.5310\n",
      "global round: 70  client: 26  local train loss: 1.4225\n",
      "global round: 70  avg train loss:0.1053  global test loss: 2.0278  global test accu: 0.4930\n",
      "================================================================================================================\n",
      "global round: 71  client: 49  local train loss: 1.1282\n",
      "global round: 71  client: 21  local train loss: 0.9739\n",
      "global round: 71  client: 12  local train loss: 1.1427\n",
      "global round: 71  client: 79  local train loss: 1.0703\n",
      "global round: 71  client: 42  local train loss: 0.9667\n",
      "global round: 71  client: 58  local train loss: 0.7511\n",
      "global round: 71  client: 27  local train loss: 1.1274\n",
      "global round: 71  client: 35  local train loss: 1.1455\n",
      "global round: 71  client: 08  local train loss: 1.3444\n",
      "global round: 71  client: 99  local train loss: 0.9279\n",
      "global round: 71  avg train loss:0.0962  global test loss: 2.0256  global test accu: 0.4994\n",
      "================================================================================================================\n",
      "global round: 72  client: 43  local train loss: 1.2305\n",
      "global round: 72  client: 26  local train loss: 1.2782\n",
      "global round: 72  client: 34  local train loss: 0.9615\n",
      "global round: 72  client: 39  local train loss: 1.5387\n",
      "global round: 72  client: 97  local train loss: 0.9692\n",
      "global round: 72  client: 92  local train loss: 0.9702\n",
      "global round: 72  client: 27  local train loss: 1.1195\n",
      "global round: 72  client: 54  local train loss: 1.0997\n",
      "global round: 72  client: 74  local train loss: 0.6972\n",
      "global round: 72  client: 35  local train loss: 1.1209\n",
      "global round: 72  avg train loss:0.0999  global test loss: 2.0270  global test accu: 0.4829\n",
      "================================================================================================================\n",
      "global round: 73  client: 10  local train loss: 1.1098\n",
      "global round: 73  client: 27  local train loss: 1.1014\n",
      "global round: 73  client: 11  local train loss: 1.2579\n",
      "global round: 73  client: 48  local train loss: 1.2276\n",
      "global round: 73  client: 43  local train loss: 1.2296\n",
      "global round: 73  client: 91  local train loss: 0.9420\n",
      "global round: 73  client: 53  local train loss: 0.9905\n",
      "global round: 73  client: 12  local train loss: 1.1566\n",
      "global round: 73  client: 32  local train loss: 1.0359\n",
      "global round: 73  client: 36  local train loss: 1.0069\n",
      "global round: 73  avg train loss:0.1005  global test loss: 2.0260  global test accu: 0.4708\n",
      "================================================================================================================\n",
      "global round: 74  client: 31  local train loss: 1.1426\n",
      "global round: 74  client: 15  local train loss: 1.1736\n",
      "global round: 74  client: 49  local train loss: 1.1073\n",
      "global round: 74  client: 65  local train loss: 1.1517\n",
      "global round: 74  client: 91  local train loss: 0.9029\n",
      "global round: 74  client: 52  local train loss: 1.2134\n",
      "global round: 74  client: 22  local train loss: 1.2289\n",
      "global round: 74  client: 56  local train loss: 1.1258\n",
      "global round: 74  client: 38  local train loss: 1.2737\n",
      "global round: 74  client: 62  local train loss: 0.9494\n",
      "global round: 74  avg train loss:0.1024  global test loss: 2.0173  global test accu: 0.4842\n",
      "================================================================================================================\n",
      "global round: 75  client: 97  local train loss: 0.9465\n",
      "global round: 75  client: 18  local train loss: 1.1781\n",
      "global round: 75  client: 67  local train loss: 1.0308\n",
      "global round: 75  client: 36  local train loss: 0.9757\n",
      "global round: 75  client: 40  local train loss: 1.0713\n",
      "global round: 75  client: 41  local train loss: 1.1074\n",
      "global round: 75  client: 80  local train loss: 1.1625\n",
      "global round: 75  client: 52  local train loss: 1.1918\n",
      "global round: 75  client: 78  local train loss: 1.1308\n",
      "global round: 75  client: 03  local train loss: 1.1607\n",
      "global round: 75  avg train loss:0.0996  global test loss: 2.0172  global test accu: 0.4669\n",
      "================================================================================================================\n",
      "global round: 76  client: 45  local train loss: 1.1024\n",
      "global round: 76  client: 14  local train loss: 0.9233\n",
      "global round: 76  client: 46  local train loss: 0.9525\n",
      "global round: 76  client: 13  local train loss: 1.5550\n",
      "global round: 76  client: 79  local train loss: 0.9888\n",
      "global round: 76  client: 00  local train loss: 1.2085\n",
      "global round: 76  client: 71  local train loss: 1.1753\n",
      "global round: 76  client: 11  local train loss: 1.2769\n",
      "global round: 76  client: 29  local train loss: 1.4408\n",
      "global round: 76  client: 35  local train loss: 1.1127\n",
      "global round: 76  avg train loss:0.1067  global test loss: 2.0173  global test accu: 0.4607\n",
      "================================================================================================================\n",
      "global round: 77  client: 24  local train loss: 1.1639\n",
      "global round: 77  client: 95  local train loss: 1.2220\n",
      "global round: 77  client: 82  local train loss: 1.0153\n",
      "global round: 77  client: 13  local train loss: 1.5113\n",
      "global round: 77  client: 48  local train loss: 1.1448\n",
      "global round: 77  client: 54  local train loss: 1.0897\n",
      "global round: 77  client: 97  local train loss: 0.9160\n",
      "global round: 77  client: 72  local train loss: 1.1354\n",
      "global round: 77  client: 87  local train loss: 1.2108\n",
      "global round: 77  client: 89  local train loss: 1.1057\n",
      "global round: 77  avg train loss:0.1047  global test loss: 2.0175  global test accu: 0.4506\n",
      "================================================================================================================\n",
      "global round: 78  client: 98  local train loss: 1.1824\n",
      "global round: 78  client: 00  local train loss: 1.1267\n",
      "global round: 78  client: 40  local train loss: 1.0534\n",
      "global round: 78  client: 71  local train loss: 1.0714\n",
      "global round: 78  client: 82  local train loss: 1.0276\n",
      "global round: 78  client: 74  local train loss: 0.6993\n",
      "global round: 78  client: 51  local train loss: 1.0577\n",
      "global round: 78  client: 54  local train loss: 1.1154\n",
      "global round: 78  client: 95  local train loss: 1.1667\n",
      "global round: 78  client: 73  local train loss: 1.1241\n",
      "global round: 78  avg train loss:0.0966  global test loss: 2.0142  global test accu: 0.4549\n",
      "================================================================================================================\n",
      "global round: 79  client: 14  local train loss: 0.9045\n",
      "global round: 79  client: 58  local train loss: 0.7031\n",
      "global round: 79  client: 42  local train loss: 0.9532\n",
      "global round: 79  client: 93  local train loss: 1.1343\n",
      "global round: 79  client: 60  local train loss: 1.1991\n",
      "global round: 79  client: 61  local train loss: 1.3668\n",
      "global round: 79  client: 18  local train loss: 1.1457\n",
      "global round: 79  client: 92  local train loss: 0.9223\n",
      "global round: 79  client: 97  local train loss: 0.9213\n",
      "global round: 79  client: 35  local train loss: 1.0785\n",
      "global round: 79  avg train loss:0.0939  global test loss: 2.0077  global test accu: 0.4645\n",
      "================================================================================================================\n",
      "global round: 80  client: 82  local train loss: 1.0308\n",
      "global round: 80  client: 11  local train loss: 1.2486\n",
      "global round: 80  client: 70  local train loss: 1.0320\n",
      "global round: 80  client: 48  local train loss: 1.1300\n",
      "global round: 80  client: 51  local train loss: 0.9450\n",
      "global round: 80  client: 52  local train loss: 1.1761\n",
      "global round: 80  client: 32  local train loss: 1.0223\n",
      "global round: 80  client: 14  local train loss: 0.8937\n",
      "global round: 80  client: 56  local train loss: 1.1253\n",
      "global round: 80  client: 42  local train loss: 0.9203\n",
      "global round: 80  avg train loss:0.0957  global test loss: 2.0028  global test accu: 0.4512\n",
      "================================================================================================================\n",
      "global round: 81  client: 26  local train loss: 1.2654\n",
      "global round: 81  client: 38  local train loss: 1.2688\n",
      "global round: 81  client: 13  local train loss: 1.5121\n",
      "global round: 81  client: 40  local train loss: 1.0380\n",
      "global round: 81  client: 34  local train loss: 0.9018\n",
      "global round: 81  client: 64  local train loss: 1.1123\n",
      "global round: 81  client: 62  local train loss: 0.9480\n",
      "global round: 81  client: 19  local train loss: 0.9890\n",
      "global round: 81  client: 42  local train loss: 0.9119\n",
      "global round: 81  client: 25  local train loss: 1.1199\n",
      "global round: 81  avg train loss:0.1006  global test loss: 1.9998  global test accu: 0.4504\n",
      "================================================================================================================\n",
      "global round: 82  client: 79  local train loss: 0.9515\n",
      "global round: 82  client: 76  local train loss: 1.1278\n",
      "global round: 82  client: 14  local train loss: 0.8798\n",
      "global round: 82  client: 64  local train loss: 1.0627\n",
      "global round: 82  client: 24  local train loss: 1.0615\n",
      "global round: 82  client: 01  local train loss: 1.2725\n",
      "global round: 82  client: 22  local train loss: 1.2071\n",
      "global round: 82  client: 05  local train loss: 1.0111\n",
      "global round: 82  client: 87  local train loss: 1.2262\n",
      "global round: 82  client: 54  local train loss: 1.1118\n",
      "global round: 82  avg train loss:0.0992  global test loss: 1.9921  global test accu: 0.4773\n",
      "================================================================================================================\n",
      "global round: 83  client: 66  local train loss: 0.9696\n",
      "global round: 83  client: 13  local train loss: 1.5113\n",
      "global round: 83  client: 32  local train loss: 0.9951\n",
      "global round: 83  client: 90  local train loss: 1.1660\n",
      "global round: 83  client: 45  local train loss: 1.1066\n",
      "global round: 83  client: 73  local train loss: 1.0735\n",
      "global round: 83  client: 84  local train loss: 1.1294\n",
      "global round: 83  client: 91  local train loss: 0.8912\n",
      "global round: 83  client: 38  local train loss: 1.2641\n",
      "global round: 83  client: 71  local train loss: 1.0667\n",
      "global round: 83  avg train loss:0.1016  global test loss: 1.9883  global test accu: 0.4863\n",
      "================================================================================================================\n",
      "global round: 84  client: 86  local train loss: 1.3829\n",
      "global round: 84  client: 39  local train loss: 1.4906\n",
      "global round: 84  client: 71  local train loss: 1.0847\n",
      "global round: 84  client: 97  local train loss: 0.9114\n",
      "global round: 84  client: 75  local train loss: 1.1259\n",
      "global round: 84  client: 18  local train loss: 1.1397\n",
      "global round: 84  client: 53  local train loss: 0.9740\n",
      "global round: 84  client: 57  local train loss: 1.0299\n",
      "global round: 84  client: 29  local train loss: 1.4400\n",
      "global round: 84  client: 04  local train loss: 1.2927\n",
      "global round: 84  avg train loss:0.1079  global test loss: 1.9864  global test accu: 0.5065\n",
      "================================================================================================================\n",
      "global round: 85  client: 66  local train loss: 0.9294\n",
      "global round: 85  client: 60  local train loss: 1.1855\n",
      "global round: 85  client: 58  local train loss: 0.6874\n",
      "global round: 85  client: 47  local train loss: 1.0061\n",
      "global round: 85  client: 76  local train loss: 1.0747\n",
      "global round: 85  client: 85  local train loss: 1.2583\n",
      "global round: 85  client: 61  local train loss: 1.3138\n",
      "global round: 85  client: 09  local train loss: 1.1162\n",
      "global round: 85  client: 10  local train loss: 1.0602\n",
      "global round: 85  client: 12  local train loss: 1.1551\n",
      "global round: 85  avg train loss:0.0981  global test loss: 1.9849  global test accu: 0.5124\n",
      "================================================================================================================\n",
      "global round: 86  client: 85  local train loss: 1.1994\n",
      "global round: 86  client: 53  local train loss: 0.9564\n",
      "global round: 86  client: 99  local train loss: 0.8996\n",
      "global round: 86  client: 45  local train loss: 1.0565\n",
      "global round: 86  client: 03  local train loss: 1.0894\n",
      "global round: 86  client: 94  local train loss: 0.9359\n",
      "global round: 86  client: 43  local train loss: 1.2364\n",
      "global round: 86  client: 50  local train loss: 1.1778\n",
      "global round: 86  client: 04  local train loss: 1.2439\n",
      "global round: 86  client: 35  local train loss: 1.0762\n",
      "global round: 86  avg train loss:0.0988  global test loss: 1.9837  global test accu: 0.5165\n",
      "================================================================================================================\n",
      "global round: 87  client: 79  local train loss: 0.9550\n",
      "global round: 87  client: 00  local train loss: 1.1266\n",
      "global round: 87  client: 47  local train loss: 1.0115\n",
      "global round: 87  client: 97  local train loss: 0.9143\n",
      "global round: 87  client: 42  local train loss: 0.9086\n",
      "global round: 87  client: 51  local train loss: 0.9433\n",
      "global round: 87  client: 41  local train loss: 1.0625\n",
      "global round: 87  client: 58  local train loss: 0.6659\n",
      "global round: 87  client: 18  local train loss: 1.1205\n",
      "global round: 87  client: 02  local train loss: 1.2049\n",
      "global round: 87  avg train loss:0.0901  global test loss: 1.9803  global test accu: 0.5007\n",
      "================================================================================================================\n",
      "global round: 88  client: 39  local train loss: 1.4513\n",
      "global round: 88  client: 93  local train loss: 1.1235\n",
      "global round: 88  client: 13  local train loss: 1.5161\n",
      "global round: 88  client: 45  local train loss: 1.0345\n",
      "global round: 88  client: 77  local train loss: 1.5167\n",
      "global round: 88  client: 50  local train loss: 1.0866\n",
      "global round: 88  client: 67  local train loss: 1.0130\n",
      "global round: 88  client: 06  local train loss: 1.1050\n",
      "global round: 88  client: 26  local train loss: 1.2725\n",
      "global round: 88  client: 75  local train loss: 1.1041\n",
      "global round: 88  avg train loss:0.1111  global test loss: 1.9727  global test accu: 0.5355\n",
      "================================================================================================================\n",
      "global round: 89  client: 44  local train loss: 0.7505\n",
      "global round: 89  client: 37  local train loss: 0.7575\n",
      "global round: 89  client: 28  local train loss: 1.1065\n",
      "global round: 89  client: 03  local train loss: 1.0858\n",
      "global round: 89  client: 76  local train loss: 1.0776\n",
      "global round: 89  client: 79  local train loss: 0.9423\n",
      "global round: 89  client: 36  local train loss: 0.9709\n",
      "global round: 89  client: 16  local train loss: 1.1518\n",
      "global round: 89  client: 55  local train loss: 1.5280\n",
      "global round: 89  client: 96  local train loss: 1.1272\n",
      "global round: 89  avg train loss:0.0954  global test loss: 1.9714  global test accu: 0.5488\n",
      "================================================================================================================\n",
      "global round: 90  client: 22  local train loss: 1.2016\n",
      "global round: 90  client: 38  local train loss: 1.2621\n",
      "global round: 90  client: 36  local train loss: 0.9392\n",
      "global round: 90  client: 21  local train loss: 0.9670\n",
      "global round: 90  client: 47  local train loss: 0.9997\n",
      "global round: 90  client: 12  local train loss: 1.1090\n",
      "global round: 90  client: 42  local train loss: 0.9110\n",
      "global round: 90  client: 41  local train loss: 1.0410\n",
      "global round: 90  client: 46  local train loss: 0.9153\n",
      "global round: 90  client: 03  local train loss: 1.0934\n",
      "global round: 90  avg train loss:0.0949  global test loss: 1.9688  global test accu: 0.5170\n",
      "================================================================================================================\n",
      "global round: 91  client: 20  local train loss: 1.0360\n",
      "global round: 91  client: 57  local train loss: 0.9765\n",
      "global round: 91  client: 44  local train loss: 0.7209\n",
      "global round: 91  client: 37  local train loss: 0.7672\n",
      "global round: 91  client: 12  local train loss: 1.1184\n",
      "global round: 91  client: 52  local train loss: 1.1749\n",
      "global round: 91  client: 69  local train loss: 1.5360\n",
      "global round: 91  client: 23  local train loss: 1.4262\n",
      "global round: 91  client: 50  local train loss: 1.0781\n",
      "global round: 91  client: 41  local train loss: 1.0447\n",
      "global round: 91  avg train loss:0.0989  global test loss: 1.9594  global test accu: 0.5396\n",
      "================================================================================================================\n",
      "global round: 92  client: 90  local train loss: 1.1065\n",
      "global round: 92  client: 58  local train loss: 0.6468\n",
      "global round: 92  client: 16  local train loss: 1.0973\n",
      "global round: 92  client: 00  local train loss: 1.0605\n",
      "global round: 92  client: 03  local train loss: 1.0818\n",
      "global round: 92  client: 07  local train loss: 0.9414\n",
      "global round: 92  client: 21  local train loss: 0.9272\n",
      "global round: 92  client: 27  local train loss: 1.0839\n",
      "global round: 92  client: 63  local train loss: 1.2683\n",
      "global round: 92  client: 96  local train loss: 1.0310\n",
      "global round: 92  avg train loss:0.0931  global test loss: 1.9584  global test accu: 0.5422\n",
      "================================================================================================================\n",
      "global round: 93  client: 78  local train loss: 1.1191\n",
      "global round: 93  client: 35  local train loss: 1.0626\n",
      "global round: 93  client: 45  local train loss: 1.0198\n",
      "global round: 93  client: 28  local train loss: 1.0256\n",
      "global round: 93  client: 56  local train loss: 1.1360\n",
      "global round: 93  client: 88  local train loss: 0.7647\n",
      "global round: 93  client: 59  local train loss: 1.0833\n",
      "global round: 93  client: 94  local train loss: 0.8445\n",
      "global round: 93  client: 40  local train loss: 1.0426\n",
      "global round: 93  client: 20  local train loss: 0.9550\n",
      "global round: 93  avg train loss:0.0914  global test loss: 1.9529  global test accu: 0.5449\n",
      "================================================================================================================\n",
      "global round: 94  client: 79  local train loss: 0.9397\n",
      "global round: 94  client: 82  local train loss: 1.0456\n",
      "global round: 94  client: 40  local train loss: 1.0153\n",
      "global round: 94  client: 36  local train loss: 0.9307\n",
      "global round: 94  client: 10  local train loss: 1.0413\n",
      "global round: 94  client: 98  local train loss: 1.1862\n",
      "global round: 94  client: 35  local train loss: 1.0757\n",
      "global round: 94  client: 74  local train loss: 0.6779\n",
      "global round: 94  client: 50  local train loss: 1.0908\n",
      "global round: 94  client: 33  local train loss: 1.1786\n",
      "global round: 94  avg train loss:0.0926  global test loss: 1.9537  global test accu: 0.5375\n",
      "================================================================================================================\n",
      "global round: 95  client: 49  local train loss: 1.1341\n",
      "global round: 95  client: 37  local train loss: 0.7638\n",
      "global round: 95  client: 97  local train loss: 0.9080\n",
      "global round: 95  client: 19  local train loss: 0.9462\n",
      "global round: 95  client: 21  local train loss: 0.9322\n",
      "global round: 95  client: 28  local train loss: 1.0279\n",
      "global round: 95  client: 96  local train loss: 1.0245\n",
      "global round: 95  client: 50  local train loss: 1.0840\n",
      "global round: 95  client: 94  local train loss: 0.8392\n",
      "global round: 95  client: 51  local train loss: 0.9060\n",
      "global round: 95  avg train loss:0.0870  global test loss: 1.9501  global test accu: 0.5327\n",
      "================================================================================================================\n",
      "global round: 96  client: 25  local train loss: 1.1150\n",
      "global round: 96  client: 22  local train loss: 1.1616\n",
      "global round: 96  client: 57  local train loss: 0.9714\n",
      "global round: 96  client: 39  local train loss: 1.4480\n",
      "global round: 96  client: 98  local train loss: 1.1368\n",
      "global round: 96  client: 64  local train loss: 1.0627\n",
      "global round: 96  client: 47  local train loss: 0.9868\n",
      "global round: 96  client: 78  local train loss: 1.1192\n",
      "global round: 96  client: 10  local train loss: 1.0278\n",
      "global round: 96  client: 14  local train loss: 0.8728\n",
      "global round: 96  avg train loss:0.0991  global test loss: 1.9430  global test accu: 0.5463\n",
      "================================================================================================================\n",
      "global round: 97  client: 50  local train loss: 1.0635\n",
      "global round: 97  client: 46  local train loss: 0.8907\n",
      "global round: 97  client: 02  local train loss: 1.2161\n",
      "global round: 97  client: 23  local train loss: 0.9455\n",
      "global round: 97  client: 47  local train loss: 0.9687\n",
      "global round: 97  client: 48  local train loss: 1.1297\n",
      "global round: 97  client: 62  local train loss: 0.9197\n",
      "global round: 97  client: 08  local train loss: 1.2730\n",
      "global round: 97  client: 15  local train loss: 1.1615\n",
      "global round: 97  client: 28  local train loss: 1.0213\n",
      "global round: 97  avg train loss:0.0963  global test loss: 1.9372  global test accu: 0.5441\n",
      "================================================================================================================\n",
      "global round: 98  client: 50  local train loss: 1.0571\n",
      "global round: 98  client: 43  local train loss: 1.2458\n",
      "global round: 98  client: 29  local train loss: 1.4417\n",
      "global round: 98  client: 03  local train loss: 1.0789\n",
      "global round: 98  client: 02  local train loss: 1.1660\n",
      "global round: 98  client: 66  local train loss: 0.9472\n",
      "global round: 98  client: 86  local train loss: 1.1889\n",
      "global round: 98  client: 74  local train loss: 0.6902\n",
      "global round: 98  client: 21  local train loss: 0.9153\n",
      "global round: 98  client: 48  local train loss: 1.1417\n",
      "global round: 98  avg train loss:0.0988  global test loss: 1.9393  global test accu: 0.5148\n",
      "================================================================================================================\n",
      "global round: 99  client: 12  local train loss: 1.1177\n",
      "global round: 99  client: 02  local train loss: 1.1504\n",
      "global round: 99  client: 33  local train loss: 1.1088\n",
      "global round: 99  client: 88  local train loss: 0.7193\n",
      "global round: 99  client: 07  local train loss: 0.8617\n",
      "global round: 99  client: 25  local train loss: 1.0703\n",
      "global round: 99  client: 24  local train loss: 1.0468\n",
      "global round: 99  client: 35  local train loss: 1.0579\n",
      "global round: 99  client: 43  local train loss: 1.1857\n",
      "global round: 99  client: 50  local train loss: 1.0413\n",
      "global round: 99  avg train loss:0.0942  global test loss: 1.9318  global test accu: 0.5278\n",
      "================================================================================================================\n",
      "global round: 100  client: 33  local train loss: 1.1217\n",
      "global round: 100  client: 13  local train loss: 1.5085\n",
      "global round: 100  client: 14  local train loss: 0.8382\n",
      "global round: 100  client: 09  local train loss: 0.9805\n",
      "global round: 100  client: 95  local train loss: 1.1832\n",
      "global round: 100  client: 59  local train loss: 1.0272\n",
      "global round: 100  client: 31  local train loss: 1.1069\n",
      "global round: 100  client: 35  local train loss: 1.0676\n",
      "global round: 100  client: 91  local train loss: 0.8789\n",
      "global round: 100  client: 80  local train loss: 1.1269\n",
      "global round: 100  avg train loss:0.0985  global test loss: 1.9318  global test accu: 0.5168\n",
      "================================================================================================================\n",
      "global round: 101  client: 03  local train loss: 1.0349\n",
      "global round: 101  client: 63  local train loss: 1.1524\n",
      "global round: 101  client: 26  local train loss: 1.2439\n",
      "global round: 101  client: 40  local train loss: 1.0035\n",
      "global round: 101  client: 53  local train loss: 0.9307\n",
      "global round: 101  client: 50  local train loss: 1.0400\n",
      "global round: 101  client: 75  local train loss: 1.0726\n",
      "global round: 101  client: 86  local train loss: 1.1440\n",
      "global round: 101  client: 21  local train loss: 0.9045\n",
      "global round: 101  client: 97  local train loss: 0.8977\n",
      "global round: 101  avg train loss:0.0948  global test loss: 1.9314  global test accu: 0.5082\n",
      "================================================================================================================\n",
      "global round: 102  client: 37  local train loss: 0.7660\n",
      "global round: 102  client: 35  local train loss: 1.0593\n",
      "global round: 102  client: 53  local train loss: 0.9186\n",
      "global round: 102  client: 03  local train loss: 1.0164\n",
      "global round: 102  client: 18  local train loss: 1.1182\n",
      "global round: 102  client: 71  local train loss: 1.0630\n",
      "global round: 102  client: 27  local train loss: 1.0690\n",
      "global round: 102  client: 66  local train loss: 0.9138\n",
      "global round: 102  client: 16  local train loss: 1.0832\n",
      "global round: 102  client: 88  local train loss: 0.7544\n",
      "global round: 102  avg train loss:0.0887  global test loss: 1.9297  global test accu: 0.5177\n",
      "================================================================================================================\n",
      "global round: 103  client: 71  local train loss: 1.0284\n",
      "global round: 103  client: 10  local train loss: 1.0131\n",
      "global round: 103  client: 37  local train loss: 0.7525\n",
      "global round: 103  client: 89  local train loss: 1.0800\n",
      "global round: 103  client: 83  local train loss: 1.0023\n",
      "global round: 103  client: 79  local train loss: 0.9334\n",
      "global round: 103  client: 15  local train loss: 1.1370\n",
      "global round: 103  client: 84  local train loss: 1.0766\n",
      "global round: 103  client: 96  local train loss: 1.0034\n",
      "global round: 103  client: 86  local train loss: 1.1290\n",
      "global round: 103  avg train loss:0.0923  global test loss: 1.9279  global test accu: 0.5283\n",
      "================================================================================================================\n",
      "global round: 104  client: 33  local train loss: 1.1130\n",
      "global round: 104  client: 20  local train loss: 0.9640\n",
      "global round: 104  client: 45  local train loss: 1.0252\n",
      "global round: 104  client: 74  local train loss: 0.6515\n",
      "global round: 104  client: 41  local train loss: 1.0172\n",
      "global round: 104  client: 50  local train loss: 1.0373\n",
      "global round: 104  client: 11  local train loss: 1.2334\n",
      "global round: 104  client: 87  local train loss: 1.2133\n",
      "global round: 104  client: 61  local train loss: 1.3056\n",
      "global round: 104  client: 09  local train loss: 0.9778\n",
      "global round: 104  avg train loss:0.0958  global test loss: 1.9239  global test accu: 0.5303\n",
      "================================================================================================================\n",
      "global round: 105  client: 87  local train loss: 1.1558\n",
      "global round: 105  client: 76  local train loss: 1.0677\n",
      "global round: 105  client: 57  local train loss: 0.9640\n",
      "global round: 105  client: 33  local train loss: 1.1047\n",
      "global round: 105  client: 99  local train loss: 0.8469\n",
      "global round: 105  client: 08  local train loss: 1.1968\n",
      "global round: 105  client: 07  local train loss: 0.8611\n",
      "global round: 105  client: 43  local train loss: 1.1874\n",
      "global round: 105  client: 64  local train loss: 1.0313\n",
      "global round: 105  client: 22  local train loss: 1.1526\n",
      "global round: 105  avg train loss:0.0961  global test loss: 1.9144  global test accu: 0.5390\n",
      "================================================================================================================\n",
      "global round: 106  client: 96  local train loss: 0.9953\n",
      "global round: 106  client: 34  local train loss: 0.8949\n",
      "global round: 106  client: 82  local train loss: 1.0080\n",
      "global round: 106  client: 37  local train loss: 0.7586\n",
      "global round: 106  client: 94  local train loss: 0.8104\n",
      "global round: 106  client: 05  local train loss: 0.9923\n",
      "global round: 106  client: 77  local train loss: 1.4523\n",
      "global round: 106  client: 51  local train loss: 0.9006\n",
      "global round: 106  client: 70  local train loss: 0.8682\n",
      "global round: 106  client: 80  local train loss: 1.0957\n",
      "global round: 106  avg train loss:0.0889  global test loss: 1.9138  global test accu: 0.5458\n",
      "================================================================================================================\n",
      "global round: 107  client: 50  local train loss: 1.0338\n",
      "global round: 107  client: 21  local train loss: 0.8859\n",
      "global round: 107  client: 53  local train loss: 0.9058\n",
      "global round: 107  client: 87  local train loss: 1.1392\n",
      "global round: 107  client: 93  local train loss: 1.1185\n",
      "global round: 107  client: 56  local train loss: 1.1054\n",
      "global round: 107  client: 64  local train loss: 1.0441\n",
      "global round: 107  client: 30  local train loss: 0.9434\n",
      "global round: 107  client: 20  local train loss: 0.9412\n",
      "global round: 107  client: 10  local train loss: 0.9951\n",
      "global round: 107  avg train loss:0.0919  global test loss: 1.9051  global test accu: 0.5546\n",
      "================================================================================================================\n",
      "global round: 108  client: 43  local train loss: 1.2137\n",
      "global round: 108  client: 72  local train loss: 0.9920\n",
      "global round: 108  client: 15  local train loss: 1.1441\n",
      "global round: 108  client: 95  local train loss: 1.1472\n",
      "global round: 108  client: 58  local train loss: 0.6475\n",
      "global round: 108  client: 98  local train loss: 1.1378\n",
      "global round: 108  client: 33  local train loss: 1.1016\n",
      "global round: 108  client: 73  local train loss: 1.0861\n",
      "global round: 108  client: 44  local train loss: 0.7116\n",
      "global round: 108  client: 78  local train loss: 1.0975\n",
      "global round: 108  avg train loss:0.0934  global test loss: 1.8995  global test accu: 0.5617\n",
      "================================================================================================================\n",
      "global round: 109  client: 29  local train loss: 1.3949\n",
      "global round: 109  client: 47  local train loss: 0.9581\n",
      "global round: 109  client: 23  local train loss: 0.9998\n",
      "global round: 109  client: 24  local train loss: 1.0206\n",
      "global round: 109  client: 38  local train loss: 1.2596\n",
      "global round: 109  client: 35  local train loss: 1.0363\n",
      "global round: 109  client: 70  local train loss: 0.8080\n",
      "global round: 109  client: 97  local train loss: 0.8617\n",
      "global round: 109  client: 92  local train loss: 0.9092\n",
      "global round: 109  client: 10  local train loss: 1.0105\n",
      "global round: 109  avg train loss:0.0933  global test loss: 1.8985  global test accu: 0.5493\n",
      "================================================================================================================\n",
      "global round: 110  client: 66  local train loss: 0.8919\n",
      "global round: 110  client: 56  local train loss: 1.1086\n",
      "global round: 110  client: 27  local train loss: 1.0404\n",
      "global round: 110  client: 00  local train loss: 1.0581\n",
      "global round: 110  client: 33  local train loss: 1.0937\n",
      "global round: 110  client: 97  local train loss: 0.8816\n",
      "global round: 110  client: 61  local train loss: 1.2434\n",
      "global round: 110  client: 01  local train loss: 1.1655\n",
      "global round: 110  client: 15  local train loss: 1.1223\n",
      "global round: 110  client: 07  local train loss: 0.8241\n",
      "global round: 110  avg train loss:0.0948  global test loss: 1.8942  global test accu: 0.5411\n",
      "================================================================================================================\n",
      "global round: 111  client: 51  local train loss: 0.8558\n",
      "global round: 111  client: 31  local train loss: 1.0711\n",
      "global round: 111  client: 86  local train loss: 1.1174\n",
      "global round: 111  client: 54  local train loss: 1.0787\n",
      "global round: 111  client: 69  local train loss: 1.4909\n",
      "global round: 111  client: 06  local train loss: 1.0653\n",
      "global round: 111  client: 70  local train loss: 0.8161\n",
      "global round: 111  client: 00  local train loss: 1.0210\n",
      "global round: 111  client: 07  local train loss: 0.8089\n",
      "global round: 111  client: 33  local train loss: 1.0706\n",
      "global round: 111  avg train loss:0.0945  global test loss: 1.8922  global test accu: 0.5346\n",
      "================================================================================================================\n",
      "global round: 112  client: 50  local train loss: 1.0076\n",
      "global round: 112  client: 61  local train loss: 1.2487\n",
      "global round: 112  client: 60  local train loss: 1.1513\n",
      "global round: 112  client: 41  local train loss: 1.0007\n",
      "global round: 112  client: 14  local train loss: 0.8298\n",
      "global round: 112  client: 59  local train loss: 1.0179\n",
      "global round: 112  client: 43  local train loss: 1.2063\n",
      "global round: 112  client: 79  local train loss: 0.9067\n",
      "global round: 112  client: 39  local train loss: 1.4608\n",
      "global round: 112  client: 06  local train loss: 1.0418\n",
      "global round: 112  avg train loss:0.0988  global test loss: 1.8870  global test accu: 0.5432\n",
      "================================================================================================================\n",
      "global round: 113  client: 53  local train loss: 0.8837\n",
      "global round: 113  client: 42  local train loss: 0.9041\n",
      "global round: 113  client: 15  local train loss: 1.1135\n",
      "global round: 113  client: 45  local train loss: 0.9863\n",
      "global round: 113  client: 46  local train loss: 0.8884\n",
      "global round: 113  client: 00  local train loss: 0.9997\n",
      "global round: 113  client: 57  local train loss: 0.9650\n",
      "global round: 113  client: 52  local train loss: 1.1417\n",
      "global round: 113  client: 68  local train loss: 1.1771\n",
      "global round: 113  client: 21  local train loss: 0.8923\n",
      "global round: 113  avg train loss:0.0905  global test loss: 1.8861  global test accu: 0.5275\n",
      "================================================================================================================\n",
      "global round: 114  client: 56  local train loss: 1.1019\n",
      "global round: 114  client: 51  local train loss: 0.8520\n",
      "global round: 114  client: 02  local train loss: 1.1429\n",
      "global round: 114  client: 29  local train loss: 1.3680\n",
      "global round: 114  client: 71  local train loss: 1.0205\n",
      "global round: 114  client: 72  local train loss: 0.8901\n",
      "global round: 114  client: 63  local train loss: 1.1166\n",
      "global round: 114  client: 80  local train loss: 1.1126\n",
      "global round: 114  client: 81  local train loss: 0.7771\n",
      "global round: 114  client: 55  local train loss: 1.4451\n",
      "global round: 114  avg train loss:0.0984  global test loss: 1.8819  global test accu: 0.5536\n",
      "================================================================================================================\n",
      "global round: 115  client: 28  local train loss: 1.0093\n",
      "global round: 115  client: 74  local train loss: 0.6479\n",
      "global round: 115  client: 13  local train loss: 1.5007\n",
      "global round: 115  client: 71  local train loss: 1.0262\n",
      "global round: 115  client: 97  local train loss: 0.8645\n",
      "global round: 115  client: 02  local train loss: 1.1326\n",
      "global round: 115  client: 70  local train loss: 0.7770\n",
      "global round: 115  client: 60  local train loss: 1.0727\n",
      "global round: 115  client: 77  local train loss: 1.4551\n",
      "global round: 115  client: 46  local train loss: 0.8466\n",
      "global round: 115  avg train loss:0.0939  global test loss: 1.8832  global test accu: 0.5361\n",
      "================================================================================================================\n",
      "global round: 116  client: 81  local train loss: 0.7146\n",
      "global round: 116  client: 20  local train loss: 0.9452\n",
      "global round: 116  client: 79  local train loss: 0.9059\n",
      "global round: 116  client: 44  local train loss: 0.7054\n",
      "global round: 116  client: 91  local train loss: 0.8591\n",
      "global round: 116  client: 10  local train loss: 1.0063\n",
      "global round: 116  client: 40  local train loss: 1.0115\n",
      "global round: 116  client: 97  local train loss: 0.8542\n",
      "global round: 116  client: 67  local train loss: 1.0019\n",
      "global round: 116  client: 34  local train loss: 0.8032\n",
      "global round: 116  avg train loss:0.0801  global test loss: 1.8799  global test accu: 0.5350\n",
      "================================================================================================================\n",
      "global round: 117  client: 01  local train loss: 1.0838\n",
      "global round: 117  client: 91  local train loss: 0.8337\n",
      "global round: 117  client: 79  local train loss: 0.8931\n",
      "global round: 117  client: 58  local train loss: 0.6219\n",
      "global round: 117  client: 70  local train loss: 0.7739\n",
      "global round: 117  client: 62  local train loss: 0.9006\n",
      "global round: 117  client: 11  local train loss: 1.1637\n",
      "global round: 117  client: 78  local train loss: 1.0498\n",
      "global round: 117  client: 46  local train loss: 0.8519\n",
      "global round: 117  client: 49  local train loss: 1.0564\n",
      "global round: 117  avg train loss:0.0839  global test loss: 1.8807  global test accu: 0.5133\n",
      "================================================================================================================\n",
      "global round: 118  client: 96  local train loss: 0.9767\n",
      "global round: 118  client: 97  local train loss: 0.8459\n",
      "global round: 118  client: 19  local train loss: 0.9500\n",
      "global round: 118  client: 90  local train loss: 1.0761\n",
      "global round: 118  client: 67  local train loss: 0.9168\n",
      "global round: 118  client: 59  local train loss: 1.0467\n",
      "global round: 118  client: 23  local train loss: 0.9695\n",
      "global round: 118  client: 74  local train loss: 0.6589\n",
      "global round: 118  client: 56  local train loss: 1.0890\n",
      "global round: 118  client: 79  local train loss: 0.8851\n",
      "global round: 118  avg train loss:0.0856  global test loss: 1.8793  global test accu: 0.5118\n",
      "================================================================================================================\n",
      "global round: 119  client: 01  local train loss: 1.0869\n",
      "global round: 119  client: 65  local train loss: 1.0875\n",
      "global round: 119  client: 49  local train loss: 1.0145\n",
      "global round: 119  client: 98  local train loss: 1.1029\n",
      "global round: 119  client: 88  local train loss: 0.7369\n",
      "global round: 119  client: 59  local train loss: 1.0157\n",
      "global round: 119  client: 15  local train loss: 1.1023\n",
      "global round: 119  client: 39  local train loss: 1.4273\n",
      "global round: 119  client: 43  local train loss: 1.2021\n",
      "global round: 119  client: 46  local train loss: 0.8173\n",
      "global round: 119  avg train loss:0.0963  global test loss: 1.8727  global test accu: 0.5230\n",
      "================================================================================================================\n",
      "global round: 120  client: 94  local train loss: 0.7983\n",
      "global round: 120  client: 69  local train loss: 1.4426\n",
      "global round: 120  client: 19  local train loss: 0.9274\n",
      "global round: 120  client: 13  local train loss: 1.4786\n",
      "global round: 120  client: 40  local train loss: 0.9476\n",
      "global round: 120  client: 18  local train loss: 1.0990\n",
      "global round: 120  client: 63  local train loss: 1.0839\n",
      "global round: 120  client: 51  local train loss: 0.8500\n",
      "global round: 120  client: 79  local train loss: 0.8827\n",
      "global round: 120  client: 80  local train loss: 1.1218\n",
      "global round: 120  avg train loss:0.0967  global test loss: 1.8714  global test accu: 0.5336\n",
      "================================================================================================================\n",
      "global round: 121  client: 06  local train loss: 1.0293\n",
      "global round: 121  client: 30  local train loss: 0.7975\n",
      "global round: 121  client: 01  local train loss: 1.0828\n",
      "global round: 121  client: 16  local train loss: 1.0723\n",
      "global round: 121  client: 46  local train loss: 0.8129\n",
      "global round: 121  client: 25  local train loss: 1.0477\n",
      "global round: 121  client: 14  local train loss: 0.7971\n",
      "global round: 121  client: 84  local train loss: 1.0347\n",
      "global round: 121  client: 03  local train loss: 1.0181\n",
      "global round: 121  client: 48  local train loss: 1.1223\n",
      "global round: 121  avg train loss:0.0892  global test loss: 1.8694  global test accu: 0.5333\n",
      "================================================================================================================\n",
      "global round: 122  client: 93  local train loss: 1.0937\n",
      "global round: 122  client: 15  local train loss: 1.1023\n",
      "global round: 122  client: 83  local train loss: 0.9350\n",
      "global round: 122  client: 58  local train loss: 0.6197\n",
      "global round: 122  client: 56  local train loss: 1.1096\n",
      "global round: 122  client: 51  local train loss: 0.8431\n",
      "global round: 122  client: 21  local train loss: 0.8668\n",
      "global round: 122  client: 72  local train loss: 0.9041\n",
      "global round: 122  client: 22  local train loss: 1.0955\n",
      "global round: 122  client: 86  local train loss: 1.0867\n",
      "global round: 122  avg train loss:0.0878  global test loss: 1.8619  global test accu: 0.5462\n",
      "================================================================================================================\n",
      "global round: 123  client: 29  local train loss: 1.3517\n",
      "global round: 123  client: 94  local train loss: 0.7821\n",
      "global round: 123  client: 19  local train loss: 0.9019\n",
      "global round: 123  client: 55  local train loss: 1.4214\n",
      "global round: 123  client: 39  local train loss: 1.4294\n",
      "global round: 123  client: 74  local train loss: 0.6386\n",
      "global round: 123  client: 75  local train loss: 1.0627\n",
      "global round: 123  client: 89  local train loss: 1.0103\n",
      "global round: 123  client: 70  local train loss: 0.7610\n",
      "global round: 123  client: 82  local train loss: 0.9277\n",
      "global round: 123  avg train loss:0.0935  global test loss: 1.8649  global test accu: 0.5358\n",
      "================================================================================================================\n",
      "global round: 124  client: 65  local train loss: 1.0191\n",
      "global round: 124  client: 15  local train loss: 1.0938\n",
      "global round: 124  client: 89  local train loss: 0.9724\n",
      "global round: 124  client: 18  local train loss: 1.0513\n",
      "global round: 124  client: 78  local train loss: 1.0500\n",
      "global round: 124  client: 82  local train loss: 0.9204\n",
      "global round: 124  client: 11  local train loss: 1.1248\n",
      "global round: 124  client: 52  local train loss: 1.1073\n",
      "global round: 124  client: 37  local train loss: 0.7504\n",
      "global round: 124  client: 96  local train loss: 0.9684\n",
      "global round: 124  avg train loss:0.0914  global test loss: 1.8584  global test accu: 0.5469\n",
      "================================================================================================================\n",
      "global round: 125  client: 56  local train loss: 1.0911\n",
      "global round: 125  client: 93  local train loss: 1.0700\n",
      "global round: 125  client: 28  local train loss: 0.9886\n",
      "global round: 125  client: 33  local train loss: 1.0658\n",
      "global round: 125  client: 97  local train loss: 0.8342\n",
      "global round: 125  client: 51  local train loss: 0.8390\n",
      "global round: 125  client: 32  local train loss: 0.9849\n",
      "global round: 125  client: 79  local train loss: 0.8726\n",
      "global round: 125  client: 20  local train loss: 0.8928\n",
      "global round: 125  client: 11  local train loss: 1.1029\n",
      "global round: 125  avg train loss:0.0886  global test loss: 1.8529  global test accu: 0.5352\n",
      "================================================================================================================\n",
      "global round: 126  client: 92  local train loss: 0.8618\n",
      "global round: 126  client: 05  local train loss: 0.9344\n",
      "global round: 126  client: 14  local train loss: 0.7885\n",
      "global round: 126  client: 82  local train loss: 0.9105\n",
      "global round: 126  client: 20  local train loss: 0.8666\n",
      "global round: 126  client: 25  local train loss: 1.0521\n",
      "global round: 126  client: 69  local train loss: 1.4475\n",
      "global round: 126  client: 57  local train loss: 0.9592\n",
      "global round: 126  client: 04  local train loss: 1.2277\n",
      "global round: 126  client: 47  local train loss: 0.9382\n",
      "global round: 126  avg train loss:0.0908  global test loss: 1.8442  global test accu: 0.5703\n",
      "================================================================================================================\n",
      "global round: 127  client: 62  local train loss: 0.8435\n",
      "global round: 127  client: 07  local train loss: 0.7898\n",
      "global round: 127  client: 60  local train loss: 1.0759\n",
      "global round: 127  client: 08  local train loss: 1.1821\n",
      "global round: 127  client: 79  local train loss: 0.8803\n",
      "global round: 127  client: 33  local train loss: 1.0231\n",
      "global round: 127  client: 21  local train loss: 0.8585\n",
      "global round: 127  client: 40  local train loss: 0.9684\n",
      "global round: 127  client: 20  local train loss: 0.8693\n",
      "global round: 127  client: 26  local train loss: 1.2109\n",
      "global round: 127  avg train loss:0.0882  global test loss: 1.8464  global test accu: 0.5267\n",
      "================================================================================================================\n",
      "global round: 128  client: 30  local train loss: 0.7767\n",
      "global round: 128  client: 19  local train loss: 0.9175\n",
      "global round: 128  client: 51  local train loss: 0.8290\n",
      "global round: 128  client: 54  local train loss: 1.0228\n",
      "global round: 128  client: 88  local train loss: 0.7104\n",
      "global round: 128  client: 84  local train loss: 0.9802\n",
      "global round: 128  client: 10  local train loss: 0.9871\n",
      "global round: 128  client: 03  local train loss: 1.0119\n",
      "global round: 128  client: 70  local train loss: 0.7485\n",
      "global round: 128  client: 29  local train loss: 1.3480\n",
      "global round: 128  avg train loss:0.0848  global test loss: 1.8448  global test accu: 0.5365\n",
      "================================================================================================================\n",
      "global round: 129  client: 13  local train loss: 1.4586\n",
      "global round: 129  client: 24  local train loss: 1.0250\n",
      "global round: 129  client: 11  local train loss: 1.0832\n",
      "global round: 129  client: 72  local train loss: 0.8936\n",
      "global round: 129  client: 61  local train loss: 1.2392\n",
      "global round: 129  client: 57  local train loss: 0.9299\n",
      "global round: 129  client: 18  local train loss: 1.0351\n",
      "global round: 129  client: 04  local train loss: 1.1664\n",
      "global round: 129  client: 02  local train loss: 1.1379\n",
      "global round: 129  client: 73  local train loss: 1.0397\n",
      "global round: 129  avg train loss:0.1001  global test loss: 1.8392  global test accu: 0.5706\n",
      "================================================================================================================\n",
      "global round: 130  client: 53  local train loss: 0.8805\n",
      "global round: 130  client: 02  local train loss: 1.1046\n",
      "global round: 130  client: 83  local train loss: 0.8836\n",
      "global round: 130  client: 74  local train loss: 0.6396\n",
      "global round: 130  client: 45  local train loss: 0.9482\n",
      "global round: 130  client: 81  local train loss: 0.7203\n",
      "global round: 130  client: 23  local train loss: 0.9543\n",
      "global round: 130  client: 89  local train loss: 0.9687\n",
      "global round: 130  client: 93  local train loss: 1.0599\n",
      "global round: 130  client: 14  local train loss: 0.7844\n",
      "global round: 130  avg train loss:0.0813  global test loss: 1.8364  global test accu: 0.5667\n",
      "================================================================================================================\n",
      "global round: 131  client: 12  local train loss: 1.1172\n",
      "global round: 131  client: 90  local train loss: 1.0363\n",
      "global round: 131  client: 38  local train loss: 1.2084\n",
      "global round: 131  client: 62  local train loss: 0.8356\n",
      "global round: 131  client: 33  local train loss: 1.0031\n",
      "global round: 131  client: 79  local train loss: 0.8565\n",
      "global round: 131  client: 83  local train loss: 0.8490\n",
      "global round: 131  client: 96  local train loss: 0.9784\n",
      "global round: 131  client: 08  local train loss: 1.1747\n",
      "global round: 131  client: 76  local train loss: 0.9987\n",
      "global round: 131  avg train loss:0.0914  global test loss: 1.8324  global test accu: 0.5626\n",
      "================================================================================================================\n",
      "global round: 132  client: 61  local train loss: 1.2036\n",
      "global round: 132  client: 94  local train loss: 0.7633\n",
      "global round: 132  client: 33  local train loss: 1.0035\n",
      "global round: 132  client: 52  local train loss: 1.0900\n",
      "global round: 132  client: 40  local train loss: 0.9429\n",
      "global round: 132  client: 92  local train loss: 0.8142\n",
      "global round: 132  client: 34  local train loss: 0.8078\n",
      "global round: 132  client: 20  local train loss: 0.8409\n",
      "global round: 132  client: 57  local train loss: 0.9305\n",
      "global round: 132  client: 60  local train loss: 1.0652\n",
      "global round: 132  avg train loss:0.0860  global test loss: 1.8249  global test accu: 0.5842\n",
      "================================================================================================================\n",
      "global round: 133  client: 49  local train loss: 1.0256\n",
      "global round: 133  client: 85  local train loss: 1.1973\n",
      "global round: 133  client: 52  local train loss: 1.0539\n",
      "global round: 133  client: 68  local train loss: 1.0853\n",
      "global round: 133  client: 00  local train loss: 0.9949\n",
      "global round: 133  client: 33  local train loss: 0.9893\n",
      "global round: 133  client: 83  local train loss: 0.8282\n",
      "global round: 133  client: 67  local train loss: 0.9197\n",
      "global round: 133  client: 08  local train loss: 1.1563\n",
      "global round: 133  client: 84  local train loss: 0.9729\n",
      "global round: 133  avg train loss:0.0929  global test loss: 1.8204  global test accu: 0.5946\n",
      "================================================================================================================\n",
      "global round: 134  client: 24  local train loss: 1.0221\n",
      "global round: 134  client: 56  local train loss: 1.0799\n",
      "global round: 134  client: 25  local train loss: 1.0463\n",
      "global round: 134  client: 53  local train loss: 0.8325\n",
      "global round: 134  client: 66  local train loss: 0.8893\n",
      "global round: 134  client: 91  local train loss: 0.8372\n",
      "global round: 134  client: 74  local train loss: 0.6647\n",
      "global round: 134  client: 50  local train loss: 1.0105\n",
      "global round: 134  client: 68  local train loss: 1.0143\n",
      "global round: 134  client: 09  local train loss: 0.9316\n",
      "global round: 134  avg train loss:0.0848  global test loss: 1.8188  global test accu: 0.5912\n",
      "================================================================================================================\n",
      "global round: 135  client: 49  local train loss: 0.9699\n",
      "global round: 135  client: 27  local train loss: 1.0399\n",
      "global round: 135  client: 29  local train loss: 1.3237\n",
      "global round: 135  client: 14  local train loss: 0.7748\n",
      "global round: 135  client: 25  local train loss: 1.0316\n",
      "global round: 135  client: 99  local train loss: 0.8115\n",
      "global round: 135  client: 24  local train loss: 1.0046\n",
      "global round: 135  client: 69  local train loss: 1.4266\n",
      "global round: 135  client: 00  local train loss: 0.9461\n",
      "global round: 135  client: 79  local train loss: 0.8628\n",
      "global round: 135  avg train loss:0.0927  global test loss: 1.8168  global test accu: 0.5790\n",
      "================================================================================================================\n",
      "global round: 136  client: 14  local train loss: 0.7272\n",
      "global round: 136  client: 52  local train loss: 1.0278\n",
      "global round: 136  client: 00  local train loss: 0.9249\n",
      "global round: 136  client: 05  local train loss: 0.9184\n",
      "global round: 136  client: 51  local train loss: 0.8234\n",
      "global round: 136  client: 07  local train loss: 0.7436\n",
      "global round: 136  client: 06  local train loss: 1.0350\n",
      "global round: 136  client: 67  local train loss: 0.9080\n",
      "global round: 136  client: 69  local train loss: 1.3880\n",
      "global round: 136  client: 04  local train loss: 1.1399\n",
      "global round: 136  avg train loss:0.0876  global test loss: 1.8111  global test accu: 0.5779\n",
      "================================================================================================================\n",
      "global round: 137  client: 67  local train loss: 0.8887\n",
      "global round: 137  client: 62  local train loss: 0.8416\n",
      "global round: 137  client: 23  local train loss: 0.9147\n",
      "global round: 137  client: 08  local train loss: 1.1357\n",
      "global round: 137  client: 79  local train loss: 0.8721\n",
      "global round: 137  client: 80  local train loss: 1.0849\n",
      "global round: 137  client: 83  local train loss: 0.8025\n",
      "global round: 137  client: 66  local train loss: 0.8550\n",
      "global round: 137  client: 89  local train loss: 0.9633\n",
      "global round: 137  client: 84  local train loss: 0.9351\n",
      "global round: 137  avg train loss:0.0845  global test loss: 1.8143  global test accu: 0.5663\n",
      "================================================================================================================\n",
      "global round: 138  client: 71  local train loss: 1.0203\n",
      "global round: 138  client: 16  local train loss: 1.0266\n",
      "global round: 138  client: 43  local train loss: 1.1942\n",
      "global round: 138  client: 30  local train loss: 0.7543\n",
      "global round: 138  client: 51  local train loss: 0.8029\n",
      "global round: 138  client: 54  local train loss: 1.0338\n",
      "global round: 138  client: 11  local train loss: 1.0962\n",
      "global round: 138  client: 80  local train loss: 1.1198\n",
      "global round: 138  client: 33  local train loss: 0.9599\n",
      "global round: 138  client: 77  local train loss: 1.4283\n",
      "global round: 138  avg train loss:0.0949  global test loss: 1.8131  global test accu: 0.5800\n",
      "================================================================================================================\n",
      "global round: 139  client: 43  local train loss: 1.2145\n",
      "global round: 139  client: 53  local train loss: 0.8347\n",
      "global round: 139  client: 60  local train loss: 1.0387\n",
      "global round: 139  client: 56  local train loss: 1.0950\n",
      "global round: 139  client: 96  local train loss: 0.9701\n",
      "global round: 139  client: 12  local train loss: 1.0121\n",
      "global round: 139  client: 41  local train loss: 0.9923\n",
      "global round: 139  client: 97  local train loss: 0.8349\n",
      "global round: 139  client: 91  local train loss: 0.7945\n",
      "global round: 139  client: 81  local train loss: 0.7090\n",
      "global round: 139  avg train loss:0.0863  global test loss: 1.8058  global test accu: 0.5782\n",
      "================================================================================================================\n",
      "global round: 140  client: 98  local train loss: 1.0832\n",
      "global round: 140  client: 52  local train loss: 1.0569\n",
      "global round: 140  client: 46  local train loss: 0.8141\n",
      "global round: 140  client: 84  local train loss: 0.9130\n",
      "global round: 140  client: 04  local train loss: 1.1717\n",
      "global round: 140  client: 55  local train loss: 1.4005\n",
      "global round: 140  client: 31  local train loss: 1.0933\n",
      "global round: 140  client: 59  local train loss: 0.9980\n",
      "global round: 140  client: 64  local train loss: 1.0415\n",
      "global round: 140  client: 49  local train loss: 0.9542\n",
      "global round: 140  avg train loss:0.0957  global test loss: 1.8032  global test accu: 0.5898\n",
      "================================================================================================================\n",
      "global round: 141  client: 89  local train loss: 0.9704\n",
      "global round: 141  client: 51  local train loss: 0.7939\n",
      "global round: 141  client: 78  local train loss: 1.0277\n",
      "global round: 141  client: 45  local train loss: 0.9353\n",
      "global round: 141  client: 99  local train loss: 0.7189\n",
      "global round: 141  client: 71  local train loss: 1.0177\n",
      "global round: 141  client: 81  local train loss: 0.7170\n",
      "global round: 141  client: 06  local train loss: 1.0062\n",
      "global round: 141  client: 80  local train loss: 1.1228\n",
      "global round: 141  client: 50  local train loss: 0.9739\n",
      "global round: 141  avg train loss:0.0844  global test loss: 1.8031  global test accu: 0.5701\n",
      "================================================================================================================\n",
      "global round: 142  client: 74  local train loss: 0.6714\n",
      "global round: 142  client: 70  local train loss: 0.7188\n",
      "global round: 142  client: 32  local train loss: 0.9062\n",
      "global round: 142  client: 13  local train loss: 1.4457\n",
      "global round: 142  client: 20  local train loss: 0.8142\n",
      "global round: 142  client: 68  local train loss: 1.0171\n",
      "global round: 142  client: 52  local train loss: 1.0580\n",
      "global round: 142  client: 12  local train loss: 1.0120\n",
      "global round: 142  client: 41  local train loss: 0.9096\n",
      "global round: 142  client: 93  local train loss: 1.0661\n",
      "global round: 142  avg train loss:0.0874  global test loss: 1.7974  global test accu: 0.6006\n",
      "================================================================================================================\n",
      "global round: 143  client: 20  local train loss: 0.8119\n",
      "global round: 143  client: 79  local train loss: 0.8615\n",
      "global round: 143  client: 47  local train loss: 0.9242\n",
      "global round: 143  client: 50  local train loss: 0.9499\n",
      "global round: 143  client: 60  local train loss: 0.9951\n",
      "global round: 143  client: 90  local train loss: 0.9912\n",
      "global round: 143  client: 95  local train loss: 1.1319\n",
      "global round: 143  client: 76  local train loss: 0.9831\n",
      "global round: 143  client: 30  local train loss: 0.7388\n",
      "global round: 143  client: 22  local train loss: 1.0612\n",
      "global round: 143  avg train loss:0.0859  global test loss: 1.7929  global test accu: 0.6046\n",
      "================================================================================================================\n",
      "global round: 144  client: 06  local train loss: 1.0003\n",
      "global round: 144  client: 66  local train loss: 0.8452\n",
      "global round: 144  client: 98  local train loss: 1.0325\n",
      "global round: 144  client: 14  local train loss: 0.7272\n",
      "global round: 144  client: 69  local train loss: 1.3812\n",
      "global round: 144  client: 17  local train loss: 0.9861\n",
      "global round: 144  client: 67  local train loss: 0.8904\n",
      "global round: 144  client: 56  local train loss: 1.1005\n",
      "global round: 144  client: 08  local train loss: 1.1235\n",
      "global round: 144  client: 36  local train loss: 0.9313\n",
      "global round: 144  avg train loss:0.0911  global test loss: 1.7884  global test accu: 0.5977\n",
      "================================================================================================================\n",
      "global round: 145  client: 36  local train loss: 0.8792\n",
      "global round: 145  client: 80  local train loss: 1.1104\n",
      "global round: 145  client: 16  local train loss: 0.9942\n",
      "global round: 145  client: 06  local train loss: 0.9965\n",
      "global round: 145  client: 25  local train loss: 1.0101\n",
      "global round: 145  client: 30  local train loss: 0.7336\n",
      "global round: 145  client: 92  local train loss: 0.7972\n",
      "global round: 145  client: 77  local train loss: 1.3942\n",
      "global round: 145  client: 17  local train loss: 0.8157\n",
      "global round: 145  client: 68  local train loss: 1.0178\n",
      "global round: 145  avg train loss:0.0886  global test loss: 1.7835  global test accu: 0.6101\n",
      "================================================================================================================\n",
      "global round: 146  client: 19  local train loss: 0.9278\n",
      "global round: 146  client: 44  local train loss: 0.7025\n",
      "global round: 146  client: 11  local train loss: 1.0279\n",
      "global round: 146  client: 52  local train loss: 1.0279\n",
      "global round: 146  client: 97  local train loss: 0.8264\n",
      "global round: 146  client: 23  local train loss: 0.8623\n",
      "global round: 146  client: 17  local train loss: 0.8231\n",
      "global round: 146  client: 72  local train loss: 0.8693\n",
      "global round: 146  client: 30  local train loss: 0.7178\n",
      "global round: 146  client: 31  local train loss: 1.0769\n",
      "global round: 146  avg train loss:0.0806  global test loss: 1.7841  global test accu: 0.6188\n",
      "================================================================================================================\n",
      "global round: 147  client: 63  local train loss: 1.0837\n",
      "global round: 147  client: 95  local train loss: 1.0284\n",
      "global round: 147  client: 78  local train loss: 1.0142\n",
      "global round: 147  client: 67  local train loss: 0.8891\n",
      "global round: 147  client: 85  local train loss: 1.0109\n",
      "global round: 147  client: 17  local train loss: 0.8108\n",
      "global round: 147  client: 36  local train loss: 0.8614\n",
      "global round: 147  client: 49  local train loss: 0.9578\n",
      "global round: 147  client: 90  local train loss: 0.9531\n",
      "global round: 147  client: 72  local train loss: 0.8706\n",
      "global round: 147  avg train loss:0.0862  global test loss: 1.7804  global test accu: 0.6222\n",
      "================================================================================================================\n",
      "global round: 148  client: 51  local train loss: 0.7873\n",
      "global round: 148  client: 62  local train loss: 0.8296\n",
      "global round: 148  client: 78  local train loss: 1.0123\n",
      "global round: 148  client: 67  local train loss: 0.8703\n",
      "global round: 148  client: 02  local train loss: 1.1120\n",
      "global round: 148  client: 01  local train loss: 1.0833\n",
      "global round: 148  client: 64  local train loss: 0.9611\n",
      "global round: 148  client: 14  local train loss: 0.7192\n",
      "global round: 148  client: 93  local train loss: 1.0607\n",
      "global round: 148  client: 47  local train loss: 0.9400\n",
      "global round: 148  avg train loss:0.0852  global test loss: 1.7735  global test accu: 0.6145\n",
      "================================================================================================================\n",
      "global round: 149  client: 62  local train loss: 0.8339\n",
      "global round: 149  client: 13  local train loss: 1.4319\n",
      "global round: 149  client: 90  local train loss: 0.9465\n",
      "global round: 149  client: 43  local train loss: 1.2048\n",
      "global round: 149  client: 31  local train loss: 1.0641\n",
      "global round: 149  client: 77  local train loss: 1.4066\n",
      "global round: 149  client: 07  local train loss: 0.7243\n",
      "global round: 149  client: 01  local train loss: 1.0184\n",
      "global round: 149  client: 05  local train loss: 0.9244\n",
      "global round: 149  client: 89  local train loss: 0.9403\n",
      "global round: 149  avg train loss:0.0954  global test loss: 1.7738  global test accu: 0.6070\n",
      "================================================================================================================\n",
      "global round: 150  client: 60  local train loss: 0.9804\n",
      "global round: 150  client: 47  local train loss: 0.9198\n",
      "global round: 150  client: 89  local train loss: 0.9122\n",
      "global round: 150  client: 91  local train loss: 0.7983\n",
      "global round: 150  client: 14  local train loss: 0.7333\n",
      "global round: 150  client: 12  local train loss: 0.9867\n",
      "global round: 150  client: 92  local train loss: 0.7893\n",
      "global round: 150  client: 64  local train loss: 0.9633\n",
      "global round: 150  client: 93  local train loss: 1.0468\n",
      "global round: 150  client: 83  local train loss: 0.8005\n",
      "global round: 150  avg train loss:0.0812  global test loss: 1.7664  global test accu: 0.6069\n",
      "================================================================================================================\n",
      "global round: 151  client: 73  local train loss: 1.0114\n",
      "global round: 151  client: 67  local train loss: 0.8597\n",
      "global round: 151  client: 07  local train loss: 0.6881\n",
      "global round: 151  client: 75  local train loss: 1.0444\n",
      "global round: 151  client: 24  local train loss: 0.9951\n",
      "global round: 151  client: 91  local train loss: 0.7498\n",
      "global round: 151  client: 28  local train loss: 1.0004\n",
      "global round: 151  client: 02  local train loss: 1.0792\n",
      "global round: 151  client: 79  local train loss: 0.8639\n",
      "global round: 151  client: 59  local train loss: 1.0056\n",
      "global round: 151  avg train loss:0.0845  global test loss: 1.7633  global test accu: 0.6034\n",
      "================================================================================================================\n",
      "global round: 152  client: 14  local train loss: 0.7230\n",
      "global round: 152  client: 15  local train loss: 1.0861\n",
      "global round: 152  client: 77  local train loss: 1.3930\n",
      "global round: 152  client: 05  local train loss: 0.9060\n",
      "global round: 152  client: 93  local train loss: 1.0291\n",
      "global round: 152  client: 55  local train loss: 1.3843\n",
      "global round: 152  client: 29  local train loss: 1.2921\n",
      "global round: 152  client: 06  local train loss: 0.9933\n",
      "global round: 152  client: 66  local train loss: 0.8391\n",
      "global round: 152  client: 67  local train loss: 0.8667\n",
      "global round: 152  avg train loss:0.0956  global test loss: 1.7570  global test accu: 0.6339\n",
      "================================================================================================================\n",
      "global round: 153  client: 44  local train loss: 0.6495\n",
      "global round: 153  client: 41  local train loss: 0.9192\n",
      "global round: 153  client: 30  local train loss: 0.7168\n",
      "global round: 153  client: 67  local train loss: 0.8668\n",
      "global round: 153  client: 63  local train loss: 0.9716\n",
      "global round: 153  client: 43  local train loss: 1.1897\n",
      "global round: 153  client: 39  local train loss: 1.4086\n",
      "global round: 153  client: 97  local train loss: 0.8158\n",
      "global round: 153  client: 78  local train loss: 0.9944\n",
      "global round: 153  client: 36  local train loss: 0.8662\n",
      "global round: 153  avg train loss:0.0854  global test loss: 1.7571  global test accu: 0.6239\n",
      "================================================================================================================\n",
      "global round: 154  client: 19  local train loss: 0.9282\n",
      "global round: 154  client: 21  local train loss: 0.8474\n",
      "global round: 154  client: 43  local train loss: 1.1791\n",
      "global round: 154  client: 73  local train loss: 1.0118\n",
      "global round: 154  client: 75  local train loss: 0.9930\n",
      "global round: 154  client: 03  local train loss: 0.9999\n",
      "global round: 154  client: 38  local train loss: 1.1673\n",
      "global round: 154  client: 12  local train loss: 0.9420\n",
      "global round: 154  client: 20  local train loss: 0.8059\n",
      "global round: 154  client: 52  local train loss: 1.0273\n",
      "global round: 154  avg train loss:0.0900  global test loss: 1.7558  global test accu: 0.6285\n",
      "================================================================================================================\n",
      "global round: 155  client: 18  local train loss: 1.0285\n",
      "global round: 155  client: 16  local train loss: 0.9537\n",
      "global round: 155  client: 06  local train loss: 0.9913\n",
      "global round: 155  client: 62  local train loss: 0.8283\n",
      "global round: 155  client: 05  local train loss: 0.8949\n",
      "global round: 155  client: 46  local train loss: 0.8133\n",
      "global round: 155  client: 33  local train loss: 0.9524\n",
      "global round: 155  client: 31  local train loss: 1.0663\n",
      "global round: 155  client: 36  local train loss: 0.8517\n",
      "global round: 155  client: 35  local train loss: 1.0390\n",
      "global round: 155  avg train loss:0.0856  global test loss: 1.7581  global test accu: 0.6025\n",
      "================================================================================================================\n",
      "global round: 156  client: 93  local train loss: 1.0210\n",
      "global round: 156  client: 76  local train loss: 0.9770\n",
      "global round: 156  client: 81  local train loss: 0.7157\n",
      "global round: 156  client: 56  local train loss: 1.0718\n",
      "global round: 156  client: 33  local train loss: 0.9587\n",
      "global round: 156  client: 96  local train loss: 0.9316\n",
      "global round: 156  client: 85  local train loss: 0.9950\n",
      "global round: 156  client: 47  local train loss: 0.9245\n",
      "global round: 156  client: 11  local train loss: 1.0225\n",
      "global round: 156  client: 24  local train loss: 0.9981\n",
      "global round: 156  avg train loss:0.0874  global test loss: 1.7510  global test accu: 0.6264\n",
      "================================================================================================================\n",
      "global round: 157  client: 41  local train loss: 0.9189\n",
      "global round: 157  client: 26  local train loss: 1.1997\n",
      "global round: 157  client: 95  local train loss: 1.0278\n",
      "global round: 157  client: 08  local train loss: 1.1076\n",
      "global round: 157  client: 39  local train loss: 1.3859\n",
      "global round: 157  client: 68  local train loss: 1.0172\n",
      "global round: 157  client: 31  local train loss: 1.0506\n",
      "global round: 157  client: 52  local train loss: 1.0227\n",
      "global round: 157  client: 92  local train loss: 0.7596\n",
      "global round: 157  client: 64  local train loss: 0.9519\n",
      "global round: 157  avg train loss:0.0949  global test loss: 1.7442  global test accu: 0.6705\n",
      "================================================================================================================\n",
      "global round: 158  client: 78  local train loss: 0.9904\n",
      "global round: 158  client: 23  local train loss: 0.8566\n",
      "global round: 158  client: 53  local train loss: 0.8136\n",
      "global round: 158  client: 47  local train loss: 0.8923\n",
      "global round: 158  client: 99  local train loss: 0.7135\n",
      "global round: 158  client: 71  local train loss: 1.0196\n",
      "global round: 158  client: 09  local train loss: 0.8700\n",
      "global round: 158  client: 95  local train loss: 0.9867\n",
      "global round: 158  client: 75  local train loss: 1.0138\n",
      "global round: 158  client: 70  local train loss: 0.6956\n",
      "global round: 158  avg train loss:0.0805  global test loss: 1.7433  global test accu: 0.6704\n",
      "================================================================================================================\n",
      "global round: 159  client: 64  local train loss: 0.9472\n",
      "global round: 159  client: 48  local train loss: 1.0856\n",
      "global round: 159  client: 82  local train loss: 0.9165\n",
      "global round: 159  client: 66  local train loss: 0.8443\n",
      "global round: 159  client: 49  local train loss: 0.9334\n",
      "global round: 159  client: 55  local train loss: 1.3897\n",
      "global round: 159  client: 24  local train loss: 0.9869\n",
      "global round: 159  client: 34  local train loss: 0.7964\n",
      "global round: 159  client: 75  local train loss: 0.9942\n",
      "global round: 159  client: 86  local train loss: 1.0728\n",
      "global round: 159  avg train loss:0.0906  global test loss: 1.7430  global test accu: 0.6669\n",
      "================================================================================================================\n",
      "global round: 160  client: 50  local train loss: 0.9522\n",
      "global round: 160  client: 91  local train loss: 0.7495\n",
      "global round: 160  client: 74  local train loss: 0.6537\n",
      "global round: 160  client: 42  local train loss: 0.8592\n",
      "global round: 160  client: 99  local train loss: 0.7170\n",
      "global round: 160  client: 46  local train loss: 0.7798\n",
      "global round: 160  client: 71  local train loss: 0.9981\n",
      "global round: 160  client: 37  local train loss: 0.7454\n",
      "global round: 160  client: 95  local train loss: 0.9912\n",
      "global round: 160  client: 39  local train loss: 1.3563\n",
      "global round: 160  avg train loss:0.0800  global test loss: 1.7458  global test accu: 0.6463\n",
      "================================================================================================================\n",
      "global round: 161  client: 08  local train loss: 1.1108\n",
      "global round: 161  client: 60  local train loss: 0.9729\n",
      "global round: 161  client: 57  local train loss: 0.9230\n",
      "global round: 161  client: 16  local train loss: 0.9357\n",
      "global round: 161  client: 44  local train loss: 0.6343\n",
      "global round: 161  client: 59  local train loss: 0.9742\n",
      "global round: 161  client: 89  local train loss: 0.9132\n",
      "global round: 161  client: 87  local train loss: 1.1236\n",
      "global round: 161  client: 43  local train loss: 1.1617\n",
      "global round: 161  client: 34  local train loss: 0.7642\n",
      "global round: 161  avg train loss:0.0865  global test loss: 1.7397  global test accu: 0.6412\n",
      "================================================================================================================\n",
      "global round: 162  client: 65  local train loss: 1.0220\n",
      "global round: 162  client: 61  local train loss: 1.2064\n",
      "global round: 162  client: 36  local train loss: 0.8387\n",
      "global round: 162  client: 10  local train loss: 0.9989\n",
      "global round: 162  client: 40  local train loss: 0.9097\n",
      "global round: 162  client: 95  local train loss: 1.0096\n",
      "global round: 162  client: 56  local train loss: 1.0281\n",
      "global round: 162  client: 93  local train loss: 1.0071\n",
      "global round: 162  client: 19  local train loss: 0.9213\n",
      "global round: 162  client: 07  local train loss: 0.6840\n",
      "global round: 162  avg train loss:0.0875  global test loss: 1.7375  global test accu: 0.6599\n",
      "================================================================================================================\n",
      "global round: 163  client: 77  local train loss: 1.4001\n",
      "global round: 163  client: 63  local train loss: 0.9787\n",
      "global round: 163  client: 01  local train loss: 1.0134\n",
      "global round: 163  client: 46  local train loss: 0.7778\n",
      "global round: 163  client: 66  local train loss: 0.8285\n",
      "global round: 163  client: 71  local train loss: 0.9959\n",
      "global round: 163  client: 27  local train loss: 1.0366\n",
      "global round: 163  client: 25  local train loss: 1.0078\n",
      "global round: 163  client: 62  local train loss: 0.7950\n",
      "global round: 163  client: 11  local train loss: 1.0185\n",
      "global round: 163  avg train loss:0.0896  global test loss: 1.7396  global test accu: 0.6402\n",
      "================================================================================================================\n",
      "global round: 164  client: 80  local train loss: 1.1134\n",
      "global round: 164  client: 59  local train loss: 0.9365\n",
      "global round: 164  client: 53  local train loss: 0.7919\n",
      "global round: 164  client: 93  local train loss: 1.0107\n",
      "global round: 164  client: 32  local train loss: 0.8717\n",
      "global round: 164  client: 49  local train loss: 0.9358\n",
      "global round: 164  client: 01  local train loss: 1.0059\n",
      "global round: 164  client: 25  local train loss: 1.0117\n",
      "global round: 164  client: 96  local train loss: 0.9307\n",
      "global round: 164  client: 24  local train loss: 0.9726\n",
      "global round: 164  avg train loss:0.0871  global test loss: 1.7336  global test accu: 0.6414\n",
      "================================================================================================================\n",
      "global round: 165  client: 05  local train loss: 0.8954\n",
      "global round: 165  client: 80  local train loss: 1.0661\n",
      "global round: 165  client: 90  local train loss: 0.9377\n",
      "global round: 165  client: 03  local train loss: 0.9619\n",
      "global round: 165  client: 07  local train loss: 0.7100\n",
      "global round: 165  client: 77  local train loss: 1.3824\n",
      "global round: 165  client: 91  local train loss: 0.7382\n",
      "global round: 165  client: 96  local train loss: 0.9071\n",
      "global round: 165  client: 01  local train loss: 1.0020\n",
      "global round: 165  client: 81  local train loss: 0.6691\n",
      "global round: 165  avg train loss:0.0843  global test loss: 1.7292  global test accu: 0.6474\n",
      "================================================================================================================\n",
      "global round: 166  client: 63  local train loss: 0.9943\n",
      "global round: 166  client: 52  local train loss: 0.9858\n",
      "global round: 166  client: 90  local train loss: 0.9120\n",
      "global round: 166  client: 25  local train loss: 0.9945\n",
      "global round: 166  client: 38  local train loss: 1.1322\n",
      "global round: 166  client: 05  local train loss: 0.8739\n",
      "global round: 166  client: 77  local train loss: 1.3820\n",
      "global round: 166  client: 91  local train loss: 0.7332\n",
      "global round: 166  client: 10  local train loss: 0.9635\n",
      "global round: 166  client: 67  local train loss: 0.8529\n",
      "global round: 166  avg train loss:0.0893  global test loss: 1.7210  global test accu: 0.6764\n",
      "================================================================================================================\n",
      "global round: 167  client: 70  local train loss: 0.6761\n",
      "global round: 167  client: 54  local train loss: 0.9989\n",
      "global round: 167  client: 47  local train loss: 0.8925\n",
      "global round: 167  client: 33  local train loss: 0.9425\n",
      "global round: 167  client: 45  local train loss: 0.8613\n",
      "global round: 167  client: 40  local train loss: 0.8968\n",
      "global round: 167  client: 61  local train loss: 1.1617\n",
      "global round: 167  client: 59  local train loss: 0.9423\n",
      "global round: 167  client: 57  local train loss: 0.8674\n",
      "global round: 167  client: 96  local train loss: 0.9054\n",
      "global round: 167  avg train loss:0.0831  global test loss: 1.7158  global test accu: 0.6821\n",
      "================================================================================================================\n",
      "global round: 168  client: 17  local train loss: 0.7964\n",
      "global round: 168  client: 45  local train loss: 0.8495\n",
      "global round: 168  client: 10  local train loss: 0.9504\n",
      "global round: 168  client: 16  local train loss: 0.9234\n",
      "global round: 168  client: 20  local train loss: 0.7981\n",
      "global round: 168  client: 11  local train loss: 1.0202\n",
      "global round: 168  client: 06  local train loss: 1.0124\n",
      "global round: 168  client: 41  local train loss: 0.9027\n",
      "global round: 168  client: 62  local train loss: 0.7985\n",
      "global round: 168  client: 51  local train loss: 0.7675\n",
      "global round: 168  avg train loss:0.0802  global test loss: 1.7171  global test accu: 0.6738\n",
      "================================================================================================================\n",
      "global round: 169  client: 31  local train loss: 1.0574\n",
      "global round: 169  client: 11  local train loss: 0.9977\n",
      "global round: 169  client: 83  local train loss: 0.8027\n",
      "global round: 169  client: 10  local train loss: 0.9410\n",
      "global round: 169  client: 48  local train loss: 1.0859\n",
      "global round: 169  client: 46  local train loss: 0.7792\n",
      "global round: 169  client: 86  local train loss: 0.9896\n",
      "global round: 169  client: 60  local train loss: 0.9842\n",
      "global round: 169  client: 05  local train loss: 0.8576\n",
      "global round: 169  client: 56  local train loss: 1.0156\n",
      "global round: 169  avg train loss:0.0865  global test loss: 1.7167  global test accu: 0.6649\n",
      "================================================================================================================\n",
      "global round: 170  client: 20  local train loss: 0.8017\n",
      "global round: 170  client: 32  local train loss: 0.8360\n",
      "global round: 170  client: 59  local train loss: 0.9487\n",
      "global round: 170  client: 27  local train loss: 0.9841\n",
      "global round: 170  client: 69  local train loss: 1.3817\n",
      "global round: 170  client: 41  local train loss: 0.8812\n",
      "global round: 170  client: 45  local train loss: 0.8460\n",
      "global round: 170  client: 22  local train loss: 0.9982\n",
      "global round: 170  client: 26  local train loss: 1.1592\n",
      "global round: 170  client: 61  local train loss: 1.1586\n",
      "global round: 170  avg train loss:0.0909  global test loss: 1.7119  global test accu: 0.6777\n",
      "================================================================================================================\n",
      "global round: 171  client: 06  local train loss: 0.9711\n",
      "global round: 171  client: 04  local train loss: 1.1668\n",
      "global round: 171  client: 70  local train loss: 0.6711\n",
      "global round: 171  client: 62  local train loss: 0.8107\n",
      "global round: 171  client: 42  local train loss: 0.7970\n",
      "global round: 171  client: 46  local train loss: 0.7824\n",
      "global round: 171  client: 15  local train loss: 1.0101\n",
      "global round: 171  client: 57  local train loss: 0.8481\n",
      "global round: 171  client: 60  local train loss: 0.9440\n",
      "global round: 171  client: 17  local train loss: 0.7458\n",
      "global round: 171  avg train loss:0.0795  global test loss: 1.7125  global test accu: 0.6499\n",
      "================================================================================================================\n",
      "global round: 172  client: 06  local train loss: 0.9876\n",
      "global round: 172  client: 63  local train loss: 0.9837\n",
      "global round: 172  client: 88  local train loss: 0.7109\n",
      "global round: 172  client: 05  local train loss: 0.8508\n",
      "global round: 172  client: 80  local train loss: 1.0739\n",
      "global round: 172  client: 33  local train loss: 0.9552\n",
      "global round: 172  client: 37  local train loss: 0.6986\n",
      "global round: 172  client: 73  local train loss: 1.0235\n",
      "global round: 172  client: 56  local train loss: 1.0172\n",
      "global round: 172  client: 34  local train loss: 0.7601\n",
      "global round: 172  avg train loss:0.0824  global test loss: 1.7075  global test accu: 0.6681\n",
      "================================================================================================================\n",
      "global round: 173  client: 81  local train loss: 0.6721\n",
      "global round: 173  client: 73  local train loss: 0.9591\n",
      "global round: 173  client: 88  local train loss: 0.6445\n",
      "global round: 173  client: 83  local train loss: 0.8017\n",
      "global round: 173  client: 51  local train loss: 0.7233\n",
      "global round: 173  client: 25  local train loss: 0.9884\n",
      "global round: 173  client: 20  local train loss: 0.7955\n",
      "global round: 173  client: 97  local train loss: 0.8094\n",
      "global round: 173  client: 31  local train loss: 1.0406\n",
      "global round: 173  client: 67  local train loss: 0.8477\n",
      "global round: 173  avg train loss:0.0753  global test loss: 1.7065  global test accu: 0.6666\n",
      "================================================================================================================\n",
      "global round: 174  client: 67  local train loss: 0.8337\n",
      "global round: 174  client: 01  local train loss: 0.9919\n",
      "global round: 174  client: 19  local train loss: 0.8952\n",
      "global round: 174  client: 91  local train loss: 0.7257\n",
      "global round: 174  client: 28  local train loss: 0.9547\n",
      "global round: 174  client: 72  local train loss: 0.8436\n",
      "global round: 174  client: 48  local train loss: 1.0693\n",
      "global round: 174  client: 07  local train loss: 0.6874\n",
      "global round: 174  client: 63  local train loss: 0.9677\n",
      "global round: 174  client: 53  local train loss: 0.7946\n",
      "global round: 174  avg train loss:0.0797  global test loss: 1.7076  global test accu: 0.6486\n",
      "================================================================================================================\n",
      "global round: 175  client: 87  local train loss: 1.0663\n",
      "global round: 175  client: 45  local train loss: 0.8343\n",
      "global round: 175  client: 42  local train loss: 0.8038\n",
      "global round: 175  client: 84  local train loss: 0.9093\n",
      "global round: 175  client: 04  local train loss: 1.1179\n",
      "global round: 175  client: 78  local train loss: 1.0063\n",
      "global round: 175  client: 36  local train loss: 0.8430\n",
      "global round: 175  client: 49  local train loss: 0.9417\n",
      "global round: 175  client: 65  local train loss: 0.9814\n",
      "global round: 175  client: 88  local train loss: 0.6443\n",
      "global round: 175  avg train loss:0.0832  global test loss: 1.7063  global test accu: 0.6455\n",
      "================================================================================================================\n",
      "global round: 176  client: 61  local train loss: 1.1514\n",
      "global round: 176  client: 49  local train loss: 0.9133\n",
      "global round: 176  client: 97  local train loss: 0.7925\n",
      "global round: 176  client: 60  local train loss: 0.9431\n",
      "global round: 176  client: 01  local train loss: 0.9630\n",
      "global round: 176  client: 55  local train loss: 1.3736\n",
      "global round: 176  client: 51  local train loss: 0.7203\n",
      "global round: 176  client: 22  local train loss: 0.9431\n",
      "global round: 176  client: 11  local train loss: 0.9895\n",
      "global round: 176  client: 81  local train loss: 0.6680\n",
      "global round: 176  avg train loss:0.0860  global test loss: 1.7022  global test accu: 0.6405\n",
      "================================================================================================================\n",
      "global round: 177  client: 61  local train loss: 1.1268\n",
      "global round: 177  client: 69  local train loss: 1.3574\n",
      "global round: 177  client: 39  local train loss: 1.3604\n",
      "global round: 177  client: 88  local train loss: 0.6565\n",
      "global round: 177  client: 47  local train loss: 0.8666\n",
      "global round: 177  client: 59  local train loss: 0.9492\n",
      "global round: 177  client: 63  local train loss: 0.9586\n",
      "global round: 177  client: 65  local train loss: 0.9358\n",
      "global round: 177  client: 94  local train loss: 0.7358\n",
      "global round: 177  client: 87  local train loss: 1.0237\n",
      "global round: 177  avg train loss:0.0906  global test loss: 1.6953  global test accu: 0.6558\n",
      "================================================================================================================\n",
      "global round: 178  client: 75  local train loss: 0.9941\n",
      "global round: 178  client: 85  local train loss: 0.9902\n",
      "global round: 178  client: 99  local train loss: 0.7045\n",
      "global round: 178  client: 32  local train loss: 0.8220\n",
      "global round: 178  client: 04  local train loss: 1.0979\n",
      "global round: 178  client: 25  local train loss: 0.9793\n",
      "global round: 178  client: 79  local train loss: 0.8455\n",
      "global round: 178  client: 81  local train loss: 0.6675\n",
      "global round: 178  client: 24  local train loss: 0.9601\n",
      "global round: 178  client: 34  local train loss: 0.7344\n",
      "global round: 178  avg train loss:0.0800  global test loss: 1.6928  global test accu: 0.6560\n",
      "================================================================================================================\n",
      "global round: 179  client: 59  local train loss: 0.9799\n",
      "global round: 179  client: 44  local train loss: 0.6042\n",
      "global round: 179  client: 03  local train loss: 0.9606\n",
      "global round: 179  client: 20  local train loss: 0.7909\n",
      "global round: 179  client: 24  local train loss: 0.9766\n",
      "global round: 179  client: 39  local train loss: 1.3543\n",
      "global round: 179  client: 95  local train loss: 0.9974\n",
      "global round: 179  client: 05  local train loss: 0.8473\n",
      "global round: 179  client: 47  local train loss: 0.8500\n",
      "global round: 179  client: 57  local train loss: 0.8501\n",
      "global round: 179  avg train loss:0.0837  global test loss: 1.6865  global test accu: 0.6837\n",
      "================================================================================================================\n",
      "global round: 180  client: 91  local train loss: 0.7392\n",
      "global round: 180  client: 24  local train loss: 0.9667\n",
      "global round: 180  client: 26  local train loss: 1.1368\n",
      "global round: 180  client: 06  local train loss: 0.9670\n",
      "global round: 180  client: 86  local train loss: 0.9809\n",
      "global round: 180  client: 83  local train loss: 0.7866\n",
      "global round: 180  client: 81  local train loss: 0.6568\n",
      "global round: 180  client: 78  local train loss: 0.9762\n",
      "global round: 180  client: 52  local train loss: 0.9985\n",
      "global round: 180  client: 09  local train loss: 0.8375\n",
      "global round: 180  avg train loss:0.0822  global test loss: 1.6832  global test accu: 0.6896\n",
      "================================================================================================================\n",
      "global round: 181  client: 90  local train loss: 0.9079\n",
      "global round: 181  client: 31  local train loss: 1.0327\n",
      "global round: 181  client: 29  local train loss: 1.2791\n",
      "global round: 181  client: 88  local train loss: 0.6587\n",
      "global round: 181  client: 64  local train loss: 0.9404\n",
      "global round: 181  client: 19  local train loss: 0.8791\n",
      "global round: 181  client: 97  local train loss: 0.8086\n",
      "global round: 181  client: 70  local train loss: 0.6414\n",
      "global round: 181  client: 77  local train loss: 1.3899\n",
      "global round: 181  client: 59  local train loss: 0.9607\n",
      "global round: 181  avg train loss:0.0863  global test loss: 1.6837  global test accu: 0.6832\n",
      "================================================================================================================\n",
      "global round: 182  client: 03  local train loss: 0.9427\n",
      "global round: 182  client: 31  local train loss: 1.0181\n",
      "global round: 182  client: 79  local train loss: 0.7989\n",
      "global round: 182  client: 84  local train loss: 0.8584\n",
      "global round: 182  client: 80  local train loss: 1.0833\n",
      "global round: 182  client: 37  local train loss: 0.6739\n",
      "global round: 182  client: 64  local train loss: 0.9110\n",
      "global round: 182  client: 93  local train loss: 1.0053\n",
      "global round: 182  client: 78  local train loss: 0.9677\n",
      "global round: 182  client: 51  local train loss: 0.6948\n",
      "global round: 182  avg train loss:0.0814  global test loss: 1.6842  global test accu: 0.6708\n",
      "================================================================================================================\n",
      "global round: 183  client: 28  local train loss: 0.8995\n",
      "global round: 183  client: 36  local train loss: 0.8129\n",
      "global round: 183  client: 08  local train loss: 1.0948\n",
      "global round: 183  client: 21  local train loss: 0.8222\n",
      "global round: 183  client: 74  local train loss: 0.6229\n",
      "global round: 183  client: 61  local train loss: 1.1189\n",
      "global round: 183  client: 55  local train loss: 1.3661\n",
      "global round: 183  client: 49  local train loss: 0.9033\n",
      "global round: 183  client: 98  local train loss: 1.0273\n",
      "global round: 183  client: 31  local train loss: 0.9997\n",
      "global round: 183  avg train loss:0.0879  global test loss: 1.6862  global test accu: 0.6644\n",
      "================================================================================================================\n",
      "global round: 184  client: 53  local train loss: 0.7240\n",
      "global round: 184  client: 03  local train loss: 0.9237\n",
      "global round: 184  client: 84  local train loss: 0.8443\n",
      "global round: 184  client: 54  local train loss: 0.9500\n",
      "global round: 184  client: 47  local train loss: 0.8431\n",
      "global round: 184  client: 50  local train loss: 0.9452\n",
      "global round: 184  client: 06  local train loss: 0.9601\n",
      "global round: 184  client: 90  local train loss: 0.8764\n",
      "global round: 184  client: 94  local train loss: 0.7084\n",
      "global round: 184  client: 40  local train loss: 0.8803\n",
      "global round: 184  avg train loss:0.0787  global test loss: 1.6809  global test accu: 0.6634\n",
      "================================================================================================================\n",
      "global round: 185  client: 55  local train loss: 1.3494\n",
      "global round: 185  client: 07  local train loss: 0.6550\n",
      "global round: 185  client: 26  local train loss: 1.1056\n",
      "global round: 185  client: 74  local train loss: 0.6043\n",
      "global round: 185  client: 73  local train loss: 0.9539\n",
      "global round: 185  client: 70  local train loss: 0.6402\n",
      "global round: 185  client: 79  local train loss: 0.8114\n",
      "global round: 185  client: 81  local train loss: 0.6442\n",
      "global round: 185  client: 30  local train loss: 0.6965\n",
      "global round: 185  client: 27  local train loss: 0.9567\n",
      "global round: 185  avg train loss:0.0765  global test loss: 1.6848  global test accu: 0.6553\n",
      "================================================================================================================\n",
      "global round: 186  client: 57  local train loss: 0.8385\n",
      "global round: 186  client: 94  local train loss: 0.6764\n",
      "global round: 186  client: 48  local train loss: 1.0620\n",
      "global round: 186  client: 25  local train loss: 0.9607\n",
      "global round: 186  client: 69  local train loss: 1.3520\n",
      "global round: 186  client: 03  local train loss: 0.9173\n",
      "global round: 186  client: 05  local train loss: 0.8301\n",
      "global round: 186  client: 44  local train loss: 0.6186\n",
      "global round: 186  client: 78  local train loss: 0.9607\n",
      "global round: 186  client: 54  local train loss: 0.9370\n",
      "global round: 186  avg train loss:0.0832  global test loss: 1.6789  global test accu: 0.6666\n",
      "================================================================================================================\n",
      "global round: 187  client: 59  local train loss: 0.9401\n",
      "global round: 187  client: 00  local train loss: 0.9233\n",
      "global round: 187  client: 40  local train loss: 0.9020\n",
      "global round: 187  client: 25  local train loss: 0.9597\n",
      "global round: 187  client: 97  local train loss: 0.7896\n",
      "global round: 187  client: 26  local train loss: 1.0721\n",
      "global round: 187  client: 36  local train loss: 0.7945\n",
      "global round: 187  client: 95  local train loss: 1.0099\n",
      "global round: 187  client: 86  local train loss: 0.9407\n",
      "global round: 187  client: 56  local train loss: 1.0159\n",
      "global round: 187  avg train loss:0.0850  global test loss: 1.6750  global test accu: 0.6700\n",
      "================================================================================================================\n",
      "global round: 188  client: 84  local train loss: 0.8327\n",
      "global round: 188  client: 29  local train loss: 1.2537\n",
      "global round: 188  client: 44  local train loss: 0.6235\n",
      "global round: 188  client: 89  local train loss: 0.9160\n",
      "global round: 188  client: 86  local train loss: 0.9228\n",
      "global round: 188  client: 87  local train loss: 1.0234\n",
      "global round: 188  client: 81  local train loss: 0.6652\n",
      "global round: 188  client: 40  local train loss: 0.8953\n",
      "global round: 188  client: 98  local train loss: 0.9557\n",
      "global round: 188  client: 27  local train loss: 0.9239\n",
      "global round: 188  avg train loss:0.0819  global test loss: 1.6699  global test accu: 0.6780\n",
      "================================================================================================================\n",
      "global round: 189  client: 76  local train loss: 0.9508\n",
      "global round: 189  client: 81  local train loss: 0.6453\n",
      "global round: 189  client: 19  local train loss: 0.8614\n",
      "global round: 189  client: 49  local train loss: 0.8874\n",
      "global round: 189  client: 82  local train loss: 0.8753\n",
      "global round: 189  client: 99  local train loss: 0.6882\n",
      "global round: 189  client: 53  local train loss: 0.7446\n",
      "global round: 189  client: 45  local train loss: 0.8338\n",
      "global round: 189  client: 41  local train loss: 0.8705\n",
      "global round: 189  client: 78  local train loss: 0.9316\n",
      "global round: 189  avg train loss:0.0754  global test loss: 1.6716  global test accu: 0.6665\n",
      "================================================================================================================\n",
      "global round: 190  client: 26  local train loss: 1.0805\n",
      "global round: 190  client: 90  local train loss: 0.9009\n",
      "global round: 190  client: 82  local train loss: 0.7689\n",
      "global round: 190  client: 24  local train loss: 0.9569\n",
      "global round: 190  client: 29  local train loss: 1.2481\n",
      "global round: 190  client: 00  local train loss: 0.8544\n",
      "global round: 190  client: 20  local train loss: 0.8102\n",
      "global round: 190  client: 11  local train loss: 0.9902\n",
      "global round: 190  client: 67  local train loss: 0.8234\n",
      "global round: 190  client: 12  local train loss: 0.9598\n",
      "global round: 190  avg train loss:0.0854  global test loss: 1.6687  global test accu: 0.6647\n",
      "================================================================================================================\n",
      "global round: 191  client: 09  local train loss: 0.7806\n",
      "global round: 191  client: 02  local train loss: 1.0786\n",
      "global round: 191  client: 41  local train loss: 0.9197\n",
      "global round: 191  client: 35  local train loss: 1.0064\n",
      "global round: 191  client: 43  local train loss: 1.1611\n",
      "global round: 191  client: 88  local train loss: 0.6165\n",
      "global round: 191  client: 17  local train loss: 0.7378\n",
      "global round: 191  client: 50  local train loss: 0.8885\n",
      "global round: 191  client: 26  local train loss: 1.0570\n",
      "global round: 191  client: 40  local train loss: 0.8935\n",
      "global round: 191  avg train loss:0.0831  global test loss: 1.6679  global test accu: 0.6667\n",
      "================================================================================================================\n",
      "global round: 192  client: 72  local train loss: 0.7981\n",
      "global round: 192  client: 44  local train loss: 0.6222\n",
      "global round: 192  client: 86  local train loss: 0.9086\n",
      "global round: 192  client: 11  local train loss: 0.9839\n",
      "global round: 192  client: 18  local train loss: 0.9552\n",
      "global round: 192  client: 88  local train loss: 0.6590\n",
      "global round: 192  client: 98  local train loss: 0.9325\n",
      "global round: 192  client: 30  local train loss: 0.6772\n",
      "global round: 192  client: 54  local train loss: 0.9350\n",
      "global round: 192  client: 58  local train loss: 0.6187\n",
      "global round: 192  avg train loss:0.0736  global test loss: 1.6641  global test accu: 0.6725\n",
      "================================================================================================================\n",
      "global round: 193  client: 46  local train loss: 0.7753\n",
      "global round: 193  client: 14  local train loss: 0.7172\n",
      "global round: 193  client: 32  local train loss: 0.8256\n",
      "global round: 193  client: 06  local train loss: 0.9423\n",
      "global round: 193  client: 18  local train loss: 0.8967\n",
      "global round: 193  client: 99  local train loss: 0.6846\n",
      "global round: 193  client: 49  local train loss: 0.8550\n",
      "global round: 193  client: 39  local train loss: 1.3574\n",
      "global round: 193  client: 84  local train loss: 0.8310\n",
      "global round: 193  client: 65  local train loss: 0.9369\n",
      "global round: 193  avg train loss:0.0802  global test loss: 1.6618  global test accu: 0.6630\n",
      "================================================================================================================\n",
      "global round: 194  client: 64  local train loss: 0.9087\n",
      "global round: 194  client: 15  local train loss: 0.9870\n",
      "global round: 194  client: 99  local train loss: 0.6747\n",
      "global round: 194  client: 33  local train loss: 0.9362\n",
      "global round: 194  client: 17  local train loss: 0.7162\n",
      "global round: 194  client: 39  local train loss: 1.3613\n",
      "global round: 194  client: 81  local train loss: 0.6554\n",
      "global round: 194  client: 88  local train loss: 0.6464\n",
      "global round: 194  client: 87  local train loss: 0.9806\n",
      "global round: 194  client: 63  local train loss: 0.9153\n",
      "global round: 194  avg train loss:0.0798  global test loss: 1.6555  global test accu: 0.6766\n",
      "================================================================================================================\n",
      "global round: 195  client: 35  local train loss: 0.9430\n",
      "global round: 195  client: 61  local train loss: 1.1049\n",
      "global round: 195  client: 03  local train loss: 0.9097\n",
      "global round: 195  client: 92  local train loss: 0.7479\n",
      "global round: 195  client: 68  local train loss: 0.9733\n",
      "global round: 195  client: 22  local train loss: 0.9121\n",
      "global round: 195  client: 31  local train loss: 0.9871\n",
      "global round: 195  client: 40  local train loss: 0.8711\n",
      "global round: 195  client: 18  local train loss: 0.8913\n",
      "global round: 195  client: 08  local train loss: 1.0666\n",
      "global round: 195  avg train loss:0.0855  global test loss: 1.6532  global test accu: 0.6796\n",
      "================================================================================================================\n",
      "global round: 196  client: 11  local train loss: 0.9892\n",
      "global round: 196  client: 10  local train loss: 0.9427\n",
      "global round: 196  client: 59  local train loss: 0.9444\n",
      "global round: 196  client: 89  local train loss: 0.8695\n",
      "global round: 196  client: 47  local train loss: 0.8482\n",
      "global round: 196  client: 16  local train loss: 0.9036\n",
      "global round: 196  client: 56  local train loss: 1.0085\n",
      "global round: 196  client: 37  local train loss: 0.6716\n",
      "global round: 196  client: 92  local train loss: 0.7420\n",
      "global round: 196  client: 35  local train loss: 0.9538\n",
      "global round: 196  avg train loss:0.0807  global test loss: 1.6501  global test accu: 0.6930\n",
      "================================================================================================================\n",
      "global round: 197  client: 69  local train loss: 1.3442\n",
      "global round: 197  client: 01  local train loss: 0.9649\n",
      "global round: 197  client: 89  local train loss: 0.8665\n",
      "global round: 197  client: 75  local train loss: 0.9502\n",
      "global round: 197  client: 77  local train loss: 1.3664\n",
      "global round: 197  client: 90  local train loss: 0.8851\n",
      "global round: 197  client: 73  local train loss: 0.9282\n",
      "global round: 197  client: 38  local train loss: 1.1207\n",
      "global round: 197  client: 42  local train loss: 0.7961\n",
      "global round: 197  client: 40  local train loss: 0.8856\n",
      "global round: 197  avg train loss:0.0919  global test loss: 1.6478  global test accu: 0.7077\n",
      "================================================================================================================\n",
      "global round: 198  client: 83  local train loss: 0.8092\n",
      "global round: 198  client: 35  local train loss: 0.9343\n",
      "global round: 198  client: 99  local train loss: 0.6785\n",
      "global round: 198  client: 87  local train loss: 0.9872\n",
      "global round: 198  client: 36  local train loss: 0.7892\n",
      "global round: 198  client: 49  local train loss: 0.8303\n",
      "global round: 198  client: 57  local train loss: 0.8529\n",
      "global round: 198  client: 75  local train loss: 0.9435\n",
      "global round: 198  client: 73  local train loss: 0.9277\n",
      "global round: 198  client: 53  local train loss: 0.7342\n",
      "global round: 198  avg train loss:0.0772  global test loss: 1.6451  global test accu: 0.7000\n",
      "================================================================================================================\n",
      "global round: 199  client: 27  local train loss: 0.9316\n",
      "global round: 199  client: 90  local train loss: 0.8443\n",
      "global round: 199  client: 58  local train loss: 0.5427\n",
      "global round: 199  client: 08  local train loss: 1.0101\n",
      "global round: 199  client: 19  local train loss: 0.8409\n",
      "global round: 199  client: 26  local train loss: 1.0579\n",
      "global round: 199  client: 22  local train loss: 0.8573\n",
      "global round: 199  client: 12  local train loss: 0.9094\n",
      "global round: 199  client: 21  local train loss: 0.8070\n",
      "global round: 199  client: 36  local train loss: 0.8065\n",
      "global round: 199  avg train loss:0.0783  global test loss: 1.6466  global test accu: 0.6830\n",
      "================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# non-iid, client_equal_size\n",
    "histories, client = federated_learning(iid = False,\n",
    "                                       same_init = True,\n",
    "                                       client_equal_size = True,\n",
    "                                       num_global_round = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359ed23a-953e-461b-bb68-033e72240705",
   "metadata": {},
   "source": [
    "### non-iid, client_equal_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "710e7325-b758-4d43-bac9-93ba080a0dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (16, 4)) \n",
    "\n",
    "num_global_round = len(histories[\"local_train_losses\"])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_global_round + 1), histories[\"local_train_losses\"], label = 'avg local train loss')\n",
    "plt.plot(range(1, num_global_round + 1), histories[\"global_test_losses\"], label = 'global test loss')\n",
    "plt.xlabel('global round')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_global_round + 1), histories[\"global_test_accus\"], label = 'global test accus')\n",
    "plt.xlabel('global round')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c751d441-b59f-4863-aba4-852193851ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871c1376e27b4cf8828f3db51fd57454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ga92nam\\AppData\\Local\\Temp\\ipykernel_17828\\4185283577.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(image), torch.tensor(label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global round: 00  client: 49  local train loss: 2.2575\n",
      "global round: 00  client: 84  local train loss: 2.0695\n",
      "global round: 00  client: 64  local train loss: 2.1100\n",
      "global round: 00  client: 88  local train loss: 1.7218\n",
      "global round: 00  client: 61  local train loss: 2.2183\n",
      "global round: 00  client: 05  local train loss: 2.2614\n",
      "global round: 00  client: 82  local train loss: 2.1281\n",
      "global round: 00  client: 08  local train loss: 2.2651\n",
      "global round: 00  client: 25  local train loss: 2.2155\n",
      "global round: 00  client: 79  local train loss: 2.2172\n",
      "global round: 00  avg train loss:0.1956  global test loss: 2.2459  global test accu: 0.2341\n",
      "================================================================================================================\n",
      "global round: 01  client: 69  local train loss: 2.2429\n",
      "global round: 01  client: 83  local train loss: 2.1815\n",
      "global round: 01  client: 88  local train loss: 1.6631\n",
      "global round: 01  client: 11  local train loss: 2.2370\n",
      "global round: 01  client: 87  local train loss: 1.7405\n",
      "global round: 01  client: 16  local train loss: 2.2332\n",
      "global round: 01  client: 36  local train loss: 2.2101\n",
      "global round: 01  client: 28  local train loss: 2.0519\n",
      "global round: 01  client: 71  local train loss: 1.8603\n",
      "global round: 01  client: 39  local train loss: 2.2354\n",
      "global round: 01  avg train loss:0.2640  global test loss: 2.1434  global test accu: 0.4519\n",
      "================================================================================================================\n",
      "global round: 02  client: 29  local train loss: 2.2468\n",
      "global round: 02  client: 36  local train loss: 2.0061\n",
      "global round: 02  client: 47  local train loss: 2.2452\n",
      "global round: 02  client: 73  local train loss: 1.7257\n",
      "global round: 02  client: 86  local train loss: 2.1123\n",
      "global round: 02  client: 02  local train loss: 2.1416\n",
      "global round: 02  client: 75  local train loss: 2.1234\n",
      "global round: 02  client: 10  local train loss: 2.1542\n",
      "global round: 02  client: 44  local train loss: 1.9046\n",
      "global round: 02  client: 35  local train loss: 1.9799\n",
      "global round: 02  avg train loss:0.2563  global test loss: 2.0705  global test accu: 0.5717\n",
      "================================================================================================================\n",
      "global round: 03  client: 42  local train loss: 2.3156\n",
      "global round: 03  client: 56  local train loss: 2.1472\n",
      "global round: 03  client: 49  local train loss: 2.2106\n",
      "global round: 03  client: 23  local train loss: 2.2536\n",
      "global round: 03  client: 28  local train loss: 1.8310\n",
      "global round: 03  client: 01  local train loss: 2.2016\n",
      "global round: 03  client: 44  local train loss: 1.6384\n",
      "global round: 03  client: 89  local train loss: 2.2592\n",
      "global round: 03  client: 46  local train loss: 1.7807\n",
      "global round: 03  client: 62  local train loss: 2.2272\n",
      "global round: 03  avg train loss:0.1874  global test loss: 2.0108  global test accu: 0.6455\n",
      "================================================================================================================\n",
      "global round: 04  client: 27  local train loss: 2.1852\n",
      "global round: 04  client: 06  local train loss: 1.9446\n",
      "global round: 04  client: 71  local train loss: 1.6515\n",
      "global round: 04  client: 38  local train loss: 2.2088\n",
      "global round: 04  client: 86  local train loss: 1.8301\n",
      "global round: 04  client: 35  local train loss: 1.6907\n",
      "global round: 04  client: 64  local train loss: 2.0254\n",
      "global round: 04  client: 90  local train loss: 1.8676\n",
      "global round: 04  client: 40  local train loss: 2.1948\n",
      "global round: 04  client: 81  local train loss: 1.8134\n",
      "global round: 04  avg train loss:0.3001  global test loss: 1.9191  global test accu: 0.7185\n",
      "================================================================================================================\n",
      "global round: 05  client: 30  local train loss: 2.2720\n",
      "global round: 05  client: 10  local train loss: 1.8613\n",
      "global round: 05  client: 16  local train loss: 2.0469\n",
      "global round: 05  client: 39  local train loss: 2.0497\n",
      "global round: 05  client: 88  local train loss: 1.5423\n",
      "global round: 05  client: 32  local train loss: 2.2151\n",
      "global round: 05  client: 83  local train loss: 1.9741\n",
      "global round: 05  client: 24  local train loss: 2.2441\n",
      "global round: 05  client: 56  local train loss: 1.8069\n",
      "global round: 05  client: 00  local train loss: 2.2082\n",
      "global round: 05  avg train loss:0.1647  global test loss: 1.8740  global test accu: 0.7428\n",
      "================================================================================================================\n",
      "global round: 06  client: 87  local train loss: 1.5614\n",
      "global round: 06  client: 29  local train loss: 2.0008\n",
      "global round: 06  client: 36  local train loss: 1.9363\n",
      "global round: 06  client: 28  local train loss: 1.7283\n",
      "global round: 06  client: 89  local train loss: 1.9665\n",
      "global round: 06  client: 34  local train loss: 2.1957\n",
      "global round: 06  client: 94  local train loss: 2.2693\n",
      "global round: 06  client: 84  local train loss: 1.9733\n",
      "global round: 06  client: 08  local train loss: 2.2081\n",
      "global round: 06  client: 24  local train loss: 1.8171\n",
      "global round: 06  avg train loss:0.1606  global test loss: 1.8289  global test accu: 0.7604\n",
      "================================================================================================================\n",
      "global round: 07  client: 84  local train loss: 1.5672\n",
      "global round: 07  client: 17  local train loss: 2.2329\n",
      "global round: 07  client: 60  local train loss: 2.2351\n",
      "global round: 07  client: 29  local train loss: 1.7507\n",
      "global round: 07  client: 39  local train loss: 1.7795\n",
      "global round: 07  client: 33  local train loss: 2.2304\n",
      "global round: 07  client: 78  local train loss: 2.2568\n",
      "global round: 07  client: 62  local train loss: 1.9142\n",
      "global round: 07  client: 42  local train loss: 2.0566\n",
      "global round: 07  client: 37  local train loss: 2.1840\n",
      "global round: 07  avg train loss:0.0982  global test loss: 1.8267  global test accu: 0.7622\n",
      "================================================================================================================\n",
      "global round: 08  client: 31  local train loss: 2.2523\n",
      "global round: 08  client: 05  local train loss: 2.2058\n",
      "global round: 08  client: 15  local train loss: 2.2400\n",
      "global round: 08  client: 88  local train loss: 1.3723\n",
      "global round: 08  client: 78  local train loss: 1.8086\n",
      "global round: 08  client: 09  local train loss: 2.0952\n",
      "global round: 08  client: 54  local train loss: 2.2512\n",
      "global round: 08  client: 10  local train loss: 1.7141\n",
      "global round: 08  client: 81  local train loss: 1.4518\n",
      "global round: 08  client: 22  local train loss: 1.8787\n",
      "global round: 08  avg train loss:0.2133  global test loss: 1.7457  global test accu: 0.7849\n",
      "================================================================================================================\n",
      "global round: 09  client: 14  local train loss: 2.2048\n",
      "global round: 09  client: 82  local train loss: 2.0418\n",
      "global round: 09  client: 25  local train loss: 2.1486\n",
      "global round: 09  client: 57  local train loss: 2.1776\n",
      "global round: 09  client: 46  local train loss: 1.5012\n",
      "global round: 09  client: 49  local train loss: 1.9902\n",
      "global round: 09  client: 09  local train loss: 1.5145\n",
      "global round: 09  client: 75  local train loss: 1.8284\n",
      "global round: 09  client: 56  local train loss: 1.7127\n",
      "global round: 09  client: 93  local train loss: 2.0725\n",
      "global round: 09  avg train loss:0.1993  global test loss: 1.7148  global test accu: 0.7905\n",
      "================================================================================================================\n",
      "global round: 10  client: 66  local train loss: 2.0276\n",
      "global round: 10  client: 28  local train loss: 1.5842\n",
      "global round: 10  client: 02  local train loss: 1.8406\n",
      "global round: 10  client: 14  local train loss: 1.6120\n",
      "global round: 10  client: 49  local train loss: 1.7116\n",
      "global round: 10  client: 39  local train loss: 1.7492\n",
      "global round: 10  client: 83  local train loss: 1.7363\n",
      "global round: 10  client: 13  local train loss: 2.2747\n",
      "global round: 10  client: 38  local train loss: 1.8063\n",
      "global round: 10  client: 21  local train loss: 2.2531\n",
      "global round: 10  avg train loss:0.1272  global test loss: 1.7049  global test accu: 0.7912\n",
      "================================================================================================================\n",
      "global round: 11  client: 08  local train loss: 1.7967\n",
      "global round: 11  client: 29  local train loss: 1.7421\n",
      "global round: 11  client: 39  local train loss: 1.6303\n",
      "global round: 11  client: 52  local train loss: 2.1750\n",
      "global round: 11  client: 82  local train loss: 1.5358\n",
      "global round: 11  client: 67  local train loss: 2.0461\n",
      "global round: 11  client: 61  local train loss: 2.1587\n",
      "global round: 11  client: 36  local train loss: 1.7082\n",
      "global round: 11  client: 50  local train loss: 2.2474\n",
      "global round: 11  client: 96  local train loss: 2.2416\n",
      "global round: 11  avg train loss:0.1183  global test loss: 1.7076  global test accu: 0.7907\n",
      "================================================================================================================\n",
      "global round: 12  client: 70  local train loss: 2.2430\n",
      "global round: 12  client: 39  local train loss: 1.6357\n",
      "global round: 12  client: 64  local train loss: 1.6863\n",
      "global round: 12  client: 05  local train loss: 1.7232\n",
      "global round: 12  client: 26  local train loss: 2.2730\n",
      "global round: 12  client: 27  local train loss: 1.7663\n",
      "global round: 12  client: 52  local train loss: 1.5901\n",
      "global round: 12  client: 54  local train loss: 1.7155\n",
      "global round: 12  client: 49  local train loss: 1.7164\n",
      "global round: 12  client: 03  local train loss: 2.2514\n",
      "global round: 12  avg train loss:0.0744  global test loss: 1.7021  global test accu: 0.7917\n",
      "================================================================================================================\n",
      "global round: 13  client: 43  local train loss: 2.2757\n",
      "global round: 13  client: 59  local train loss: 2.1812\n",
      "global round: 13  client: 16  local train loss: 1.7941\n",
      "global round: 13  client: 23  local train loss: 1.9590\n",
      "global round: 13  client: 50  local train loss: 1.6942\n",
      "global round: 13  client: 54  local train loss: 1.6756\n",
      "global round: 13  client: 32  local train loss: 1.7623\n",
      "global round: 13  client: 75  local train loss: 1.5443\n",
      "global round: 13  client: 68  local train loss: 2.2883\n",
      "global round: 13  client: 03  local train loss: 1.6729\n",
      "global round: 13  avg train loss:0.0787  global test loss: 1.7007  global test accu: 0.7921\n",
      "================================================================================================================\n",
      "global round: 14  client: 23  local train loss: 1.6641\n",
      "global round: 14  client: 80  local train loss: 2.2562\n",
      "global round: 14  client: 13  local train loss: 1.7349\n",
      "global round: 14  client: 44  local train loss: 1.6085\n",
      "global round: 14  client: 22  local train loss: 1.3892\n",
      "global round: 14  client: 20  local train loss: 2.2568\n",
      "global round: 14  client: 91  local train loss: 2.2363\n",
      "global round: 14  client: 04  local train loss: 2.2372\n",
      "global round: 14  client: 96  local train loss: 1.6103\n",
      "global round: 14  client: 66  local train loss: 1.4428\n",
      "global round: 14  avg train loss:0.1442  global test loss: 1.6616  global test accu: 0.8001\n",
      "================================================================================================================\n",
      "global round: 15  client: 20  local train loss: 1.6353\n",
      "global round: 15  client: 69  local train loss: 2.0837\n",
      "global round: 15  client: 99  local train loss: 2.1857\n",
      "global round: 15  client: 28  local train loss: 1.4989\n",
      "global round: 15  client: 47  local train loss: 1.9982\n",
      "global round: 15  client: 07  local train loss: 2.2281\n",
      "global round: 15  client: 09  local train loss: 1.5183\n",
      "global round: 15  client: 51  local train loss: 2.2354\n",
      "global round: 15  client: 58  local train loss: 2.1553\n",
      "global round: 15  client: 10  local train loss: 1.6121\n",
      "global round: 15  avg train loss:0.1244  global test loss: 1.6559  global test accu: 0.8005\n",
      "================================================================================================================\n",
      "global round: 16  client: 12  local train loss: 2.1579\n",
      "global round: 16  client: 18  local train loss: 2.1629\n",
      "global round: 16  client: 55  local train loss: 2.2900\n",
      "global round: 16  client: 06  local train loss: 1.5367\n",
      "global round: 16  client: 75  local train loss: 1.5438\n",
      "global round: 16  client: 77  local train loss: 2.1544\n",
      "global round: 16  client: 97  local train loss: 2.2194\n",
      "global round: 16  client: 40  local train loss: 1.7768\n",
      "global round: 16  client: 39  local train loss: 1.6388\n",
      "global round: 16  client: 70  local train loss: 1.6325\n",
      "global round: 16  avg train loss:0.1507  global test loss: 1.6522  global test accu: 0.8008\n",
      "================================================================================================================\n",
      "global round: 17  client: 02  local train loss: 1.5434\n",
      "global round: 17  client: 65  local train loss: 2.2874\n",
      "global round: 17  client: 70  local train loss: 1.5812\n",
      "global round: 17  client: 38  local train loss: 1.6238\n",
      "global round: 17  client: 77  local train loss: 1.5129\n",
      "global round: 17  client: 62  local train loss: 1.7398\n",
      "global round: 17  client: 42  local train loss: 1.8889\n",
      "global round: 17  client: 27  local train loss: 1.5937\n",
      "global round: 17  client: 78  local train loss: 1.7308\n",
      "global round: 17  client: 39  local train loss: 1.6000\n",
      "global round: 17  avg train loss:0.0775  global test loss: 1.6414  global test accu: 0.8021\n",
      "================================================================================================================\n",
      "global round: 18  client: 10  local train loss: 1.5486\n",
      "global round: 18  client: 14  local train loss: 1.6069\n",
      "global round: 18  client: 88  local train loss: 1.3009\n",
      "global round: 18  client: 79  local train loss: 2.1442\n",
      "global round: 18  client: 44  local train loss: 1.3738\n",
      "global round: 18  client: 27  local train loss: 1.5439\n",
      "global round: 18  client: 12  local train loss: 1.5107\n",
      "global round: 18  client: 03  local train loss: 1.6658\n",
      "global round: 18  client: 97  local train loss: 1.5817\n",
      "global round: 18  client: 29  local train loss: 1.6217\n",
      "global round: 18  avg train loss:0.1619  global test loss: 1.5768  global test accu: 0.8120\n",
      "================================================================================================================\n",
      "global round: 19  client: 23  local train loss: 1.6316\n",
      "global round: 19  client: 32  local train loss: 1.6302\n",
      "global round: 19  client: 18  local train loss: 1.5092\n",
      "global round: 19  client: 25  local train loss: 1.6425\n",
      "global round: 19  client: 17  local train loss: 1.7820\n",
      "global round: 19  client: 35  local train loss: 1.5914\n",
      "global round: 19  client: 00  local train loss: 1.7455\n",
      "global round: 19  client: 19  local train loss: 1.7833\n",
      "global round: 19  client: 40  local train loss: 1.5756\n",
      "global round: 19  client: 21  local train loss: 1.6751\n",
      "global round: 19  avg train loss:0.1584  global test loss: 1.5530  global test accu: 0.8148\n",
      "================================================================================================================\n",
      "global round: 20  client: 91  local train loss: 1.5823\n",
      "global round: 20  client: 62  local train loss: 1.5729\n",
      "global round: 20  client: 39  local train loss: 1.5960\n",
      "global round: 20  client: 49  local train loss: 1.6806\n",
      "global round: 20  client: 27  local train loss: 1.4901\n",
      "global round: 20  client: 30  local train loss: 1.8491\n",
      "global round: 20  client: 05  local train loss: 1.6929\n",
      "global round: 20  client: 40  local train loss: 1.5057\n",
      "global round: 20  client: 71  local train loss: 1.5024\n",
      "global round: 20  client: 55  local train loss: 1.7608\n",
      "global round: 20  avg train loss:0.0890  global test loss: 1.5341  global test accu: 0.8157\n",
      "================================================================================================================\n",
      "global round: 21  client: 22  local train loss: 1.3583\n",
      "global round: 21  client: 09  local train loss: 1.4752\n",
      "global round: 21  client: 91  local train loss: 1.4747\n",
      "global round: 21  client: 90  local train loss: 1.4935\n",
      "global round: 21  client: 84  local train loss: 1.5908\n",
      "global round: 21  client: 55  local train loss: 1.6073\n",
      "global round: 21  client: 98  local train loss: 2.2375\n",
      "global round: 21  client: 21  local train loss: 1.5180\n",
      "global round: 21  client: 95  local train loss: 2.3039\n",
      "global round: 21  client: 67  local train loss: 1.4517\n",
      "global round: 21  avg train loss:0.1658  global test loss: 1.4904  global test accu: 0.8218\n",
      "================================================================================================================\n",
      "global round: 22  client: 50  local train loss: 1.6771\n",
      "global round: 22  client: 23  local train loss: 1.5240\n",
      "global round: 22  client: 78  local train loss: 1.6512\n",
      "global round: 22  client: 34  local train loss: 1.7156\n",
      "global round: 22  client: 07  local train loss: 1.6034\n",
      "global round: 22  client: 92  local train loss: 2.3065\n",
      "global round: 22  client: 52  local train loss: 1.6024\n",
      "global round: 22  client: 40  local train loss: 1.4773\n",
      "global round: 22  client: 85  local train loss: 2.1684\n",
      "global round: 22  client: 13  local train loss: 1.6792\n",
      "global round: 22  avg train loss:0.0755  global test loss: 1.4945  global test accu: 0.8212\n",
      "================================================================================================================\n",
      "global round: 23  client: 97  local train loss: 1.5138\n",
      "global round: 23  client: 37  local train loss: 1.6828\n",
      "global round: 23  client: 87  local train loss: 1.3691\n",
      "global round: 23  client: 72  local train loss: 2.1003\n",
      "global round: 23  client: 55  local train loss: 1.5884\n",
      "global round: 23  client: 29  local train loss: 1.5073\n",
      "global round: 23  client: 32  local train loss: 1.5085\n",
      "global round: 23  client: 90  local train loss: 1.2532\n",
      "global round: 23  client: 14  local train loss: 1.5182\n",
      "global round: 23  client: 09  local train loss: 1.3600\n",
      "global round: 23  avg train loss:0.1687  global test loss: 1.4480  global test accu: 0.8247\n",
      "================================================================================================================\n",
      "global round: 24  client: 12  local train loss: 1.4828\n",
      "global round: 24  client: 27  local train loss: 1.4631\n",
      "global round: 24  client: 44  local train loss: 1.3211\n",
      "global round: 24  client: 48  local train loss: 2.0381\n",
      "global round: 24  client: 29  local train loss: 1.3903\n",
      "global round: 24  client: 78  local train loss: 1.5294\n",
      "global round: 24  client: 97  local train loss: 1.4175\n",
      "global round: 24  client: 07  local train loss: 1.4836\n",
      "global round: 24  client: 74  local train loss: 2.0377\n",
      "global round: 24  client: 54  local train loss: 1.6840\n",
      "global round: 24  avg train loss:0.1505  global test loss: 1.4404  global test accu: 0.8244\n",
      "================================================================================================================\n",
      "global round: 25  client: 86  local train loss: 1.7149\n",
      "global round: 25  client: 88  local train loss: 1.2075\n",
      "global round: 25  client: 58  local train loss: 1.5188\n",
      "global round: 25  client: 44  local train loss: 1.2430\n",
      "global round: 25  client: 40  local train loss: 1.4659\n",
      "global round: 25  client: 78  local train loss: 1.4749\n",
      "global round: 25  client: 98  local train loss: 1.4984\n",
      "global round: 25  client: 83  local train loss: 1.6031\n",
      "global round: 25  client: 67  local train loss: 1.3387\n",
      "global round: 25  client: 48  local train loss: 1.2655\n",
      "global round: 25  avg train loss:0.1824  global test loss: 1.3781  global test accu: 0.8287\n",
      "================================================================================================================\n",
      "global round: 26  client: 58  local train loss: 1.3207\n",
      "global round: 26  client: 51  local train loss: 1.6371\n",
      "global round: 26  client: 62  local train loss: 1.4928\n",
      "global round: 26  client: 75  local train loss: 1.5107\n",
      "global round: 26  client: 98  local train loss: 1.4046\n",
      "global round: 26  client: 05  local train loss: 1.5365\n",
      "global round: 26  client: 00  local train loss: 1.4936\n",
      "global round: 26  client: 77  local train loss: 1.5397\n",
      "global round: 26  client: 96  local train loss: 1.5536\n",
      "global round: 26  client: 44  local train loss: 1.2006\n",
      "global round: 26  avg train loss:0.1049  global test loss: 1.3581  global test accu: 0.8302\n",
      "================================================================================================================\n",
      "global round: 27  client: 08  local train loss: 1.7059\n",
      "global round: 27  client: 45  local train loss: 2.2328\n",
      "global round: 27  client: 31  local train loss: 1.7414\n",
      "global round: 27  client: 30  local train loss: 1.5461\n",
      "global round: 27  client: 12  local train loss: 1.3666\n",
      "global round: 27  client: 72  local train loss: 1.3181\n",
      "global round: 27  client: 00  local train loss: 1.3423\n",
      "global round: 27  client: 14  local train loss: 1.4161\n",
      "global round: 27  client: 66  local train loss: 1.4495\n",
      "global round: 27  client: 39  local train loss: 1.4989\n",
      "global round: 27  avg train loss:0.0947  global test loss: 1.3499  global test accu: 0.8299\n",
      "================================================================================================================\n",
      "global round: 28  client: 77  local train loss: 1.3265\n",
      "global round: 28  client: 31  local train loss: 1.4382\n",
      "global round: 28  client: 83  local train loss: 1.3491\n",
      "global round: 28  client: 78  local train loss: 1.4137\n",
      "global round: 28  client: 96  local train loss: 1.2695\n",
      "global round: 28  client: 98  local train loss: 1.3948\n",
      "global round: 28  client: 09  local train loss: 1.3252\n",
      "global round: 28  client: 37  local train loss: 1.3960\n",
      "global round: 28  client: 30  local train loss: 1.3750\n",
      "global round: 28  client: 03  local train loss: 1.5613\n",
      "global round: 28  avg train loss:0.0755  global test loss: 1.3406  global test accu: 0.8306\n",
      "================================================================================================================\n",
      "global round: 29  client: 36  local train loss: 1.6052\n",
      "global round: 29  client: 18  local train loss: 1.4581\n",
      "global round: 29  client: 09  local train loss: 1.2493\n",
      "global round: 29  client: 42  local train loss: 1.7383\n",
      "global round: 29  client: 01  local train loss: 1.8590\n",
      "global round: 29  client: 47  local train loss: 1.6072\n",
      "global round: 29  client: 60  local train loss: 1.7746\n",
      "global round: 29  client: 04  local train loss: 1.6445\n",
      "global round: 29  client: 22  local train loss: 1.2586\n",
      "global round: 29  client: 25  local train loss: 1.5354\n",
      "global round: 29  avg train loss:0.1137  global test loss: 1.3284  global test accu: 0.8318\n",
      "================================================================================================================\n",
      "global round: 30  client: 49  local train loss: 1.5236\n",
      "global round: 30  client: 07  local train loss: 1.4446\n",
      "global round: 30  client: 08  local train loss: 1.3845\n",
      "global round: 30  client: 29  local train loss: 1.3872\n",
      "global round: 30  client: 23  local train loss: 1.4782\n",
      "global round: 30  client: 10  local train loss: 1.4840\n",
      "global round: 30  client: 14  local train loss: 1.3279\n",
      "global round: 30  client: 91  local train loss: 1.4392\n",
      "global round: 30  client: 48  local train loss: 1.2507\n",
      "global round: 30  client: 34  local train loss: 1.4676\n",
      "global round: 30  avg train loss:0.0740  global test loss: 1.3212  global test accu: 0.8323\n",
      "================================================================================================================\n",
      "global round: 31  client: 78  local train loss: 1.4047\n",
      "global round: 31  client: 44  local train loss: 1.1900\n",
      "global round: 31  client: 41  local train loss: 2.0927\n",
      "global round: 31  client: 81  local train loss: 1.3626\n",
      "global round: 31  client: 15  local train loss: 1.7111\n",
      "global round: 31  client: 48  local train loss: 1.2178\n",
      "global round: 31  client: 28  local train loss: 1.4715\n",
      "global round: 31  client: 22  local train loss: 1.1667\n",
      "global round: 31  client: 24  local train loss: 1.7740\n",
      "global round: 31  client: 76  local train loss: 2.1759\n",
      "global round: 31  avg train loss:0.2000  global test loss: 1.2887  global test accu: 0.8341\n",
      "================================================================================================================\n",
      "global round: 32  client: 21  local train loss: 1.4653\n",
      "global round: 32  client: 44  local train loss: 1.1457\n",
      "global round: 32  client: 12  local train loss: 1.3131\n",
      "global round: 32  client: 41  local train loss: 1.1927\n",
      "global round: 32  client: 93  local train loss: 1.4809\n",
      "global round: 32  client: 22  local train loss: 1.1414\n",
      "global round: 32  client: 16  local train loss: 1.6394\n",
      "global round: 32  client: 80  local train loss: 1.6478\n",
      "global round: 32  client: 48  local train loss: 1.1997\n",
      "global round: 32  client: 43  local train loss: 1.7170\n",
      "global round: 32  avg train loss:0.1437  global test loss: 1.2504  global test accu: 0.8375\n",
      "================================================================================================================\n",
      "global round: 33  client: 82  local train loss: 1.5528\n",
      "global round: 33  client: 64  local train loss: 1.5363\n",
      "global round: 33  client: 36  local train loss: 1.2831\n",
      "global round: 33  client: 49  local train loss: 1.3372\n",
      "global round: 33  client: 79  local train loss: 1.5274\n",
      "global round: 33  client: 78  local train loss: 1.3595\n",
      "global round: 33  client: 43  local train loss: 1.3331\n",
      "global round: 33  client: 66  local train loss: 1.2426\n",
      "global round: 33  client: 27  local train loss: 1.3833\n",
      "global round: 33  client: 02  local train loss: 1.5054\n",
      "global round: 33  avg train loss:0.1081  global test loss: 1.2467  global test accu: 0.8382\n",
      "================================================================================================================\n",
      "global round: 34  client: 74  local train loss: 1.2851\n",
      "global round: 34  client: 00  local train loss: 1.3284\n",
      "global round: 34  client: 55  local train loss: 1.5543\n",
      "global round: 34  client: 58  local train loss: 1.3103\n",
      "global round: 34  client: 42  local train loss: 1.4684\n",
      "global round: 34  client: 43  local train loss: 1.3055\n",
      "global round: 34  client: 57  local train loss: 1.5646\n",
      "global round: 34  client: 48  local train loss: 1.1740\n",
      "global round: 34  client: 67  local train loss: 1.2669\n",
      "global round: 34  client: 16  local train loss: 1.2730\n",
      "global round: 34  avg train loss:0.1041  global test loss: 1.2307  global test accu: 0.8388\n",
      "================================================================================================================\n",
      "global round: 35  client: 23  local train loss: 1.3417\n",
      "global round: 35  client: 35  local train loss: 1.3366\n",
      "global round: 35  client: 09  local train loss: 1.2402\n",
      "global round: 35  client: 92  local train loss: 1.5623\n",
      "global round: 35  client: 88  local train loss: 1.1078\n",
      "global round: 35  client: 58  local train loss: 1.2152\n",
      "global round: 35  client: 14  local train loss: 1.3163\n",
      "global round: 35  client: 06  local train loss: 1.3814\n",
      "global round: 35  client: 86  local train loss: 1.3218\n",
      "global round: 35  client: 72  local train loss: 1.2710\n",
      "global round: 35  avg train loss:0.1661  global test loss: 1.1904  global test accu: 0.8401\n",
      "================================================================================================================\n",
      "global round: 36  client: 21  local train loss: 1.2500\n",
      "global round: 36  client: 57  local train loss: 1.1925\n",
      "global round: 36  client: 85  local train loss: 1.4089\n",
      "global round: 36  client: 83  local train loss: 1.3237\n",
      "global round: 36  client: 82  local train loss: 1.2230\n",
      "global round: 36  client: 06  local train loss: 1.0975\n",
      "global round: 36  client: 44  local train loss: 1.1251\n",
      "global round: 36  client: 99  local train loss: 1.5251\n",
      "global round: 36  client: 62  local train loss: 1.3250\n",
      "global round: 36  client: 86  local train loss: 1.1911\n",
      "global round: 36  avg train loss:0.1283  global test loss: 1.1660  global test accu: 0.8409\n",
      "================================================================================================================\n",
      "global round: 37  client: 84  local train loss: 1.3545\n",
      "global round: 37  client: 23  local train loss: 1.2151\n",
      "global round: 37  client: 17  local train loss: 1.5683\n",
      "global round: 37  client: 78  local train loss: 1.3269\n",
      "global round: 37  client: 15  local train loss: 1.3451\n",
      "global round: 37  client: 87  local train loss: 1.1686\n",
      "global round: 37  client: 34  local train loss: 1.3403\n",
      "global round: 37  client: 09  local train loss: 1.1508\n",
      "global round: 37  client: 47  local train loss: 1.3262\n",
      "global round: 37  client: 79  local train loss: 1.2875\n",
      "global round: 37  avg train loss:0.1187  global test loss: 1.1452  global test accu: 0.8424\n",
      "================================================================================================================\n",
      "global round: 38  client: 81  local train loss: 1.1120\n",
      "global round: 38  client: 27  local train loss: 1.2334\n",
      "global round: 38  client: 79  local train loss: 1.2127\n",
      "global round: 38  client: 55  local train loss: 1.4074\n",
      "global round: 38  client: 83  local train loss: 1.1905\n",
      "global round: 38  client: 19  local train loss: 1.2138\n",
      "global round: 38  client: 82  local train loss: 1.1601\n",
      "global round: 38  client: 25  local train loss: 1.3457\n",
      "global round: 38  client: 50  local train loss: 1.4939\n",
      "global round: 38  client: 04  local train loss: 1.3758\n",
      "global round: 38  avg train loss:0.1295  global test loss: 1.1175  global test accu: 0.8435\n",
      "================================================================================================================\n",
      "global round: 39  client: 28  local train loss: 1.2195\n",
      "global round: 39  client: 60  local train loss: 1.3596\n",
      "global round: 39  client: 15  local train loss: 1.2506\n",
      "global round: 39  client: 30  local train loss: 1.3908\n",
      "global round: 39  client: 06  local train loss: 1.0832\n",
      "global round: 39  client: 66  local train loss: 1.1777\n",
      "global round: 39  client: 88  local train loss: 1.0186\n",
      "global round: 39  client: 79  local train loss: 1.1998\n",
      "global round: 39  client: 80  local train loss: 1.3042\n",
      "global round: 39  client: 20  local train loss: 1.6260\n",
      "global round: 39  avg train loss:0.1308  global test loss: 1.0837  global test accu: 0.8468\n",
      "================================================================================================================\n",
      "global round: 40  client: 47  local train loss: 1.1745\n",
      "global round: 40  client: 90  local train loss: 1.2282\n",
      "global round: 40  client: 37  local train loss: 1.3145\n",
      "global round: 40  client: 35  local train loss: 1.1058\n",
      "global round: 40  client: 03  local train loss: 1.3646\n",
      "global round: 40  client: 27  local train loss: 1.1227\n",
      "global round: 40  client: 88  local train loss: 0.9667\n",
      "global round: 40  client: 30  local train loss: 1.1460\n",
      "global round: 40  client: 10  local train loss: 1.3020\n",
      "global round: 40  client: 69  local train loss: 1.6477\n",
      "global round: 40  avg train loss:0.1357  global test loss: 1.0529  global test accu: 0.8490\n",
      "================================================================================================================\n",
      "global round: 41  client: 39  local train loss: 1.3186\n",
      "global round: 41  client: 53  local train loss: 2.2297\n",
      "global round: 41  client: 58  local train loss: 1.1871\n",
      "global round: 41  client: 44  local train loss: 1.0744\n",
      "global round: 41  client: 51  local train loss: 1.3842\n",
      "global round: 41  client: 61  local train loss: 1.6628\n",
      "global round: 41  client: 32  local train loss: 1.4305\n",
      "global round: 41  client: 33  local train loss: 1.7545\n",
      "global round: 41  client: 17  local train loss: 1.2678\n",
      "global round: 41  client: 82  local train loss: 1.1262\n",
      "global round: 41  avg train loss:0.0987  global test loss: 1.0533  global test accu: 0.8492\n",
      "================================================================================================================\n",
      "global round: 42  client: 11  local train loss: 2.0614\n",
      "global round: 42  client: 64  local train loss: 1.2055\n",
      "global round: 42  client: 91  local train loss: 1.2912\n",
      "global round: 42  client: 15  local train loss: 1.1937\n",
      "global round: 42  client: 16  local train loss: 1.2681\n",
      "global round: 42  client: 28  local train loss: 1.0851\n",
      "global round: 42  client: 04  local train loss: 1.2038\n",
      "global round: 42  client: 03  local train loss: 1.1151\n",
      "global round: 42  client: 30  local train loss: 1.1409\n",
      "global round: 42  client: 73  local train loss: 1.5004\n",
      "global round: 42  avg train loss:0.1230  global test loss: 1.0492  global test accu: 0.8495\n",
      "================================================================================================================\n",
      "global round: 43  client: 88  local train loss: 0.9475\n",
      "global round: 43  client: 85  local train loss: 1.1793\n",
      "global round: 43  client: 15  local train loss: 1.1784\n",
      "global round: 43  client: 38  local train loss: 1.5850\n",
      "global round: 43  client: 75  local train loss: 1.2999\n",
      "global round: 43  client: 29  local train loss: 1.2761\n",
      "global round: 43  client: 83  local train loss: 1.1474\n",
      "global round: 43  client: 24  local train loss: 1.3156\n",
      "global round: 43  client: 47  local train loss: 1.0921\n",
      "global round: 43  client: 79  local train loss: 1.1685\n",
      "global round: 43  avg train loss:0.1011  global test loss: 1.0294  global test accu: 0.8510\n",
      "================================================================================================================\n",
      "global round: 44  client: 10  local train loss: 1.1011\n",
      "global round: 44  client: 78  local train loss: 1.2367\n",
      "global round: 44  client: 58  local train loss: 1.0720\n",
      "global round: 44  client: 97  local train loss: 1.4096\n",
      "global round: 44  client: 28  local train loss: 1.0640\n",
      "global round: 44  client: 92  local train loss: 1.3071\n",
      "global round: 44  client: 70  local train loss: 1.5669\n",
      "global round: 44  client: 85  local train loss: 1.0851\n",
      "global round: 44  client: 37  local train loss: 1.1016\n",
      "global round: 44  client: 39  local train loss: 1.0842\n",
      "global round: 44  avg train loss:0.0764  global test loss: 1.0233  global test accu: 0.8516\n",
      "================================================================================================================\n",
      "global round: 45  client: 87  local train loss: 1.0140\n",
      "global round: 45  client: 77  local train loss: 1.3067\n",
      "global round: 45  client: 29  local train loss: 1.0045\n",
      "global round: 45  client: 99  local train loss: 1.1652\n",
      "global round: 45  client: 10  local train loss: 1.0840\n",
      "global round: 45  client: 98  local train loss: 1.3841\n",
      "global round: 45  client: 41  local train loss: 1.1903\n",
      "global round: 45  client: 12  local train loss: 1.2442\n",
      "global round: 45  client: 86  local train loss: 1.1611\n",
      "global round: 45  client: 18  local train loss: 1.2835\n",
      "global round: 45  avg train loss:0.1296  global test loss: 1.0077  global test accu: 0.8528\n",
      "================================================================================================================\n",
      "global round: 46  client: 78  local train loss: 1.1219\n",
      "global round: 46  client: 96  local train loss: 1.2612\n",
      "global round: 46  client: 01  local train loss: 1.3045\n",
      "global round: 46  client: 08  local train loss: 1.3756\n",
      "global round: 46  client: 94  local train loss: 1.8119\n",
      "global round: 46  client: 17  local train loss: 1.2135\n",
      "global round: 46  client: 62  local train loss: 1.1696\n",
      "global round: 46  client: 10  local train loss: 1.0794\n",
      "global round: 46  client: 44  local train loss: 1.0099\n",
      "global round: 46  client: 05  local train loss: 1.3989\n",
      "global round: 46  avg train loss:0.0699  global test loss: 1.0007  global test accu: 0.8531\n",
      "================================================================================================================\n",
      "global round: 47  client: 17  local train loss: 1.1727\n",
      "global round: 47  client: 36  local train loss: 1.2134\n",
      "global round: 47  client: 22  local train loss: 1.1209\n",
      "global round: 47  client: 97  local train loss: 1.0815\n",
      "global round: 47  client: 71  local train loss: 1.2599\n",
      "global round: 47  client: 29  local train loss: 0.9894\n",
      "global round: 47  client: 23  local train loss: 1.1961\n",
      "global round: 47  client: 34  local train loss: 1.2071\n",
      "global round: 47  client: 80  local train loss: 1.1892\n",
      "global round: 47  client: 59  local train loss: 1.5800\n",
      "global round: 47  avg train loss:0.1098  global test loss: 0.9962  global test accu: 0.8524\n",
      "================================================================================================================\n",
      "global round: 48  client: 87  local train loss: 0.9467\n",
      "global round: 48  client: 70  local train loss: 1.0003\n",
      "global round: 48  client: 30  local train loss: 1.1269\n",
      "global round: 48  client: 65  local train loss: 1.6185\n",
      "global round: 48  client: 68  local train loss: 1.6992\n",
      "global round: 48  client: 98  local train loss: 1.1251\n",
      "global round: 48  client: 21  local train loss: 1.1624\n",
      "global round: 48  client: 25  local train loss: 1.1959\n",
      "global round: 48  client: 66  local train loss: 1.0747\n",
      "global round: 48  client: 61  local train loss: 1.1661\n",
      "global round: 48  avg train loss:0.0810  global test loss: 0.9771  global test accu: 0.8541\n",
      "================================================================================================================\n",
      "global round: 49  client: 01  local train loss: 1.0714\n",
      "global round: 49  client: 34  local train loss: 1.1018\n",
      "global round: 49  client: 83  local train loss: 1.0818\n",
      "global round: 49  client: 60  local train loss: 1.1760\n",
      "global round: 49  client: 99  local train loss: 1.0521\n",
      "global round: 49  client: 53  local train loss: 1.0642\n",
      "global round: 49  client: 67  local train loss: 1.1702\n",
      "global round: 49  client: 76  local train loss: 1.2669\n",
      "global round: 49  client: 54  local train loss: 1.4730\n",
      "global round: 49  client: 87  local train loss: 0.9254\n",
      "global round: 49  avg train loss:0.1081  global test loss: 0.9596  global test accu: 0.8551\n",
      "================================================================================================================\n",
      "global round: 50  client: 31  local train loss: 1.4344\n",
      "global round: 50  client: 44  local train loss: 0.9740\n",
      "global round: 50  client: 96  local train loss: 0.9597\n",
      "global round: 50  client: 32  local train loss: 1.1159\n",
      "global round: 50  client: 56  local train loss: 1.5929\n",
      "global round: 50  client: 80  local train loss: 1.1130\n",
      "global round: 50  client: 86  local train loss: 1.0604\n",
      "global round: 50  client: 14  local train loss: 1.2007\n",
      "global round: 50  client: 43  local train loss: 1.3058\n",
      "global round: 50  client: 18  local train loss: 1.0557\n",
      "global round: 50  avg train loss:0.0854  global test loss: 0.9548  global test accu: 0.8555\n",
      "================================================================================================================\n",
      "global round: 51  client: 76  local train loss: 1.0218\n",
      "global round: 51  client: 26  local train loss: 1.7388\n",
      "global round: 51  client: 51  local train loss: 1.1039\n",
      "global round: 51  client: 82  local train loss: 1.0704\n",
      "global round: 51  client: 07  local train loss: 1.3453\n",
      "global round: 51  client: 24  local train loss: 1.0993\n",
      "global round: 51  client: 31  local train loss: 1.1278\n",
      "global round: 51  client: 81  local train loss: 1.0198\n",
      "global round: 51  client: 77  local train loss: 1.0726\n",
      "global round: 51  client: 08  local train loss: 1.1039\n",
      "global round: 51  avg train loss:0.0785  global test loss: 0.9451  global test accu: 0.8557\n",
      "================================================================================================================\n",
      "global round: 52  client: 74  local train loss: 1.1717\n",
      "global round: 52  client: 33  local train loss: 1.1242\n",
      "global round: 52  client: 61  local train loss: 1.1161\n",
      "global round: 52  client: 35  local train loss: 1.0250\n",
      "global round: 52  client: 90  local train loss: 1.0098\n",
      "global round: 52  client: 63  local train loss: 1.9311\n",
      "global round: 52  client: 73  local train loss: 0.9603\n",
      "global round: 52  client: 85  local train loss: 1.0863\n",
      "global round: 52  client: 16  local train loss: 1.1178\n",
      "global round: 52  client: 39  local train loss: 1.0478\n",
      "global round: 52  avg train loss:0.1704  global test loss: 0.9329  global test accu: 0.8568\n",
      "================================================================================================================\n",
      "global round: 53  client: 12  local train loss: 1.0462\n",
      "global round: 53  client: 22  local train loss: 0.9741\n",
      "global round: 53  client: 86  local train loss: 1.0244\n",
      "global round: 53  client: 74  local train loss: 0.9779\n",
      "global round: 53  client: 25  local train loss: 1.0774\n",
      "global round: 53  client: 39  local train loss: 0.9882\n",
      "global round: 53  client: 88  local train loss: 0.9296\n",
      "global round: 53  client: 97  local train loss: 1.0785\n",
      "global round: 53  client: 53  local train loss: 0.9804\n",
      "global round: 53  client: 14  local train loss: 1.0230\n",
      "global round: 53  avg train loss:0.1235  global test loss: 0.9062  global test accu: 0.8589\n",
      "================================================================================================================\n",
      "global round: 54  client: 87  local train loss: 0.9106\n",
      "global round: 54  client: 78  local train loss: 1.1114\n",
      "global round: 54  client: 91  local train loss: 1.0607\n",
      "global round: 54  client: 71  local train loss: 0.9612\n",
      "global round: 54  client: 98  local train loss: 1.1026\n",
      "global round: 54  client: 59  local train loss: 1.0455\n",
      "global round: 54  client: 30  local train loss: 1.0564\n",
      "global round: 54  client: 73  local train loss: 0.8940\n",
      "global round: 54  client: 25  local train loss: 1.0184\n",
      "global round: 54  client: 79  local train loss: 1.1393\n",
      "global round: 54  avg train loss:0.1248  global test loss: 0.8757  global test accu: 0.8607\n",
      "================================================================================================================\n",
      "global round: 55  client: 45  local train loss: 1.3398\n",
      "global round: 55  client: 55  local train loss: 1.3071\n",
      "global round: 55  client: 51  local train loss: 1.0738\n",
      "global round: 55  client: 53  local train loss: 0.9374\n",
      "global round: 55  client: 47  local train loss: 1.0668\n",
      "global round: 55  client: 27  local train loss: 1.0805\n",
      "global round: 55  client: 48  local train loss: 1.1603\n",
      "global round: 55  client: 02  local train loss: 1.2087\n",
      "global round: 55  client: 94  local train loss: 1.0581\n",
      "global round: 55  client: 69  local train loss: 1.1546\n",
      "global round: 55  avg train loss:0.0566  global test loss: 0.8802  global test accu: 0.8601\n",
      "================================================================================================================\n",
      "global round: 56  client: 89  local train loss: 1.7954\n",
      "global round: 56  client: 78  local train loss: 1.0199\n",
      "global round: 56  client: 31  local train loss: 1.1581\n",
      "global round: 56  client: 95  local train loss: 1.5531\n",
      "global round: 56  client: 47  local train loss: 0.9491\n",
      "global round: 56  client: 58  local train loss: 1.0627\n",
      "global round: 56  client: 01  local train loss: 1.0388\n",
      "global round: 56  client: 54  local train loss: 1.0557\n",
      "global round: 56  client: 03  local train loss: 1.1043\n",
      "global round: 56  client: 33  local train loss: 1.0440\n",
      "global round: 56  avg train loss:0.0393  global test loss: 0.8815  global test accu: 0.8601\n",
      "================================================================================================================\n",
      "global round: 57  client: 87  local train loss: 0.8616\n",
      "global round: 57  client: 40  local train loss: 1.3712\n",
      "global round: 57  client: 78  local train loss: 1.0287\n",
      "global round: 57  client: 42  local train loss: 1.3661\n",
      "global round: 57  client: 04  local train loss: 1.1562\n",
      "global round: 57  client: 01  local train loss: 0.9765\n",
      "global round: 57  client: 00  local train loss: 1.2458\n",
      "global round: 57  client: 11  local train loss: 1.1040\n",
      "global round: 57  client: 58  local train loss: 0.9585\n",
      "global round: 57  client: 53  local train loss: 0.9173\n",
      "global round: 57  avg train loss:0.0834  global test loss: 0.8698  global test accu: 0.8614\n",
      "================================================================================================================\n",
      "global round: 58  client: 46  local train loss: 1.3372\n",
      "global round: 58  client: 69  local train loss: 1.0098\n",
      "global round: 58  client: 32  local train loss: 1.0343\n",
      "global round: 58  client: 59  local train loss: 0.9537\n",
      "global round: 58  client: 33  local train loss: 0.9947\n",
      "global round: 58  client: 09  local train loss: 1.1167\n",
      "global round: 58  client: 84  local train loss: 1.1176\n",
      "global round: 58  client: 56  local train loss: 1.0159\n",
      "global round: 58  client: 76  local train loss: 1.0295\n",
      "global round: 58  client: 71  local train loss: 0.8885\n",
      "global round: 58  avg train loss:0.1378  global test loss: 0.8639  global test accu: 0.8617\n",
      "================================================================================================================\n",
      "global round: 59  client: 89  local train loss: 0.9520\n",
      "global round: 59  client: 10  local train loss: 1.0663\n",
      "global round: 59  client: 85  local train loss: 1.0076\n",
      "global round: 59  client: 32  local train loss: 0.9695\n",
      "global round: 59  client: 24  local train loss: 1.0400\n",
      "global round: 59  client: 30  local train loss: 0.9725\n",
      "global round: 59  client: 88  local train loss: 0.8707\n",
      "global round: 59  client: 81  local train loss: 0.9200\n",
      "global round: 59  client: 75  local train loss: 1.0620\n",
      "global round: 59  client: 13  local train loss: 1.5735\n",
      "global round: 59  avg train loss:0.1052  global test loss: 0.8436  global test accu: 0.8631\n",
      "================================================================================================================\n",
      "global round: 60  client: 08  local train loss: 1.0672\n",
      "global round: 60  client: 57  local train loss: 1.1480\n",
      "global round: 60  client: 28  local train loss: 1.0401\n",
      "global round: 60  client: 09  local train loss: 0.9189\n",
      "global round: 60  client: 86  local train loss: 0.9820\n",
      "global round: 60  client: 58  local train loss: 0.9431\n",
      "global round: 60  client: 92  local train loss: 1.1611\n",
      "global round: 60  client: 24  local train loss: 0.9370\n",
      "global round: 60  client: 61  local train loss: 1.0822\n",
      "global round: 60  client: 93  local train loss: 1.1891\n",
      "global round: 60  avg train loss:0.0863  global test loss: 0.8431  global test accu: 0.8632\n",
      "================================================================================================================\n",
      "global round: 61  client: 10  local train loss: 0.9471\n",
      "global round: 61  client: 40  local train loss: 0.9852\n",
      "global round: 61  client: 01  local train loss: 0.9688\n",
      "global round: 61  client: 82  local train loss: 0.9997\n",
      "global round: 61  client: 86  local train loss: 0.9436\n",
      "global round: 61  client: 59  local train loss: 0.9629\n",
      "global round: 61  client: 25  local train loss: 0.9983\n",
      "global round: 61  client: 87  local train loss: 0.8619\n",
      "global round: 61  client: 14  local train loss: 0.9809\n",
      "global round: 61  client: 12  local train loss: 0.9743\n",
      "global round: 61  avg train loss:0.1042  global test loss: 0.8276  global test accu: 0.8646\n",
      "================================================================================================================\n",
      "global round: 62  client: 29  local train loss: 0.9839\n",
      "global round: 62  client: 62  local train loss: 1.0282\n",
      "global round: 62  client: 31  local train loss: 1.1101\n",
      "global round: 62  client: 14  local train loss: 0.9262\n",
      "global round: 62  client: 79  local train loss: 1.0175\n",
      "global round: 62  client: 35  local train loss: 0.9410\n",
      "global round: 62  client: 43  local train loss: 1.0800\n",
      "global round: 62  client: 36  local train loss: 1.0093\n",
      "global round: 62  client: 99  local train loss: 1.0213\n",
      "global round: 62  client: 28  local train loss: 0.9231\n",
      "global round: 62  avg train loss:0.0678  global test loss: 0.8246  global test accu: 0.8641\n",
      "================================================================================================================\n",
      "global round: 63  client: 98  local train loss: 1.0220\n",
      "global round: 63  client: 23  local train loss: 1.0510\n",
      "global round: 63  client: 96  local train loss: 0.9429\n",
      "global round: 63  client: 40  local train loss: 0.9548\n",
      "global round: 63  client: 69  local train loss: 0.9982\n",
      "global round: 63  client: 13  local train loss: 1.0523\n",
      "global round: 63  client: 62  local train loss: 0.8853\n",
      "global round: 63  client: 55  local train loss: 1.0130\n",
      "global round: 63  client: 83  local train loss: 1.0301\n",
      "global round: 63  client: 79  local train loss: 0.9699\n",
      "global round: 63  avg train loss:0.0371  global test loss: 0.8245  global test accu: 0.8642\n",
      "================================================================================================================\n",
      "global round: 64  client: 97  local train loss: 0.9977\n",
      "global round: 64  client: 22  local train loss: 0.9228\n",
      "global round: 64  client: 50  local train loss: 1.1801\n",
      "global round: 64  client: 35  local train loss: 0.8733\n",
      "global round: 64  client: 07  local train loss: 1.0437\n",
      "global round: 64  client: 00  local train loss: 0.9658\n",
      "global round: 64  client: 03  local train loss: 0.9637\n",
      "global round: 64  client: 67  local train loss: 0.9910\n",
      "global round: 64  client: 64  local train loss: 1.0733\n",
      "global round: 64  client: 78  local train loss: 1.0146\n",
      "global round: 64  avg train loss:0.0963  global test loss: 0.8173  global test accu: 0.8643\n",
      "================================================================================================================\n",
      "global round: 65  client: 25  local train loss: 0.9516\n",
      "global round: 65  client: 62  local train loss: 0.8876\n",
      "global round: 65  client: 14  local train loss: 0.9181\n",
      "global round: 65  client: 80  local train loss: 1.0849\n",
      "global round: 65  client: 43  local train loss: 0.9479\n",
      "global round: 65  client: 85  local train loss: 0.9403\n",
      "global round: 65  client: 03  local train loss: 0.9111\n",
      "global round: 65  client: 38  local train loss: 1.0904\n",
      "global round: 65  client: 72  local train loss: 1.1658\n",
      "global round: 65  client: 45  local train loss: 0.9603\n",
      "global round: 65  avg train loss:0.0547  global test loss: 0.8188  global test accu: 0.8641\n",
      "================================================================================================================\n",
      "global round: 66  client: 84  local train loss: 0.9291\n",
      "global round: 66  client: 42  local train loss: 1.0800\n",
      "global round: 66  client: 61  local train loss: 1.0088\n",
      "global round: 66  client: 38  local train loss: 0.9112\n",
      "global round: 66  client: 13  local train loss: 1.0059\n",
      "global round: 66  client: 30  local train loss: 0.9137\n",
      "global round: 66  client: 49  local train loss: 1.2746\n",
      "global round: 66  client: 72  local train loss: 0.9086\n",
      "global round: 66  client: 85  local train loss: 0.9324\n",
      "global round: 66  client: 50  local train loss: 0.9408\n",
      "global round: 66  avg train loss:0.0523  global test loss: 0.8144  global test accu: 0.8650\n",
      "================================================================================================================\n",
      "global round: 67  client: 28  local train loss: 0.9091\n",
      "global round: 67  client: 22  local train loss: 0.8635\n",
      "global round: 67  client: 68  local train loss: 1.0667\n",
      "global round: 67  client: 21  local train loss: 1.0073\n",
      "global round: 67  client: 48  local train loss: 0.9232\n",
      "global round: 67  client: 76  local train loss: 0.9622\n",
      "global round: 67  client: 94  local train loss: 0.9355\n",
      "global round: 67  client: 52  local train loss: 1.4453\n",
      "global round: 67  client: 41  local train loss: 1.0203\n",
      "global round: 67  client: 59  local train loss: 0.9237\n",
      "global round: 67  avg train loss:0.0968  global test loss: 0.8082  global test accu: 0.8650\n",
      "================================================================================================================\n",
      "global round: 68  client: 28  local train loss: 0.8974\n",
      "global round: 68  client: 96  local train loss: 0.8122\n",
      "global round: 68  client: 55  local train loss: 1.0166\n",
      "global round: 68  client: 47  local train loss: 0.9638\n",
      "global round: 68  client: 83  local train loss: 0.9233\n",
      "global round: 68  client: 39  local train loss: 0.9543\n",
      "global round: 68  client: 57  local train loss: 0.8848\n",
      "global round: 68  client: 49  local train loss: 0.8631\n",
      "global round: 68  client: 12  local train loss: 0.9177\n",
      "global round: 68  client: 27  local train loss: 0.9460\n",
      "global round: 68  avg train loss:0.0526  global test loss: 0.8050  global test accu: 0.8655\n",
      "================================================================================================================\n",
      "global round: 69  client: 86  local train loss: 0.9276\n",
      "global round: 69  client: 70  local train loss: 0.9581\n",
      "global round: 69  client: 54  local train loss: 0.9827\n",
      "global round: 69  client: 53  local train loss: 0.8987\n",
      "global round: 69  client: 26  local train loss: 1.1655\n",
      "global round: 69  client: 45  local train loss: 0.8866\n",
      "global round: 69  client: 37  local train loss: 1.0786\n",
      "global round: 69  client: 13  local train loss: 1.0274\n",
      "global round: 69  client: 41  local train loss: 0.8665\n",
      "global round: 69  client: 11  local train loss: 0.9737\n",
      "global round: 69  avg train loss:0.0485  global test loss: 0.8035  global test accu: 0.8651\n",
      "================================================================================================================\n",
      "global round: 70  client: 86  local train loss: 0.8986\n",
      "global round: 70  client: 68  local train loss: 0.9417\n",
      "global round: 70  client: 54  local train loss: 0.9001\n",
      "global round: 70  client: 35  local train loss: 0.8667\n",
      "global round: 70  client: 84  local train loss: 0.8847\n",
      "global round: 70  client: 91  local train loss: 0.9159\n",
      "global round: 70  client: 78  local train loss: 0.9444\n",
      "global round: 70  client: 55  local train loss: 0.9806\n",
      "global round: 70  client: 81  local train loss: 0.8594\n",
      "global round: 70  client: 72  local train loss: 0.9054\n",
      "global round: 70  avg train loss:0.0907  global test loss: 0.7893  global test accu: 0.8656\n",
      "================================================================================================================\n",
      "global round: 71  client: 38  local train loss: 0.9071\n",
      "global round: 71  client: 99  local train loss: 0.9043\n",
      "global round: 71  client: 58  local train loss: 0.9241\n",
      "global round: 71  client: 86  local train loss: 0.8939\n",
      "global round: 71  client: 12  local train loss: 0.9035\n",
      "global round: 71  client: 05  local train loss: 1.0905\n",
      "global round: 71  client: 70  local train loss: 0.8184\n",
      "global round: 71  client: 30  local train loss: 0.9109\n",
      "global round: 71  client: 32  local train loss: 0.9471\n",
      "global round: 71  client: 26  local train loss: 1.0541\n",
      "global round: 71  avg train loss:0.0505  global test loss: 0.7867  global test accu: 0.8656\n",
      "================================================================================================================\n",
      "global round: 72  client: 10  local train loss: 0.9316\n",
      "global round: 72  client: 35  local train loss: 0.8449\n",
      "global round: 72  client: 66  local train loss: 1.0037\n",
      "global round: 72  client: 95  local train loss: 1.0120\n",
      "global round: 72  client: 47  local train loss: 0.8964\n",
      "global round: 72  client: 52  local train loss: 0.9184\n",
      "global round: 72  client: 96  local train loss: 0.8003\n",
      "global round: 72  client: 29  local train loss: 0.8216\n",
      "global round: 72  client: 34  local train loss: 1.0616\n",
      "global round: 72  client: 92  local train loss: 0.9934\n",
      "global round: 72  avg train loss:0.0659  global test loss: 0.7828  global test accu: 0.8662\n",
      "================================================================================================================\n",
      "global round: 73  client: 33  local train loss: 0.9792\n",
      "global round: 73  client: 23  local train loss: 0.9003\n",
      "global round: 73  client: 89  local train loss: 0.9527\n",
      "global round: 73  client: 77  local train loss: 1.0286\n",
      "global round: 73  client: 57  local train loss: 0.8693\n",
      "global round: 73  client: 30  local train loss: 0.8745\n",
      "global round: 73  client: 56  local train loss: 0.9557\n",
      "global round: 73  client: 75  local train loss: 0.9242\n",
      "global round: 73  client: 70  local train loss: 0.7936\n",
      "global round: 73  client: 22  local train loss: 0.8594\n",
      "global round: 73  avg train loss:0.0704  global test loss: 0.7779  global test accu: 0.8663\n",
      "================================================================================================================\n",
      "global round: 74  client: 93  local train loss: 0.9047\n",
      "global round: 74  client: 01  local train loss: 0.9309\n",
      "global round: 74  client: 24  local train loss: 0.9564\n",
      "global round: 74  client: 66  local train loss: 0.8626\n",
      "global round: 74  client: 07  local train loss: 0.9472\n",
      "global round: 74  client: 99  local train loss: 0.8656\n",
      "global round: 74  client: 92  local train loss: 0.8988\n",
      "global round: 74  client: 41  local train loss: 0.8662\n",
      "global round: 74  client: 71  local train loss: 0.8795\n",
      "global round: 74  client: 27  local train loss: 0.8875\n",
      "global round: 74  avg train loss:0.0908  global test loss: 0.7687  global test accu: 0.8667\n",
      "================================================================================================================\n",
      "global round: 75  client: 93  local train loss: 0.8529\n",
      "global round: 75  client: 10  local train loss: 0.8935\n",
      "global round: 75  client: 71  local train loss: 0.8144\n",
      "global round: 75  client: 57  local train loss: 0.8487\n",
      "global round: 75  client: 70  local train loss: 0.8062\n",
      "global round: 75  client: 26  local train loss: 0.9844\n",
      "global round: 75  client: 50  local train loss: 0.9397\n",
      "global round: 75  client: 92  local train loss: 0.9017\n",
      "global round: 75  client: 72  local train loss: 0.8872\n",
      "global round: 75  client: 04  local train loss: 1.0147\n",
      "global round: 75  avg train loss:0.0732  global test loss: 0.7596  global test accu: 0.8678\n",
      "================================================================================================================\n",
      "global round: 76  client: 77  local train loss: 0.9110\n",
      "global round: 76  client: 79  local train loss: 0.9746\n",
      "global round: 76  client: 02  local train loss: 0.9328\n",
      "global round: 76  client: 55  local train loss: 0.9799\n",
      "global round: 76  client: 65  local train loss: 1.0334\n",
      "global round: 76  client: 78  local train loss: 0.9321\n",
      "global round: 76  client: 38  local train loss: 0.8882\n",
      "global round: 76  client: 89  local train loss: 0.8564\n",
      "global round: 76  client: 25  local train loss: 0.9506\n",
      "global round: 76  client: 98  local train loss: 0.9743\n",
      "global round: 76  avg train loss:0.0456  global test loss: 0.7594  global test accu: 0.8674\n",
      "================================================================================================================\n",
      "global round: 77  client: 75  local train loss: 0.8760\n",
      "global round: 77  client: 96  local train loss: 0.7928\n",
      "global round: 77  client: 12  local train loss: 0.8855\n",
      "global round: 77  client: 74  local train loss: 0.9662\n",
      "global round: 77  client: 29  local train loss: 0.7935\n",
      "global round: 77  client: 16  local train loss: 1.0260\n",
      "global round: 77  client: 86  local train loss: 0.9007\n",
      "global round: 77  client: 10  local train loss: 0.8827\n",
      "global round: 77  client: 04  local train loss: 0.9044\n",
      "global round: 77  client: 25  local train loss: 0.9012\n",
      "global round: 77  avg train loss:0.0725  global test loss: 0.7561  global test accu: 0.8681\n",
      "================================================================================================================\n",
      "global round: 78  client: 14  local train loss: 0.9178\n",
      "global round: 78  client: 15  local train loss: 1.1619\n",
      "global round: 78  client: 16  local train loss: 0.8916\n",
      "global round: 78  client: 66  local train loss: 0.8574\n",
      "global round: 78  client: 99  local train loss: 0.8531\n",
      "global round: 78  client: 06  local train loss: 1.0369\n",
      "global round: 78  client: 95  local train loss: 0.8768\n",
      "global round: 78  client: 45  local train loss: 0.8771\n",
      "global round: 78  client: 49  local train loss: 0.9320\n",
      "global round: 78  client: 97  local train loss: 0.9197\n",
      "global round: 78  avg train loss:0.0682  global test loss: 0.7555  global test accu: 0.8682\n",
      "================================================================================================================\n",
      "global round: 79  client: 16  local train loss: 0.8860\n",
      "global round: 79  client: 62  local train loss: 0.8688\n",
      "global round: 79  client: 89  local train loss: 0.8606\n",
      "global round: 79  client: 83  local train loss: 0.8970\n",
      "global round: 79  client: 55  local train loss: 0.9176\n",
      "global round: 79  client: 86  local train loss: 0.8620\n",
      "global round: 79  client: 81  local train loss: 0.8243\n",
      "global round: 79  client: 90  local train loss: 0.9364\n",
      "global round: 79  client: 00  local train loss: 0.9206\n",
      "global round: 79  client: 71  local train loss: 0.8079\n",
      "global round: 79  avg train loss:0.1038  global test loss: 0.7417  global test accu: 0.8686\n",
      "================================================================================================================\n",
      "global round: 80  client: 34  local train loss: 0.9255\n",
      "global round: 80  client: 88  local train loss: 0.8294\n",
      "global round: 80  client: 56  local train loss: 0.8861\n",
      "global round: 80  client: 83  local train loss: 0.8470\n",
      "global round: 80  client: 37  local train loss: 0.8961\n",
      "global round: 80  client: 62  local train loss: 0.8117\n",
      "global round: 80  client: 31  local train loss: 1.0429\n",
      "global round: 80  client: 21  local train loss: 0.8538\n",
      "global round: 80  client: 28  local train loss: 0.8922\n",
      "global round: 80  client: 51  local train loss: 1.0133\n",
      "global round: 80  avg train loss:0.0818  global test loss: 0.7324  global test accu: 0.8683\n",
      "================================================================================================================\n",
      "global round: 81  client: 15  local train loss: 0.9323\n",
      "global round: 81  client: 98  local train loss: 0.9263\n",
      "global round: 81  client: 06  local train loss: 0.8171\n",
      "global round: 81  client: 18  local train loss: 1.0131\n",
      "global round: 81  client: 53  local train loss: 0.8511\n",
      "global round: 81  client: 44  local train loss: 0.9482\n",
      "global round: 81  client: 27  local train loss: 0.8515\n",
      "global round: 81  client: 10  local train loss: 0.8800\n",
      "global round: 81  client: 95  local train loss: 0.9085\n",
      "global round: 81  client: 47  local train loss: 0.8592\n",
      "global round: 81  avg train loss:0.0815  global test loss: 0.7293  global test accu: 0.8689\n",
      "================================================================================================================\n",
      "global round: 82  client: 87  local train loss: 0.8379\n",
      "global round: 82  client: 39  local train loss: 0.8725\n",
      "global round: 82  client: 77  local train loss: 0.8929\n",
      "global round: 82  client: 12  local train loss: 0.8642\n",
      "global round: 82  client: 43  local train loss: 0.9396\n",
      "global round: 82  client: 78  local train loss: 0.9061\n",
      "global round: 82  client: 59  local train loss: 0.9160\n",
      "global round: 82  client: 62  local train loss: 0.8052\n",
      "global round: 82  client: 04  local train loss: 0.9092\n",
      "global round: 82  client: 37  local train loss: 0.8401\n",
      "global round: 82  avg train loss:0.0783  global test loss: 0.7220  global test accu: 0.8688\n",
      "================================================================================================================\n",
      "global round: 83  client: 62  local train loss: 0.8113\n",
      "global round: 83  client: 66  local train loss: 0.8384\n",
      "global round: 83  client: 31  local train loss: 0.9592\n",
      "global round: 83  client: 42  local train loss: 1.0088\n",
      "global round: 83  client: 40  local train loss: 0.9522\n",
      "global round: 83  client: 01  local train loss: 0.8853\n",
      "global round: 83  client: 88  local train loss: 0.7708\n",
      "global round: 83  client: 55  local train loss: 0.8840\n",
      "global round: 83  client: 48  local train loss: 0.8793\n",
      "global round: 83  client: 79  local train loss: 0.9170\n",
      "global round: 83  avg train loss:0.0829  global test loss: 0.7114  global test accu: 0.8700\n",
      "================================================================================================================\n",
      "global round: 84  client: 41  local train loss: 0.8354\n",
      "global round: 84  client: 56  local train loss: 0.8517\n",
      "global round: 84  client: 71  local train loss: 0.7994\n",
      "global round: 84  client: 38  local train loss: 0.8568\n",
      "global round: 84  client: 18  local train loss: 0.8342\n",
      "global round: 84  client: 13  local train loss: 0.9687\n",
      "global round: 84  client: 15  local train loss: 0.9212\n",
      "global round: 84  client: 29  local train loss: 0.7890\n",
      "global round: 84  client: 58  local train loss: 0.8758\n",
      "global round: 84  client: 79  local train loss: 0.8807\n",
      "global round: 84  avg train loss:0.0745  global test loss: 0.7060  global test accu: 0.8700\n",
      "================================================================================================================\n",
      "global round: 85  client: 90  local train loss: 0.8174\n",
      "global round: 85  client: 93  local train loss: 0.8481\n",
      "global round: 85  client: 27  local train loss: 0.8240\n",
      "global round: 85  client: 77  local train loss: 0.8541\n",
      "global round: 85  client: 25  local train loss: 0.9061\n",
      "global round: 85  client: 31  local train loss: 0.9682\n",
      "global round: 85  client: 14  local train loss: 0.8467\n",
      "global round: 85  client: 33  local train loss: 0.9153\n",
      "global round: 85  client: 99  local train loss: 0.8412\n",
      "global round: 85  client: 41  local train loss: 0.7834\n",
      "global round: 85  avg train loss:0.0808  global test loss: 0.7001  global test accu: 0.8707\n",
      "================================================================================================================\n",
      "global round: 86  client: 68  local train loss: 0.8854\n",
      "global round: 86  client: 62  local train loss: 0.7731\n",
      "global round: 86  client: 38  local train loss: 0.8124\n",
      "global round: 86  client: 71  local train loss: 0.7756\n",
      "global round: 86  client: 70  local train loss: 0.8007\n",
      "global round: 86  client: 44  local train loss: 0.8012\n",
      "global round: 86  client: 58  local train loss: 0.8084\n",
      "global round: 86  client: 99  local train loss: 0.7972\n",
      "global round: 86  client: 84  local train loss: 0.8645\n",
      "global round: 86  client: 43  local train loss: 0.8423\n",
      "global round: 86  avg train loss:0.0810  global test loss: 0.6917  global test accu: 0.8711\n",
      "================================================================================================================\n",
      "global round: 87  client: 86  local train loss: 0.8528\n",
      "global round: 87  client: 76  local train loss: 0.9243\n",
      "global round: 87  client: 22  local train loss: 0.8333\n",
      "global round: 87  client: 58  local train loss: 0.7981\n",
      "global round: 87  client: 18  local train loss: 0.8221\n",
      "global round: 87  client: 96  local train loss: 0.7552\n",
      "global round: 87  client: 17  local train loss: 1.1777\n",
      "global round: 87  client: 50  local train loss: 0.8823\n",
      "global round: 87  client: 85  local train loss: 0.9219\n",
      "global round: 87  client: 98  local train loss: 0.8855\n",
      "global round: 87  avg train loss:0.0758  global test loss: 0.6902  global test accu: 0.8708\n",
      "================================================================================================================\n",
      "global round: 88  client: 08  local train loss: 0.9807\n",
      "global round: 88  client: 49  local train loss: 0.7549\n",
      "global round: 88  client: 78  local train loss: 0.8689\n",
      "global round: 88  client: 48  local train loss: 0.7980\n",
      "global round: 88  client: 18  local train loss: 0.8014\n",
      "global round: 88  client: 00  local train loss: 0.8528\n",
      "global round: 88  client: 72  local train loss: 0.8723\n",
      "global round: 88  client: 75  local train loss: 0.8543\n",
      "global round: 88  client: 02  local train loss: 0.8485\n",
      "global round: 88  client: 07  local train loss: 0.8996\n",
      "global round: 88  avg train loss:0.0649  global test loss: 0.6887  global test accu: 0.8715\n",
      "================================================================================================================\n",
      "global round: 89  client: 95  local train loss: 0.8809\n",
      "global round: 89  client: 81  local train loss: 0.7893\n",
      "global round: 89  client: 59  local train loss: 0.8343\n",
      "global round: 89  client: 48  local train loss: 0.7841\n",
      "global round: 89  client: 76  local train loss: 0.8290\n",
      "global round: 89  client: 80  local train loss: 0.9713\n",
      "global round: 89  client: 73  local train loss: 0.8609\n",
      "global round: 89  client: 87  local train loss: 0.7774\n",
      "global round: 89  client: 98  local train loss: 0.8613\n",
      "global round: 89  client: 07  local train loss: 0.8506\n",
      "global round: 89  avg train loss:0.1164  global test loss: 0.6742  global test accu: 0.8732\n",
      "================================================================================================================\n",
      "global round: 90  client: 15  local train loss: 0.8884\n",
      "global round: 90  client: 07  local train loss: 0.8308\n",
      "global round: 90  client: 22  local train loss: 0.7814\n",
      "global round: 90  client: 60  local train loss: 1.0550\n",
      "global round: 90  client: 31  local train loss: 0.9518\n",
      "global round: 90  client: 24  local train loss: 0.8869\n",
      "global round: 90  client: 79  local train loss: 0.8737\n",
      "global round: 90  client: 56  local train loss: 0.8375\n",
      "global round: 90  client: 84  local train loss: 0.7941\n",
      "global round: 90  client: 42  local train loss: 0.9075\n",
      "global round: 90  avg train loss:0.0637  global test loss: 0.6706  global test accu: 0.8733\n",
      "================================================================================================================\n",
      "global round: 91  client: 70  local train loss: 0.7059\n",
      "global round: 91  client: 24  local train loss: 0.7854\n",
      "global round: 91  client: 97  local train loss: 0.8761\n",
      "global round: 91  client: 75  local train loss: 0.7956\n",
      "global round: 91  client: 48  local train loss: 0.7675\n",
      "global round: 91  client: 07  local train loss: 0.8247\n",
      "global round: 91  client: 96  local train loss: 0.6823\n",
      "global round: 91  client: 26  local train loss: 0.9968\n",
      "global round: 91  client: 50  local train loss: 0.8319\n",
      "global round: 91  client: 59  local train loss: 0.7925\n",
      "global round: 91  avg train loss:0.0452  global test loss: 0.6685  global test accu: 0.8735\n",
      "================================================================================================================\n",
      "global round: 92  client: 20  local train loss: 1.1488\n",
      "global round: 92  client: 30  local train loss: 0.8802\n",
      "global round: 92  client: 82  local train loss: 0.9054\n",
      "global round: 92  client: 77  local train loss: 0.8387\n",
      "global round: 92  client: 21  local train loss: 0.7803\n",
      "global round: 92  client: 10  local train loss: 0.8528\n",
      "global round: 92  client: 73  local train loss: 0.7451\n",
      "global round: 92  client: 13  local train loss: 0.9164\n",
      "global round: 92  client: 94  local train loss: 0.8859\n",
      "global round: 92  client: 60  local train loss: 0.8116\n",
      "global round: 92  avg train loss:0.0672  global test loss: 0.6637  global test accu: 0.8742\n",
      "================================================================================================================\n",
      "global round: 93  client: 87  local train loss: 0.7490\n",
      "global round: 93  client: 32  local train loss: 0.9102\n",
      "global round: 93  client: 46  local train loss: 0.8937\n",
      "global round: 93  client: 43  local train loss: 0.8337\n",
      "global round: 93  client: 03  local train loss: 0.9169\n",
      "global round: 93  client: 00  local train loss: 0.8172\n",
      "global round: 93  client: 71  local train loss: 0.7595\n",
      "global round: 93  client: 51  local train loss: 0.9180\n",
      "global round: 93  client: 62  local train loss: 0.7668\n",
      "global round: 93  client: 67  local train loss: 0.8867\n",
      "global round: 93  avg train loss:0.1085  global test loss: 0.6547  global test accu: 0.8747\n",
      "================================================================================================================\n",
      "global round: 94  client: 18  local train loss: 0.7996\n",
      "global round: 94  client: 31  local train loss: 0.9277\n",
      "global round: 94  client: 26  local train loss: 0.9600\n",
      "global round: 94  client: 66  local train loss: 0.8150\n",
      "global round: 94  client: 78  local train loss: 0.8443\n",
      "global round: 94  client: 28  local train loss: 0.8403\n",
      "global round: 94  client: 73  local train loss: 0.7308\n",
      "global round: 94  client: 42  local train loss: 0.8846\n",
      "global round: 94  client: 47  local train loss: 0.8097\n",
      "global round: 94  client: 87  local train loss: 0.7306\n",
      "global round: 94  avg train loss:0.0938  global test loss: 0.6423  global test accu: 0.8760\n",
      "================================================================================================================\n",
      "global round: 95  client: 57  local train loss: 0.8339\n",
      "global round: 95  client: 33  local train loss: 0.8460\n",
      "global round: 95  client: 39  local train loss: 0.7823\n",
      "global round: 95  client: 95  local train loss: 0.7856\n",
      "global round: 95  client: 64  local train loss: 0.9092\n",
      "global round: 95  client: 17  local train loss: 0.9613\n",
      "global round: 95  client: 86  local train loss: 0.8146\n",
      "global round: 95  client: 83  local train loss: 0.8458\n",
      "global round: 95  client: 63  local train loss: 0.9240\n",
      "global round: 95  client: 10  local train loss: 0.7955\n",
      "global round: 95  avg train loss:0.0746  global test loss: 0.6449  global test accu: 0.8759\n",
      "================================================================================================================\n",
      "global round: 96  client: 92  local train loss: 0.9419\n",
      "global round: 96  client: 66  local train loss: 0.7603\n",
      "global round: 96  client: 38  local train loss: 0.8129\n",
      "global round: 96  client: 91  local train loss: 0.8545\n",
      "global round: 96  client: 65  local train loss: 0.8615\n",
      "global round: 96  client: 05  local train loss: 0.9369\n",
      "global round: 96  client: 27  local train loss: 0.7928\n",
      "global round: 96  client: 53  local train loss: 0.7885\n",
      "global round: 96  client: 11  local train loss: 0.9087\n",
      "global round: 96  client: 55  local train loss: 0.9315\n",
      "global round: 96  avg train loss:0.0370  global test loss: 0.6448  global test accu: 0.8760\n",
      "================================================================================================================\n",
      "global round: 97  client: 61  local train loss: 0.9760\n",
      "global round: 97  client: 06  local train loss: 0.8025\n",
      "global round: 97  client: 16  local train loss: 0.8781\n",
      "global round: 97  client: 67  local train loss: 0.7720\n",
      "global round: 97  client: 21  local train loss: 0.7291\n",
      "global round: 97  client: 96  local train loss: 0.6838\n",
      "global round: 97  client: 03  local train loss: 0.7688\n",
      "global round: 97  client: 53  local train loss: 0.7091\n",
      "global round: 97  client: 11  local train loss: 0.7651\n",
      "global round: 97  client: 37  local train loss: 0.8429\n",
      "global round: 97  avg train loss:0.0587  global test loss: 0.6436  global test accu: 0.8756\n",
      "================================================================================================================\n",
      "global round: 98  client: 77  local train loss: 0.8169\n",
      "global round: 98  client: 32  local train loss: 0.8033\n",
      "global round: 98  client: 72  local train loss: 0.8091\n",
      "global round: 98  client: 95  local train loss: 0.8031\n",
      "global round: 98  client: 43  local train loss: 0.8108\n",
      "global round: 98  client: 58  local train loss: 0.8062\n",
      "global round: 98  client: 45  local train loss: 0.8221\n",
      "global round: 98  client: 04  local train loss: 0.8636\n",
      "global round: 98  client: 81  local train loss: 0.7522\n",
      "global round: 98  client: 71  local train loss: 0.7385\n",
      "global round: 98  avg train loss:0.0830  global test loss: 0.6369  global test accu: 0.8768\n",
      "================================================================================================================\n",
      "global round: 99  client: 27  local train loss: 0.7470\n",
      "global round: 99  client: 54  local train loss: 0.9067\n",
      "global round: 99  client: 34  local train loss: 0.8901\n",
      "global round: 99  client: 31  local train loss: 0.9547\n",
      "global round: 99  client: 77  local train loss: 0.7934\n",
      "global round: 99  client: 70  local train loss: 0.6943\n",
      "global round: 99  client: 99  local train loss: 0.7955\n",
      "global round: 99  client: 07  local train loss: 0.8244\n",
      "global round: 99  client: 65  local train loss: 0.7483\n",
      "global round: 99  client: 36  local train loss: 0.8717\n",
      "global round: 99  avg train loss:0.0391  global test loss: 0.6376  global test accu: 0.8767\n",
      "================================================================================================================\n",
      "global round: 100  client: 17  local train loss: 0.9346\n",
      "global round: 100  client: 74  local train loss: 0.8515\n",
      "global round: 100  client: 92  local train loss: 0.8106\n",
      "global round: 100  client: 71  local train loss: 0.7219\n",
      "global round: 100  client: 44  local train loss: 0.7753\n",
      "global round: 100  client: 16  local train loss: 0.7897\n",
      "global round: 100  client: 75  local train loss: 0.7829\n",
      "global round: 100  client: 12  local train loss: 0.8363\n",
      "global round: 100  client: 55  local train loss: 0.8672\n",
      "global round: 100  client: 84  local train loss: 0.7759\n",
      "global round: 100  avg train loss:0.0909  global test loss: 0.6321  global test accu: 0.8772\n",
      "================================================================================================================\n",
      "global round: 101  client: 49  local train loss: 0.7199\n",
      "global round: 101  client: 83  local train loss: 0.7619\n",
      "global round: 101  client: 53  local train loss: 0.7081\n",
      "global round: 101  client: 85  local train loss: 0.8203\n",
      "global round: 101  client: 05  local train loss: 0.8183\n",
      "global round: 101  client: 98  local train loss: 0.8392\n",
      "global round: 101  client: 34  local train loss: 0.8197\n",
      "global round: 101  client: 16  local train loss: 0.7834\n",
      "global round: 101  client: 20  local train loss: 0.7745\n",
      "global round: 101  client: 78  local train loss: 0.8042\n",
      "global round: 101  avg train loss:0.0349  global test loss: 0.6319  global test accu: 0.8770\n",
      "================================================================================================================\n",
      "global round: 102  client: 50  local train loss: 0.8027\n",
      "global round: 102  client: 48  local train loss: 0.7633\n",
      "global round: 102  client: 62  local train loss: 0.7264\n",
      "global round: 102  client: 47  local train loss: 0.7471\n",
      "global round: 102  client: 13  local train loss: 0.8627\n",
      "global round: 102  client: 89  local train loss: 0.8478\n",
      "global round: 102  client: 82  local train loss: 0.7813\n",
      "global round: 102  client: 18  local train loss: 0.7615\n",
      "global round: 102  client: 32  local train loss: 0.7735\n",
      "global round: 102  client: 92  local train loss: 0.8169\n",
      "global round: 102  avg train loss:0.0423  global test loss: 0.6308  global test accu: 0.8769\n",
      "================================================================================================================\n",
      "global round: 103  client: 48  local train loss: 0.7420\n",
      "global round: 103  client: 30  local train loss: 0.7771\n",
      "global round: 103  client: 02  local train loss: 0.7896\n",
      "global round: 103  client: 18  local train loss: 0.7472\n",
      "global round: 103  client: 12  local train loss: 0.7617\n",
      "global round: 103  client: 93  local train loss: 0.8002\n",
      "global round: 103  client: 36  local train loss: 0.7016\n",
      "global round: 103  client: 75  local train loss: 0.7634\n",
      "global round: 103  client: 25  local train loss: 0.8559\n",
      "global round: 103  client: 04  local train loss: 0.7864\n",
      "global round: 103  avg train loss:0.0684  global test loss: 0.6282  global test accu: 0.8769\n",
      "================================================================================================================\n",
      "global round: 104  client: 86  local train loss: 0.7790\n",
      "global round: 104  client: 17  local train loss: 0.9049\n",
      "global round: 104  client: 46  local train loss: 0.7625\n",
      "global round: 104  client: 42  local train loss: 0.8575\n",
      "global round: 104  client: 66  local train loss: 0.7660\n",
      "global round: 104  client: 70  local train loss: 0.6635\n",
      "global round: 104  client: 19  local train loss: 0.9963\n",
      "global round: 104  client: 96  local train loss: 0.6691\n",
      "global round: 104  client: 10  local train loss: 0.7840\n",
      "global round: 104  client: 74  local train loss: 0.7600\n",
      "global round: 104  avg train loss:0.1067  global test loss: 0.6246  global test accu: 0.8777\n",
      "================================================================================================================\n",
      "global round: 105  client: 52  local train loss: 0.9066\n",
      "global round: 105  client: 67  local train loss: 0.7567\n",
      "global round: 105  client: 26  local train loss: 0.9157\n",
      "global round: 105  client: 25  local train loss: 0.8029\n",
      "global round: 105  client: 12  local train loss: 0.7509\n",
      "global round: 105  client: 96  local train loss: 0.6490\n",
      "global round: 105  client: 68  local train loss: 0.8077\n",
      "global round: 105  client: 54  local train loss: 0.7610\n",
      "global round: 105  client: 74  local train loss: 0.7533\n",
      "global round: 105  client: 85  local train loss: 0.7812\n",
      "global round: 105  avg train loss:0.0574  global test loss: 0.6225  global test accu: 0.8778\n",
      "================================================================================================================\n",
      "global round: 106  client: 89  local train loss: 0.7341\n",
      "global round: 106  client: 40  local train loss: 0.8675\n",
      "global round: 106  client: 00  local train loss: 0.7896\n",
      "global round: 106  client: 17  local train loss: 0.9115\n",
      "global round: 106  client: 66  local train loss: 0.7453\n",
      "global round: 106  client: 35  local train loss: 0.8406\n",
      "global round: 106  client: 76  local train loss: 0.8180\n",
      "global round: 106  client: 85  local train loss: 0.7715\n",
      "global round: 106  client: 82  local train loss: 0.7550\n",
      "global round: 106  client: 38  local train loss: 0.7598\n",
      "global round: 106  avg train loss:0.0720  global test loss: 0.6214  global test accu: 0.8779\n",
      "================================================================================================================\n",
      "global round: 107  client: 22  local train loss: 0.7687\n",
      "global round: 107  client: 08  local train loss: 0.8409\n",
      "global round: 107  client: 20  local train loss: 0.7562\n",
      "global round: 107  client: 61  local train loss: 0.8412\n",
      "global round: 107  client: 82  local train loss: 0.7458\n",
      "global round: 107  client: 45  local train loss: 0.7412\n",
      "global round: 107  client: 85  local train loss: 0.7692\n",
      "global round: 107  client: 31  local train loss: 0.9181\n",
      "global round: 107  client: 36  local train loss: 0.7028\n",
      "global round: 107  client: 84  local train loss: 0.7418\n",
      "global round: 107  avg train loss:0.0634  global test loss: 0.6180  global test accu: 0.8785\n",
      "================================================================================================================\n",
      "global round: 108  client: 85  local train loss: 0.7655\n",
      "global round: 108  client: 11  local train loss: 0.7567\n",
      "global round: 108  client: 60  local train loss: 0.8039\n",
      "global round: 108  client: 06  local train loss: 0.7344\n",
      "global round: 108  client: 69  local train loss: 0.9798\n",
      "global round: 108  client: 22  local train loss: 0.7299\n",
      "global round: 108  client: 68  local train loss: 0.7587\n",
      "global round: 108  client: 54  local train loss: 0.7500\n",
      "global round: 108  client: 02  local train loss: 0.7338\n",
      "global round: 108  client: 81  local train loss: 0.7192\n",
      "global round: 108  avg train loss:0.0818  global test loss: 0.6108  global test accu: 0.8793\n",
      "================================================================================================================\n",
      "global round: 109  client: 75  local train loss: 0.7563\n",
      "global round: 109  client: 38  local train loss: 0.7537\n",
      "global round: 109  client: 31  local train loss: 0.9072\n",
      "global round: 109  client: 59  local train loss: 0.7947\n",
      "global round: 109  client: 98  local train loss: 0.8032\n",
      "global round: 109  client: 32  local train loss: 0.7717\n",
      "global round: 109  client: 89  local train loss: 0.7188\n",
      "global round: 109  client: 45  local train loss: 0.7111\n",
      "global round: 109  client: 04  local train loss: 0.7850\n",
      "global round: 109  client: 66  local train loss: 0.7418\n",
      "global round: 109  avg train loss:0.0497  global test loss: 0.6094  global test accu: 0.8793\n",
      "================================================================================================================\n",
      "global round: 110  client: 66  local train loss: 0.7338\n",
      "global round: 110  client: 32  local train loss: 0.7444\n",
      "global round: 110  client: 45  local train loss: 0.6958\n",
      "global round: 110  client: 59  local train loss: 0.7330\n",
      "global round: 110  client: 93  local train loss: 0.7328\n",
      "global round: 110  client: 60  local train loss: 0.7602\n",
      "global round: 110  client: 50  local train loss: 0.7477\n",
      "global round: 110  client: 27  local train loss: 0.7430\n",
      "global round: 110  client: 86  local train loss: 0.7562\n",
      "global round: 110  client: 35  local train loss: 0.7203\n",
      "global round: 110  avg train loss:0.0694  global test loss: 0.6053  global test accu: 0.8796\n",
      "================================================================================================================\n",
      "global round: 111  client: 05  local train loss: 0.8058\n",
      "global round: 111  client: 51  local train loss: 0.9135\n",
      "global round: 111  client: 68  local train loss: 0.7099\n",
      "global round: 111  client: 98  local train loss: 0.7914\n",
      "global round: 111  client: 20  local train loss: 0.7366\n",
      "global round: 111  client: 52  local train loss: 0.7701\n",
      "global round: 111  client: 17  local train loss: 0.9024\n",
      "global round: 111  client: 65  local train loss: 0.7266\n",
      "global round: 111  client: 04  local train loss: 0.7718\n",
      "global round: 111  client: 00  local train loss: 0.7582\n",
      "global round: 111  avg train loss:0.0276  global test loss: 0.6050  global test accu: 0.8800\n",
      "================================================================================================================\n",
      "global round: 112  client: 77  local train loss: 0.7998\n",
      "global round: 112  client: 05  local train loss: 0.8270\n",
      "global round: 112  client: 37  local train loss: 0.7655\n",
      "global round: 112  client: 86  local train loss: 0.7424\n",
      "global round: 112  client: 44  local train loss: 0.7374\n",
      "global round: 112  client: 42  local train loss: 0.8358\n",
      "global round: 112  client: 66  local train loss: 0.7237\n",
      "global round: 112  client: 11  local train loss: 0.7389\n",
      "global round: 112  client: 99  local train loss: 0.7348\n",
      "global round: 112  client: 81  local train loss: 0.7001\n",
      "global round: 112  avg train loss:0.0835  global test loss: 0.5982  global test accu: 0.8809\n",
      "================================================================================================================\n",
      "global round: 113  client: 01  local train loss: 0.8340\n",
      "global round: 113  client: 09  local train loss: 0.9065\n",
      "global round: 113  client: 42  local train loss: 0.7926\n",
      "global round: 113  client: 81  local train loss: 0.6915\n",
      "global round: 113  client: 26  local train loss: 0.9213\n",
      "global round: 113  client: 41  local train loss: 0.7847\n",
      "global round: 113  client: 08  local train loss: 0.7745\n",
      "global round: 113  client: 22  local train loss: 0.7272\n",
      "global round: 113  client: 02  local train loss: 0.7223\n",
      "global round: 113  client: 13  local train loss: 0.8495\n",
      "global round: 113  avg train loss:0.0790  global test loss: 0.5949  global test accu: 0.8818\n",
      "================================================================================================================\n",
      "global round: 114  client: 91  local train loss: 0.7205\n",
      "global round: 114  client: 83  local train loss: 0.7555\n",
      "global round: 114  client: 59  local train loss: 0.7382\n",
      "global round: 114  client: 01  local train loss: 0.7372\n",
      "global round: 114  client: 84  local train loss: 0.7304\n",
      "global round: 114  client: 93  local train loss: 0.7157\n",
      "global round: 114  client: 40  local train loss: 0.7922\n",
      "global round: 114  client: 68  local train loss: 0.7628\n",
      "global round: 114  client: 61  local train loss: 0.8094\n",
      "global round: 114  client: 55  local train loss: 0.8143\n",
      "global round: 114  avg train loss:0.0545  global test loss: 0.5933  global test accu: 0.8815\n",
      "================================================================================================================\n",
      "global round: 115  client: 95  local train loss: 0.8469\n",
      "global round: 115  client: 34  local train loss: 0.8041\n",
      "global round: 115  client: 71  local train loss: 0.7187\n",
      "global round: 115  client: 94  local train loss: 0.7617\n",
      "global round: 115  client: 18  local train loss: 0.7564\n",
      "global round: 115  client: 19  local train loss: 0.7061\n",
      "global round: 115  client: 51  local train loss: 0.9020\n",
      "global round: 115  client: 91  local train loss: 0.6786\n",
      "global round: 115  client: 76  local train loss: 0.7607\n",
      "global round: 115  client: 59  local train loss: 0.7243\n",
      "global round: 115  avg train loss:0.0722  global test loss: 0.5884  global test accu: 0.8823\n",
      "================================================================================================================\n",
      "global round: 116  client: 13  local train loss: 0.7709\n",
      "global round: 116  client: 88  local train loss: 0.7541\n",
      "global round: 116  client: 11  local train loss: 0.7322\n",
      "global round: 116  client: 31  local train loss: 0.8702\n",
      "global round: 116  client: 75  local train loss: 0.7370\n",
      "global round: 116  client: 01  local train loss: 0.7294\n",
      "global round: 116  client: 55  local train loss: 0.7257\n",
      "global round: 116  client: 44  local train loss: 0.7122\n",
      "global round: 116  client: 72  local train loss: 0.7711\n",
      "global round: 116  client: 46  local train loss: 0.7377\n",
      "global round: 116  avg train loss:0.0985  global test loss: 0.5814  global test accu: 0.8827\n",
      "================================================================================================================\n",
      "global round: 117  client: 68  local train loss: 0.7397\n",
      "global round: 117  client: 81  local train loss: 0.6890\n",
      "global round: 117  client: 53  local train loss: 0.6991\n",
      "global round: 117  client: 78  local train loss: 0.8051\n",
      "global round: 117  client: 33  local train loss: 0.7903\n",
      "global round: 117  client: 32  local train loss: 0.7523\n",
      "global round: 117  client: 56  local train loss: 0.7993\n",
      "global round: 117  client: 94  local train loss: 0.6791\n",
      "global round: 117  client: 70  local train loss: 0.6427\n",
      "global round: 117  client: 72  local train loss: 0.7238\n",
      "global round: 117  avg train loss:0.0557  global test loss: 0.5789  global test accu: 0.8825\n",
      "================================================================================================================\n",
      "global round: 118  client: 54  local train loss: 0.7475\n",
      "global round: 118  client: 39  local train loss: 0.7177\n",
      "global round: 118  client: 62  local train loss: 0.7071\n",
      "global round: 118  client: 25  local train loss: 0.7767\n",
      "global round: 118  client: 59  local train loss: 0.7240\n",
      "global round: 118  client: 46  local train loss: 0.7093\n",
      "global round: 118  client: 63  local train loss: 0.7408\n",
      "global round: 118  client: 09  local train loss: 0.7103\n",
      "global round: 118  client: 95  local train loss: 0.7396\n",
      "global round: 118  client: 71  local train loss: 0.6877\n",
      "global round: 118  avg train loss:0.0860  global test loss: 0.5729  global test accu: 0.8834\n",
      "================================================================================================================\n",
      "global round: 119  client: 36  local train loss: 0.6869\n",
      "global round: 119  client: 45  local train loss: 0.6802\n",
      "global round: 119  client: 33  local train loss: 0.7290\n",
      "global round: 119  client: 38  local train loss: 0.7427\n",
      "global round: 119  client: 09  local train loss: 0.7008\n",
      "global round: 119  client: 66  local train loss: 0.7130\n",
      "global round: 119  client: 91  local train loss: 0.6504\n",
      "global round: 119  client: 40  local train loss: 0.7780\n",
      "global round: 119  client: 28  local train loss: 0.7650\n",
      "global round: 119  client: 11  local train loss: 0.7216\n",
      "global round: 119  avg train loss:0.0580  global test loss: 0.5721  global test accu: 0.8836\n",
      "================================================================================================================\n",
      "global round: 120  client: 88  local train loss: 0.6661\n",
      "global round: 120  client: 14  local train loss: 0.8080\n",
      "global round: 120  client: 98  local train loss: 0.7873\n",
      "global round: 120  client: 56  local train loss: 0.7260\n",
      "global round: 120  client: 43  local train loss: 0.7660\n",
      "global round: 120  client: 15  local train loss: 0.8623\n",
      "global round: 120  client: 27  local train loss: 0.7126\n",
      "global round: 120  client: 75  local train loss: 0.7118\n",
      "global round: 120  client: 00  local train loss: 0.7354\n",
      "global round: 120  client: 77  local train loss: 0.7711\n",
      "global round: 120  avg train loss:0.0719  global test loss: 0.5681  global test accu: 0.8841\n",
      "================================================================================================================\n",
      "global round: 121  client: 84  local train loss: 0.7116\n",
      "global round: 121  client: 38  local train loss: 0.6816\n",
      "global round: 121  client: 95  local train loss: 0.7652\n",
      "global round: 121  client: 44  local train loss: 0.6907\n",
      "global round: 121  client: 32  local train loss: 0.7320\n",
      "global round: 121  client: 24  local train loss: 0.7856\n",
      "global round: 121  client: 33  local train loss: 0.7288\n",
      "global round: 121  client: 53  local train loss: 0.6389\n",
      "global round: 121  client: 06  local train loss: 0.7049\n",
      "global round: 121  client: 86  local train loss: 0.7325\n",
      "global round: 121  avg train loss:0.0697  global test loss: 0.5651  global test accu: 0.8840\n",
      "================================================================================================================\n",
      "global round: 122  client: 17  local train loss: 0.8863\n",
      "global round: 122  client: 07  local train loss: 0.7975\n",
      "global round: 122  client: 80  local train loss: 0.8510\n",
      "global round: 122  client: 76  local train loss: 0.7349\n",
      "global round: 122  client: 70  local train loss: 0.6127\n",
      "global round: 122  client: 59  local train loss: 0.7003\n",
      "global round: 122  client: 95  local train loss: 0.7340\n",
      "global round: 122  client: 88  local train loss: 0.6570\n",
      "global round: 122  client: 04  local train loss: 0.7670\n",
      "global round: 122  client: 62  local train loss: 0.6523\n",
      "global round: 122  avg train loss:0.0555  global test loss: 0.5610  global test accu: 0.8842\n",
      "================================================================================================================\n",
      "global round: 123  client: 06  local train loss: 0.6687\n",
      "global round: 123  client: 58  local train loss: 0.7557\n",
      "global round: 123  client: 57  local train loss: 0.7176\n",
      "global round: 123  client: 04  local train loss: 0.7207\n",
      "global round: 123  client: 36  local train loss: 0.6411\n",
      "global round: 123  client: 48  local train loss: 0.7450\n",
      "global round: 123  client: 74  local train loss: 0.7519\n",
      "global round: 123  client: 86  local train loss: 0.7079\n",
      "global round: 123  client: 46  local train loss: 0.6965\n",
      "global round: 123  client: 70  local train loss: 0.6039\n",
      "global round: 123  avg train loss:0.0891  global test loss: 0.5573  global test accu: 0.8848\n",
      "================================================================================================================\n",
      "global round: 124  client: 31  local train loss: 0.8498\n",
      "global round: 124  client: 51  local train loss: 0.9112\n",
      "global round: 124  client: 03  local train loss: 0.7515\n",
      "global round: 124  client: 79  local train loss: 0.8479\n",
      "global round: 124  client: 43  local train loss: 0.7179\n",
      "global round: 124  client: 25  local train loss: 0.7427\n",
      "global round: 124  client: 02  local train loss: 0.7089\n",
      "global round: 124  client: 90  local train loss: 0.7908\n",
      "global round: 124  client: 77  local train loss: 0.7388\n",
      "global round: 124  client: 88  local train loss: 0.6481\n",
      "global round: 124  avg train loss:0.0764  global test loss: 0.5540  global test accu: 0.8855\n",
      "================================================================================================================\n",
      "global round: 125  client: 12  local train loss: 0.7517\n",
      "global round: 125  client: 47  local train loss: 0.7104\n",
      "global round: 125  client: 17  local train loss: 0.8668\n",
      "global round: 125  client: 36  local train loss: 0.6313\n",
      "global round: 125  client: 85  local train loss: 0.7835\n",
      "global round: 125  client: 75  local train loss: 0.6989\n",
      "global round: 125  client: 53  local train loss: 0.6331\n",
      "global round: 125  client: 46  local train loss: 0.6883\n",
      "global round: 125  client: 76  local train loss: 0.7200\n",
      "global round: 125  client: 61  local train loss: 0.8004\n",
      "global round: 125  avg train loss:0.0670  global test loss: 0.5514  global test accu: 0.8858\n",
      "================================================================================================================\n",
      "global round: 126  client: 80  local train loss: 0.7669\n",
      "global round: 126  client: 28  local train loss: 0.7199\n",
      "global round: 126  client: 94  local train loss: 0.6613\n",
      "global round: 126  client: 38  local train loss: 0.6876\n",
      "global round: 126  client: 87  local train loss: 0.7220\n",
      "global round: 126  client: 58  local train loss: 0.6882\n",
      "global round: 126  client: 72  local train loss: 0.7177\n",
      "global round: 126  client: 89  local train loss: 0.7035\n",
      "global round: 126  client: 92  local train loss: 0.8025\n",
      "global round: 126  client: 67  local train loss: 0.7476\n",
      "global round: 126  avg train loss:0.0747  global test loss: 0.5495  global test accu: 0.8862\n",
      "================================================================================================================\n",
      "global round: 127  client: 68  local train loss: 0.7231\n",
      "global round: 127  client: 87  local train loss: 0.6604\n",
      "global round: 127  client: 43  local train loss: 0.7054\n",
      "global round: 127  client: 69  local train loss: 0.7783\n",
      "global round: 127  client: 57  local train loss: 0.6385\n",
      "global round: 127  client: 14  local train loss: 0.6865\n",
      "global round: 127  client: 89  local train loss: 0.6537\n",
      "global round: 127  client: 12  local train loss: 0.6776\n",
      "global round: 127  client: 27  local train loss: 0.6832\n",
      "global round: 127  client: 60  local train loss: 0.7619\n",
      "global round: 127  avg train loss:0.0527  global test loss: 0.5458  global test accu: 0.8866\n",
      "================================================================================================================\n",
      "global round: 128  client: 63  local train loss: 0.6927\n",
      "global round: 128  client: 61  local train loss: 0.7317\n",
      "global round: 128  client: 70  local train loss: 0.6068\n",
      "global round: 128  client: 75  local train loss: 0.6855\n",
      "global round: 128  client: 35  local train loss: 0.7090\n",
      "global round: 128  client: 76  local train loss: 0.7054\n",
      "global round: 128  client: 94  local train loss: 0.6233\n",
      "global round: 128  client: 73  local train loss: 0.7204\n",
      "global round: 128  client: 42  local train loss: 0.7947\n",
      "global round: 128  client: 59  local train loss: 0.7030\n",
      "global round: 128  avg train loss:0.0818  global test loss: 0.5431  global test accu: 0.8874\n",
      "================================================================================================================\n",
      "global round: 129  client: 34  local train loss: 0.7622\n",
      "global round: 129  client: 11  local train loss: 0.6986\n",
      "global round: 129  client: 97  local train loss: 0.8098\n",
      "global round: 129  client: 84  local train loss: 0.6826\n",
      "global round: 129  client: 17  local train loss: 0.8519\n",
      "global round: 129  client: 54  local train loss: 0.6801\n",
      "global round: 129  client: 90  local train loss: 0.6764\n",
      "global round: 129  client: 63  local train loss: 0.6646\n",
      "global round: 129  client: 42  local train loss: 0.7375\n",
      "global round: 129  client: 18  local train loss: 0.7171\n",
      "global round: 129  avg train loss:0.0691  global test loss: 0.5405  global test accu: 0.8879\n",
      "================================================================================================================\n",
      "global round: 130  client: 13  local train loss: 0.8240\n",
      "global round: 130  client: 30  local train loss: 0.7462\n",
      "global round: 130  client: 39  local train loss: 0.6635\n",
      "global round: 130  client: 28  local train loss: 0.7003\n",
      "global round: 130  client: 22  local train loss: 0.7124\n",
      "global round: 130  client: 73  local train loss: 0.6482\n",
      "global round: 130  client: 31  local train loss: 0.8378\n",
      "global round: 130  client: 52  local train loss: 0.7564\n",
      "global round: 130  client: 45  local train loss: 0.6470\n",
      "global round: 130  client: 05  local train loss: 0.7698\n",
      "global round: 130  avg train loss:0.0684  global test loss: 0.5368  global test accu: 0.8885\n",
      "================================================================================================================\n",
      "global round: 131  client: 15  local train loss: 0.7509\n",
      "global round: 131  client: 24  local train loss: 0.6941\n",
      "global round: 131  client: 67  local train loss: 0.6803\n",
      "global round: 131  client: 82  local train loss: 0.7380\n",
      "global round: 131  client: 06  local train loss: 0.6623\n",
      "global round: 131  client: 19  local train loss: 0.6781\n",
      "global round: 131  client: 79  local train loss: 0.7317\n",
      "global round: 131  client: 47  local train loss: 0.6657\n",
      "global round: 131  client: 88  local train loss: 0.6397\n",
      "global round: 131  client: 34  local train loss: 0.7121\n",
      "global round: 131  avg train loss:0.0944  global test loss: 0.5312  global test accu: 0.8886\n",
      "================================================================================================================\n",
      "global round: 132  client: 11  local train loss: 0.6734\n",
      "global round: 132  client: 78  local train loss: 0.7572\n",
      "global round: 132  client: 70  local train loss: 0.5752\n",
      "global round: 132  client: 57  local train loss: 0.6358\n",
      "global round: 132  client: 26  local train loss: 0.8893\n",
      "global round: 132  client: 24  local train loss: 0.6401\n",
      "global round: 132  client: 03  local train loss: 0.6653\n",
      "global round: 132  client: 15  local train loss: 0.7189\n",
      "global round: 132  client: 17  local train loss: 0.8369\n",
      "global round: 132  client: 59  local train loss: 0.6839\n",
      "global round: 132  avg train loss:0.0278  global test loss: 0.5313  global test accu: 0.8886\n",
      "================================================================================================================\n",
      "global round: 133  client: 67  local train loss: 0.6675\n",
      "global round: 133  client: 14  local train loss: 0.6687\n",
      "global round: 133  client: 25  local train loss: 0.7166\n",
      "global round: 133  client: 55  local train loss: 0.6978\n",
      "global round: 133  client: 01  local train loss: 0.7246\n",
      "global round: 133  client: 43  local train loss: 0.6819\n",
      "global round: 133  client: 32  local train loss: 0.7151\n",
      "global round: 133  client: 35  local train loss: 0.6524\n",
      "global round: 133  client: 74  local train loss: 0.6934\n",
      "global round: 133  client: 40  local train loss: 0.7560\n",
      "global round: 133  avg train loss:0.0600  global test loss: 0.5300  global test accu: 0.8887\n",
      "================================================================================================================\n",
      "global round: 134  client: 38  local train loss: 0.6705\n",
      "global round: 134  client: 26  local train loss: 0.8730\n",
      "global round: 134  client: 64  local train loss: 0.7697\n",
      "global round: 134  client: 14  local train loss: 0.6545\n",
      "global round: 134  client: 99  local train loss: 0.7049\n",
      "global round: 134  client: 75  local train loss: 0.6735\n",
      "global round: 134  client: 61  local train loss: 0.7449\n",
      "global round: 134  client: 40  local train loss: 0.7190\n",
      "global round: 134  client: 11  local train loss: 0.6523\n",
      "global round: 134  client: 69  local train loss: 0.7196\n",
      "global round: 134  avg train loss:0.0443  global test loss: 0.5307  global test accu: 0.8883\n",
      "================================================================================================================\n",
      "global round: 135  client: 55  local train loss: 0.6713\n",
      "global round: 135  client: 85  local train loss: 0.6989\n",
      "global round: 135  client: 40  local train loss: 0.7135\n",
      "global round: 135  client: 35  local train loss: 0.6441\n",
      "global round: 135  client: 73  local train loss: 0.6435\n",
      "global round: 135  client: 54  local train loss: 0.6568\n",
      "global round: 135  client: 59  local train loss: 0.6682\n",
      "global round: 135  client: 88  local train loss: 0.6206\n",
      "global round: 135  client: 93  local train loss: 0.7028\n",
      "global round: 135  client: 80  local train loss: 0.7494\n",
      "global round: 135  avg train loss:0.0885  global test loss: 0.5233  global test accu: 0.8891\n",
      "================================================================================================================\n",
      "global round: 136  client: 23  local train loss: 0.8692\n",
      "global round: 136  client: 26  local train loss: 0.8713\n",
      "global round: 136  client: 05  local train loss: 0.7135\n",
      "global round: 136  client: 85  local train loss: 0.6860\n",
      "global round: 136  client: 82  local train loss: 0.6658\n",
      "global round: 136  client: 55  local train loss: 0.6974\n",
      "global round: 136  client: 79  local train loss: 0.7146\n",
      "global round: 136  client: 70  local train loss: 0.5436\n",
      "global round: 136  client: 42  local train loss: 0.7603\n",
      "global round: 136  client: 06  local train loss: 0.6401\n",
      "global round: 136  avg train loss:0.0375  global test loss: 0.5222  global test accu: 0.8890\n",
      "================================================================================================================\n",
      "global round: 137  client: 64  local train loss: 0.6589\n",
      "global round: 137  client: 35  local train loss: 0.6393\n",
      "global round: 137  client: 04  local train loss: 0.7191\n",
      "global round: 137  client: 97  local train loss: 0.6850\n",
      "global round: 137  client: 42  local train loss: 0.6871\n",
      "global round: 137  client: 71  local train loss: 0.6762\n",
      "global round: 137  client: 24  local train loss: 0.6418\n",
      "global round: 137  client: 33  local train loss: 0.7241\n",
      "global round: 137  client: 50  local train loss: 0.7340\n",
      "global round: 137  client: 51  local train loss: 0.8953\n",
      "global round: 137  avg train loss:0.0552  global test loss: 0.5208  global test accu: 0.8889\n",
      "================================================================================================================\n",
      "global round: 138  client: 27  local train loss: 0.6640\n",
      "global round: 138  client: 55  local train loss: 0.6727\n",
      "global round: 138  client: 23  local train loss: 0.5955\n",
      "global round: 138  client: 76  local train loss: 0.6945\n",
      "global round: 138  client: 80  local train loss: 0.7425\n",
      "global round: 138  client: 10  local train loss: 0.7637\n",
      "global round: 138  client: 61  local train loss: 0.7390\n",
      "global round: 138  client: 21  local train loss: 0.7227\n",
      "global round: 138  client: 01  local train loss: 0.6669\n",
      "global round: 138  client: 51  local train loss: 0.8704\n",
      "global round: 138  avg train loss:0.0329  global test loss: 0.5215  global test accu: 0.8889\n",
      "================================================================================================================\n",
      "global round: 139  client: 27  local train loss: 0.6345\n",
      "global round: 139  client: 23  local train loss: 0.6236\n",
      "global round: 139  client: 00  local train loss: 0.7084\n",
      "global round: 139  client: 88  local train loss: 0.6189\n",
      "global round: 139  client: 08  local train loss: 0.7764\n",
      "global round: 139  client: 60  local train loss: 0.7271\n",
      "global round: 139  client: 02  local train loss: 0.6778\n",
      "global round: 139  client: 06  local train loss: 0.6350\n",
      "global round: 139  client: 58  local train loss: 0.6816\n",
      "global round: 139  client: 10  local train loss: 0.6644\n",
      "global round: 139  avg train loss:0.0720  global test loss: 0.5170  global test accu: 0.8892\n",
      "================================================================================================================\n",
      "global round: 140  client: 22  local train loss: 0.6648\n",
      "global round: 140  client: 58  local train loss: 0.6435\n",
      "global round: 140  client: 13  local train loss: 0.7684\n",
      "global round: 140  client: 53  local train loss: 0.6116\n",
      "global round: 140  client: 86  local train loss: 0.7038\n",
      "global round: 140  client: 41  local train loss: 0.6912\n",
      "global round: 140  client: 60  local train loss: 0.6801\n",
      "global round: 140  client: 52  local train loss: 0.6895\n",
      "global round: 140  client: 00  local train loss: 0.6487\n",
      "global round: 140  client: 73  local train loss: 0.6302\n",
      "global round: 140  avg train loss:0.0789  global test loss: 0.5136  global test accu: 0.8898\n",
      "================================================================================================================\n",
      "global round: 141  client: 73  local train loss: 0.6199\n",
      "global round: 141  client: 92  local train loss: 0.7513\n",
      "global round: 141  client: 48  local train loss: 0.6690\n",
      "global round: 141  client: 40  local train loss: 0.7098\n",
      "global round: 141  client: 57  local train loss: 0.6225\n",
      "global round: 141  client: 84  local train loss: 0.6584\n",
      "global round: 141  client: 56  local train loss: 0.7095\n",
      "global round: 141  client: 39  local train loss: 0.6218\n",
      "global round: 141  client: 30  local train loss: 0.6265\n",
      "global round: 141  client: 80  local train loss: 0.7340\n",
      "global round: 141  avg train loss:0.0656  global test loss: 0.5110  global test accu: 0.8901\n",
      "================================================================================================================\n",
      "global round: 142  client: 92  local train loss: 0.7047\n",
      "global round: 142  client: 47  local train loss: 0.6176\n",
      "global round: 142  client: 45  local train loss: 0.6456\n",
      "global round: 142  client: 02  local train loss: 0.6389\n",
      "global round: 142  client: 68  local train loss: 0.6720\n",
      "global round: 142  client: 16  local train loss: 0.7826\n",
      "global round: 142  client: 65  local train loss: 0.7195\n",
      "global round: 142  client: 81  local train loss: 0.6763\n",
      "global round: 142  client: 63  local train loss: 0.6641\n",
      "global round: 142  client: 27  local train loss: 0.6227\n",
      "global round: 142  avg train loss:0.0560  global test loss: 0.5100  global test accu: 0.8902\n",
      "================================================================================================================\n",
      "global round: 143  client: 65  local train loss: 0.6127\n",
      "global round: 143  client: 36  local train loss: 0.6275\n",
      "global round: 143  client: 51  local train loss: 0.8742\n",
      "global round: 143  client: 56  local train loss: 0.6516\n",
      "global round: 143  client: 93  local train loss: 0.6449\n",
      "global round: 143  client: 84  local train loss: 0.6262\n",
      "global round: 143  client: 00  local train loss: 0.6577\n",
      "global round: 143  client: 58  local train loss: 0.6434\n",
      "global round: 143  client: 99  local train loss: 0.6355\n",
      "global round: 143  client: 73  local train loss: 0.6186\n",
      "global round: 143  avg train loss:0.0677  global test loss: 0.5061  global test accu: 0.8906\n",
      "================================================================================================================\n",
      "global round: 144  client: 19  local train loss: 0.6267\n",
      "global round: 144  client: 50  local train loss: 0.6559\n",
      "global round: 144  client: 23  local train loss: 0.6247\n",
      "global round: 144  client: 97  local train loss: 0.6767\n",
      "global round: 144  client: 11  local train loss: 0.6471\n",
      "global round: 144  client: 32  local train loss: 0.6781\n",
      "global round: 144  client: 37  local train loss: 0.7285\n",
      "global round: 144  client: 60  local train loss: 0.6708\n",
      "global round: 144  client: 10  local train loss: 0.6559\n",
      "global round: 144  client: 98  local train loss: 0.7532\n",
      "global round: 144  avg train loss:0.0522  global test loss: 0.5052  global test accu: 0.8909\n",
      "================================================================================================================\n",
      "global round: 145  client: 55  local train loss: 0.7142\n",
      "global round: 145  client: 96  local train loss: 0.6386\n",
      "global round: 145  client: 14  local train loss: 0.6628\n",
      "global round: 145  client: 19  local train loss: 0.6075\n",
      "global round: 145  client: 27  local train loss: 0.6064\n",
      "global round: 145  client: 09  local train loss: 0.6968\n",
      "global round: 145  client: 83  local train loss: 0.7229\n",
      "global round: 145  client: 38  local train loss: 0.6394\n",
      "global round: 145  client: 11  local train loss: 0.6259\n",
      "global round: 145  client: 29  local train loss: 0.7505\n",
      "global round: 145  avg train loss:0.0518  global test loss: 0.5043  global test accu: 0.8911\n",
      "================================================================================================================\n",
      "global round: 146  client: 02  local train loss: 0.6297\n",
      "global round: 146  client: 38  local train loss: 0.6144\n",
      "global round: 146  client: 06  local train loss: 0.6288\n",
      "global round: 146  client: 59  local train loss: 0.6588\n",
      "global round: 146  client: 66  local train loss: 0.7034\n",
      "global round: 146  client: 95  local train loss: 0.7622\n",
      "global round: 146  client: 25  local train loss: 0.6998\n",
      "global round: 146  client: 80  local train loss: 0.7132\n",
      "global round: 146  client: 24  local train loss: 0.6420\n",
      "global round: 146  client: 50  local train loss: 0.6400\n",
      "global round: 146  avg train loss:0.0518  global test loss: 0.5036  global test accu: 0.8909\n",
      "================================================================================================================\n",
      "global round: 147  client: 06  local train loss: 0.6197\n",
      "global round: 147  client: 40  local train loss: 0.7041\n",
      "global round: 147  client: 66  local train loss: 0.6351\n",
      "global round: 147  client: 17  local train loss: 0.8295\n",
      "global round: 147  client: 13  local train loss: 0.7286\n",
      "global round: 147  client: 02  local train loss: 0.6234\n",
      "global round: 147  client: 94  local train loss: 0.6526\n",
      "global round: 147  client: 31  local train loss: 0.8280\n",
      "global round: 147  client: 01  local train loss: 0.6661\n",
      "global round: 147  client: 41  local train loss: 0.6158\n",
      "global round: 147  avg train loss:0.0557  global test loss: 0.5017  global test accu: 0.8912\n",
      "================================================================================================================\n",
      "global round: 148  client: 60  local train loss: 0.6548\n",
      "global round: 148  client: 59  local train loss: 0.6343\n",
      "global round: 148  client: 63  local train loss: 0.6398\n",
      "global round: 148  client: 68  local train loss: 0.6605\n",
      "global round: 148  client: 29  local train loss: 0.5611\n",
      "global round: 148  client: 81  local train loss: 0.6268\n",
      "global round: 148  client: 37  local train loss: 0.6397\n",
      "global round: 148  client: 96  local train loss: 0.5280\n",
      "global round: 148  client: 80  local train loss: 0.7089\n",
      "global round: 148  client: 74  local train loss: 0.6724\n",
      "global round: 148  avg train loss:0.0633  global test loss: 0.4988  global test accu: 0.8915\n",
      "================================================================================================================\n",
      "global round: 149  client: 46  local train loss: 0.6753\n",
      "global round: 149  client: 08  local train loss: 0.7132\n",
      "global round: 149  client: 42  local train loss: 0.6906\n",
      "global round: 149  client: 68  local train loss: 0.6458\n",
      "global round: 149  client: 33  local train loss: 0.6660\n",
      "global round: 149  client: 20  local train loss: 0.7247\n",
      "global round: 149  client: 41  local train loss: 0.6115\n",
      "global round: 149  client: 60  local train loss: 0.6599\n",
      "global round: 149  client: 89  local train loss: 0.6329\n",
      "global round: 149  client: 67  local train loss: 0.6664\n",
      "global round: 149  avg train loss:0.0538  global test loss: 0.4979  global test accu: 0.8916\n",
      "================================================================================================================\n",
      "global round: 150  client: 08  local train loss: 0.6758\n",
      "global round: 150  client: 15  local train loss: 0.7216\n",
      "global round: 150  client: 85  local train loss: 0.6798\n",
      "global round: 150  client: 39  local train loss: 0.5919\n",
      "global round: 150  client: 76  local train loss: 0.6858\n",
      "global round: 150  client: 80  local train loss: 0.7167\n",
      "global round: 150  client: 38  local train loss: 0.6181\n",
      "global round: 150  client: 63  local train loss: 0.6269\n",
      "global round: 150  client: 53  local train loss: 0.5900\n",
      "global round: 150  client: 59  local train loss: 0.6340\n",
      "global round: 150  avg train loss:0.0470  global test loss: 0.4970  global test accu: 0.8913\n",
      "================================================================================================================\n",
      "global round: 151  client: 63  local train loss: 0.6254\n",
      "global round: 151  client: 12  local train loss: 0.6715\n",
      "global round: 151  client: 39  local train loss: 0.5699\n",
      "global round: 151  client: 21  local train loss: 0.5806\n",
      "global round: 151  client: 46  local train loss: 0.6445\n",
      "global round: 151  client: 18  local train loss: 0.6728\n",
      "global round: 151  client: 20  local train loss: 0.6079\n",
      "global round: 151  client: 75  local train loss: 0.6605\n",
      "global round: 151  client: 72  local train loss: 0.6947\n",
      "global round: 151  client: 15  local train loss: 0.6893\n",
      "global round: 151  avg train loss:0.0736  global test loss: 0.4948  global test accu: 0.8923\n",
      "================================================================================================================\n",
      "global round: 152  client: 64  local train loss: 0.6550\n",
      "global round: 152  client: 31  local train loss: 0.7828\n",
      "global round: 152  client: 34  local train loss: 0.7064\n",
      "global round: 152  client: 06  local train loss: 0.6152\n",
      "global round: 152  client: 49  local train loss: 0.7037\n",
      "global round: 152  client: 55  local train loss: 0.6077\n",
      "global round: 152  client: 88  local train loss: 0.6106\n",
      "global round: 152  client: 51  local train loss: 0.8374\n",
      "global round: 152  client: 85  local train loss: 0.6698\n",
      "global round: 152  client: 92  local train loss: 0.6917\n",
      "global round: 152  avg train loss:0.0589  global test loss: 0.4917  global test accu: 0.8922\n",
      "================================================================================================================\n",
      "global round: 153  client: 51  local train loss: 0.8787\n",
      "global round: 153  client: 63  local train loss: 0.6145\n",
      "global round: 153  client: 47  local train loss: 0.6088\n",
      "global round: 153  client: 78  local train loss: 0.7182\n",
      "global round: 153  client: 37  local train loss: 0.6417\n",
      "global round: 153  client: 71  local train loss: 0.6298\n",
      "global round: 153  client: 74  local train loss: 0.6435\n",
      "global round: 153  client: 38  local train loss: 0.6052\n",
      "global round: 153  client: 17  local train loss: 0.8135\n",
      "global round: 153  client: 56  local train loss: 0.6464\n",
      "global round: 153  avg train loss:0.0648  global test loss: 0.4896  global test accu: 0.8923\n",
      "================================================================================================================\n",
      "global round: 154  client: 38  local train loss: 0.6084\n",
      "global round: 154  client: 74  local train loss: 0.6428\n",
      "global round: 154  client: 69  local train loss: 0.7085\n",
      "global round: 154  client: 21  local train loss: 0.5689\n",
      "global round: 154  client: 99  local train loss: 0.6086\n",
      "global round: 154  client: 87  local train loss: 0.6582\n",
      "global round: 154  client: 59  local train loss: 0.6199\n",
      "global round: 154  client: 67  local train loss: 0.6351\n",
      "global round: 154  client: 09  local train loss: 0.6237\n",
      "global round: 154  client: 92  local train loss: 0.6450\n",
      "global round: 154  avg train loss:0.0699  global test loss: 0.4877  global test accu: 0.8924\n",
      "================================================================================================================\n",
      "global round: 155  client: 95  local train loss: 0.6571\n",
      "global round: 155  client: 33  local train loss: 0.6541\n",
      "global round: 155  client: 31  local train loss: 0.8203\n",
      "global round: 155  client: 98  local train loss: 0.6806\n",
      "global round: 155  client: 19  local train loss: 0.6042\n",
      "global round: 155  client: 93  local train loss: 0.6290\n",
      "global round: 155  client: 52  local train loss: 0.6679\n",
      "global round: 155  client: 36  local train loss: 0.5719\n",
      "global round: 155  client: 96  local train loss: 0.5330\n",
      "global round: 155  client: 59  local train loss: 0.6174\n",
      "global round: 155  avg train loss:0.0522  global test loss: 0.4859  global test accu: 0.8925\n",
      "================================================================================================================\n",
      "global round: 156  client: 25  local train loss: 0.6734\n",
      "global round: 156  client: 38  local train loss: 0.6042\n",
      "global round: 156  client: 00  local train loss: 0.6517\n",
      "global round: 156  client: 96  local train loss: 0.5016\n",
      "global round: 156  client: 64  local train loss: 0.6229\n",
      "global round: 156  client: 90  local train loss: 0.6678\n",
      "global round: 156  client: 62  local train loss: 0.6366\n",
      "global round: 156  client: 17  local train loss: 0.8063\n",
      "global round: 156  client: 70  local train loss: 0.5679\n",
      "global round: 156  client: 87  local train loss: 0.6087\n",
      "global round: 156  avg train loss:0.0680  global test loss: 0.4836  global test accu: 0.8929\n",
      "================================================================================================================\n",
      "global round: 157  client: 67  local train loss: 0.6214\n",
      "global round: 157  client: 52  local train loss: 0.6289\n",
      "global round: 157  client: 21  local train loss: 0.5646\n",
      "global round: 157  client: 10  local train loss: 0.6457\n",
      "global round: 157  client: 92  local train loss: 0.6225\n",
      "global round: 157  client: 59  local train loss: 0.6129\n",
      "global round: 157  client: 32  local train loss: 0.6480\n",
      "global round: 157  client: 17  local train loss: 0.7863\n",
      "global round: 157  client: 62  local train loss: 0.5525\n",
      "global round: 157  client: 30  local train loss: 0.6358\n",
      "global round: 157  avg train loss:0.0396  global test loss: 0.4829  global test accu: 0.8928\n",
      "================================================================================================================\n",
      "global round: 158  client: 10  local train loss: 0.6231\n",
      "global round: 158  client: 87  local train loss: 0.6078\n",
      "global round: 158  client: 00  local train loss: 0.6243\n",
      "global round: 158  client: 60  local train loss: 0.6558\n",
      "global round: 158  client: 55  local train loss: 0.6142\n",
      "global round: 158  client: 59  local train loss: 0.6155\n",
      "global round: 158  client: 66  local train loss: 0.6310\n",
      "global round: 158  client: 71  local train loss: 0.6029\n",
      "global round: 158  client: 98  local train loss: 0.6781\n",
      "global round: 158  client: 24  local train loss: 0.6123\n",
      "global round: 158  avg train loss:0.0719  global test loss: 0.4791  global test accu: 0.8930\n",
      "================================================================================================================\n",
      "global round: 159  client: 90  local train loss: 0.6193\n",
      "global round: 159  client: 25  local train loss: 0.6563\n",
      "global round: 159  client: 46  local train loss: 0.6374\n",
      "global round: 159  client: 72  local train loss: 0.6407\n",
      "global round: 159  client: 54  local train loss: 0.6278\n",
      "global round: 159  client: 35  local train loss: 0.6289\n",
      "global round: 159  client: 80  local train loss: 0.6931\n",
      "global round: 159  client: 41  local train loss: 0.6053\n",
      "global round: 159  client: 18  local train loss: 0.6242\n",
      "global round: 159  client: 01  local train loss: 0.6541\n",
      "global round: 159  avg train loss:0.0829  global test loss: 0.4767  global test accu: 0.8937\n",
      "================================================================================================================\n",
      "global round: 160  client: 66  local train loss: 0.6173\n",
      "global round: 160  client: 48  local train loss: 0.6312\n",
      "global round: 160  client: 67  local train loss: 0.6124\n",
      "global round: 160  client: 72  local train loss: 0.6357\n",
      "global round: 160  client: 90  local train loss: 0.6124\n",
      "global round: 160  client: 80  local train loss: 0.6948\n",
      "global round: 160  client: 34  local train loss: 0.6684\n",
      "global round: 160  client: 08  local train loss: 0.6768\n",
      "global round: 160  client: 27  local train loss: 0.6134\n",
      "global round: 160  client: 26  local train loss: 0.8231\n",
      "global round: 160  avg train loss:0.0677  global test loss: 0.4747  global test accu: 0.8937\n",
      "================================================================================================================\n",
      "global round: 161  client: 25  local train loss: 0.6430\n",
      "global round: 161  client: 57  local train loss: 0.6025\n",
      "global round: 161  client: 70  local train loss: 0.5252\n",
      "global round: 161  client: 94  local train loss: 0.5885\n",
      "global round: 161  client: 46  local train loss: 0.6232\n",
      "global round: 161  client: 42  local train loss: 0.7024\n",
      "global round: 161  client: 33  local train loss: 0.6402\n",
      "global round: 161  client: 95  local train loss: 0.7259\n",
      "global round: 161  client: 38  local train loss: 0.5897\n",
      "global round: 161  client: 00  local train loss: 0.6104\n",
      "global round: 161  avg train loss:0.0420  global test loss: 0.4732  global test accu: 0.8940\n",
      "================================================================================================================\n",
      "global round: 162  client: 49  local train loss: 0.5631\n",
      "global round: 162  client: 47  local train loss: 0.5834\n",
      "global round: 162  client: 10  local train loss: 0.6188\n",
      "global round: 162  client: 80  local train loss: 0.6866\n",
      "global round: 162  client: 54  local train loss: 0.5900\n",
      "global round: 162  client: 03  local train loss: 0.6621\n",
      "global round: 162  client: 59  local train loss: 0.6190\n",
      "global round: 162  client: 02  local train loss: 0.6251\n",
      "global round: 162  client: 13  local train loss: 0.7302\n",
      "global round: 162  client: 21  local train loss: 0.5521\n",
      "global round: 162  avg train loss:0.0266  global test loss: 0.4733  global test accu: 0.8941\n",
      "================================================================================================================\n",
      "global round: 163  client: 03  local train loss: 0.5947\n",
      "global round: 163  client: 05  local train loss: 0.7146\n",
      "global round: 163  client: 17  local train loss: 0.7887\n",
      "global round: 163  client: 46  local train loss: 0.6179\n",
      "global round: 163  client: 95  local train loss: 0.6741\n",
      "global round: 163  client: 30  local train loss: 0.5908\n",
      "global round: 163  client: 74  local train loss: 0.6335\n",
      "global round: 163  client: 52  local train loss: 0.6239\n",
      "global round: 163  client: 83  local train loss: 0.6307\n",
      "global round: 163  client: 27  local train loss: 0.5773\n",
      "global round: 163  avg train loss:0.0530  global test loss: 0.4714  global test accu: 0.8943\n",
      "================================================================================================================\n",
      "global round: 164  client: 48  local train loss: 0.6003\n",
      "global round: 164  client: 47  local train loss: 0.5689\n",
      "global round: 164  client: 90  local train loss: 0.6165\n",
      "global round: 164  client: 06  local train loss: 0.6063\n",
      "global round: 164  client: 20  local train loss: 0.6276\n",
      "global round: 164  client: 95  local train loss: 0.6720\n",
      "global round: 164  client: 94  local train loss: 0.5657\n",
      "global round: 164  client: 69  local train loss: 0.6517\n",
      "global round: 164  client: 00  local train loss: 0.6126\n",
      "global round: 164  client: 23  local train loss: 0.6003\n",
      "global round: 164  avg train loss:0.0520  global test loss: 0.4696  global test accu: 0.8948\n",
      "================================================================================================================\n",
      "global round: 165  client: 90  local train loss: 0.6032\n",
      "global round: 165  client: 69  local train loss: 0.6575\n",
      "global round: 165  client: 50  local train loss: 0.6393\n",
      "global round: 165  client: 88  local train loss: 0.5930\n",
      "global round: 165  client: 30  local train loss: 0.5914\n",
      "global round: 165  client: 14  local train loss: 0.6309\n",
      "global round: 165  client: 00  local train loss: 0.6089\n",
      "global round: 165  client: 66  local train loss: 0.6074\n",
      "global round: 165  client: 38  local train loss: 0.5789\n",
      "global round: 165  client: 35  local train loss: 0.5986\n",
      "global round: 165  avg train loss:0.0758  global test loss: 0.4660  global test accu: 0.8951\n",
      "================================================================================================================\n",
      "global round: 166  client: 71  local train loss: 0.5954\n",
      "global round: 166  client: 12  local train loss: 0.6209\n",
      "global round: 166  client: 26  local train loss: 0.7642\n",
      "global round: 166  client: 39  local train loss: 0.5747\n",
      "global round: 166  client: 81  local train loss: 0.6051\n",
      "global round: 166  client: 80  local train loss: 0.6874\n",
      "global round: 166  client: 58  local train loss: 0.6377\n",
      "global round: 166  client: 89  local train loss: 0.5830\n",
      "global round: 166  client: 29  local train loss: 0.5459\n",
      "global round: 166  client: 90  local train loss: 0.5979\n",
      "global round: 166  avg train loss:0.0698  global test loss: 0.4639  global test accu: 0.8955\n",
      "================================================================================================================\n",
      "global round: 167  client: 19  local train loss: 0.5820\n",
      "global round: 167  client: 90  local train loss: 0.6005\n",
      "global round: 167  client: 43  local train loss: 0.6777\n",
      "global round: 167  client: 83  local train loss: 0.5920\n",
      "global round: 167  client: 65  local train loss: 0.6149\n",
      "global round: 167  client: 00  local train loss: 0.6077\n",
      "global round: 167  client: 94  local train loss: 0.5602\n",
      "global round: 167  client: 89  local train loss: 0.5784\n",
      "global round: 167  client: 27  local train loss: 0.5690\n",
      "global round: 167  client: 08  local train loss: 0.6535\n",
      "global round: 167  avg train loss:0.0532  global test loss: 0.4617  global test accu: 0.8956\n",
      "================================================================================================================\n",
      "global round: 168  client: 24  local train loss: 0.5885\n",
      "global round: 168  client: 69  local train loss: 0.6430\n",
      "global round: 168  client: 65  local train loss: 0.5668\n",
      "global round: 168  client: 19  local train loss: 0.5647\n",
      "global round: 168  client: 57  local train loss: 0.5658\n",
      "global round: 168  client: 49  local train loss: 0.5505\n",
      "global round: 168  client: 90  local train loss: 0.5983\n",
      "global round: 168  client: 88  local train loss: 0.5723\n",
      "global round: 168  client: 10  local train loss: 0.6145\n",
      "global round: 168  client: 06  local train loss: 0.5852\n",
      "global round: 168  avg train loss:0.0823  global test loss: 0.4566  global test accu: 0.8956\n",
      "================================================================================================================\n",
      "global round: 169  client: 23  local train loss: 0.5741\n",
      "global round: 169  client: 88  local train loss: 0.5587\n",
      "global round: 169  client: 98  local train loss: 0.6656\n",
      "global round: 169  client: 08  local train loss: 0.6199\n",
      "global round: 169  client: 44  local train loss: 0.6789\n",
      "global round: 169  client: 76  local train loss: 0.6605\n",
      "global round: 169  client: 91  local train loss: 0.6322\n",
      "global round: 169  client: 78  local train loss: 0.6454\n",
      "global round: 169  client: 06  local train loss: 0.5669\n",
      "global round: 169  client: 82  local train loss: 0.6626\n",
      "global round: 169  avg train loss:0.0734  global test loss: 0.4558  global test accu: 0.8955\n",
      "================================================================================================================\n",
      "global round: 170  client: 20  local train loss: 0.5989\n",
      "global round: 170  client: 67  local train loss: 0.6078\n",
      "global round: 170  client: 52  local train loss: 0.6190\n",
      "global round: 170  client: 57  local train loss: 0.5417\n",
      "global round: 170  client: 61  local train loss: 0.7138\n",
      "global round: 170  client: 79  local train loss: 0.6967\n",
      "global round: 170  client: 95  local train loss: 0.6388\n",
      "global round: 170  client: 94  local train loss: 0.5427\n",
      "global round: 170  client: 31  local train loss: 0.7551\n",
      "global round: 170  client: 14  local train loss: 0.5959\n",
      "global round: 170  avg train loss:0.0350  global test loss: 0.4563  global test accu: 0.8954\n",
      "================================================================================================================\n",
      "global round: 171  client: 96  local train loss: 0.5168\n",
      "global round: 171  client: 91  local train loss: 0.5048\n",
      "global round: 171  client: 85  local train loss: 0.6518\n",
      "global round: 171  client: 99  local train loss: 0.5824\n",
      "global round: 171  client: 18  local train loss: 0.6051\n",
      "global round: 171  client: 84  local train loss: 0.6206\n",
      "global round: 171  client: 56  local train loss: 0.6385\n",
      "global round: 171  client: 51  local train loss: 0.8563\n",
      "global round: 171  client: 34  local train loss: 0.6495\n",
      "global round: 171  client: 36  local train loss: 0.5545\n",
      "global round: 171  avg train loss:0.0430  global test loss: 0.4573  global test accu: 0.8960\n",
      "================================================================================================================\n",
      "global round: 172  client: 49  local train loss: 0.4695\n",
      "global round: 172  client: 25  local train loss: 0.6497\n",
      "global round: 172  client: 76  local train loss: 0.6163\n",
      "global round: 172  client: 48  local train loss: 0.5995\n",
      "global round: 172  client: 97  local train loss: 0.6584\n",
      "global round: 172  client: 40  local train loss: 0.6906\n",
      "global round: 172  client: 66  local train loss: 0.6025\n",
      "global round: 172  client: 89  local train loss: 0.5533\n",
      "global round: 172  client: 53  local train loss: 0.5648\n",
      "global round: 172  client: 01  local train loss: 0.6173\n",
      "global round: 172  avg train loss:0.0460  global test loss: 0.4573  global test accu: 0.8960\n",
      "================================================================================================================\n",
      "global round: 173  client: 03  local train loss: 0.5938\n",
      "global round: 173  client: 38  local train loss: 0.5766\n",
      "global round: 173  client: 06  local train loss: 0.5700\n",
      "global round: 173  client: 51  local train loss: 0.8128\n",
      "global round: 173  client: 02  local train loss: 0.6017\n",
      "global round: 173  client: 93  local train loss: 0.6043\n",
      "global round: 173  client: 11  local train loss: 0.6265\n",
      "global round: 173  client: 83  local train loss: 0.5938\n",
      "global round: 173  client: 04  local train loss: 0.6775\n",
      "global round: 173  client: 58  local train loss: 0.6016\n",
      "global round: 173  avg train loss:0.0494  global test loss: 0.4569  global test accu: 0.8962\n",
      "================================================================================================================\n",
      "global round: 174  client: 93  local train loss: 0.5728\n",
      "global round: 174  client: 77  local train loss: 0.7302\n",
      "global round: 174  client: 00  local train loss: 0.6042\n",
      "global round: 174  client: 92  local train loss: 0.6442\n",
      "global round: 174  client: 35  local train loss: 0.5809\n",
      "global round: 174  client: 36  local train loss: 0.5300\n",
      "global round: 174  client: 70  local train loss: 0.4956\n",
      "global round: 174  client: 62  local train loss: 0.5737\n",
      "global round: 174  client: 27  local train loss: 0.5677\n",
      "global round: 174  client: 94  local train loss: 0.5661\n",
      "global round: 174  avg train loss:0.0432  global test loss: 0.4568  global test accu: 0.8961\n",
      "================================================================================================================\n",
      "global round: 175  client: 41  local train loss: 0.5782\n",
      "global round: 175  client: 36  local train loss: 0.5176\n",
      "global round: 175  client: 57  local train loss: 0.5415\n",
      "global round: 175  client: 32  local train loss: 0.6459\n",
      "global round: 175  client: 00  local train loss: 0.6000\n",
      "global round: 175  client: 07  local train loss: 0.7160\n",
      "global round: 175  client: 73  local train loss: 0.6148\n",
      "global round: 175  client: 29  local train loss: 0.5026\n",
      "global round: 175  client: 13  local train loss: 0.6893\n",
      "global round: 175  client: 58  local train loss: 0.5883\n",
      "global round: 175  avg train loss:0.0545  global test loss: 0.4564  global test accu: 0.8959\n",
      "================================================================================================================\n",
      "global round: 176  client: 44  local train loss: 0.5825\n",
      "global round: 176  client: 63  local train loss: 0.6138\n",
      "global round: 176  client: 33  local train loss: 0.6434\n",
      "global round: 176  client: 97  local train loss: 0.6141\n",
      "global round: 176  client: 70  local train loss: 0.4800\n",
      "global round: 176  client: 34  local train loss: 0.6362\n",
      "global round: 176  client: 72  local train loss: 0.6289\n",
      "global round: 176  client: 55  local train loss: 0.6337\n",
      "global round: 176  client: 01  local train loss: 0.6031\n",
      "global round: 176  client: 47  local train loss: 0.5779\n",
      "global round: 176  avg train loss:0.0547  global test loss: 0.4554  global test accu: 0.8956\n",
      "================================================================================================================\n",
      "global round: 177  client: 87  local train loss: 0.6027\n",
      "global round: 177  client: 33  local train loss: 0.5961\n",
      "global round: 177  client: 52  local train loss: 0.6099\n",
      "global round: 177  client: 92  local train loss: 0.5925\n",
      "global round: 177  client: 79  local train loss: 0.6477\n",
      "global round: 177  client: 82  local train loss: 0.5856\n",
      "global round: 177  client: 46  local train loss: 0.6141\n",
      "global round: 177  client: 08  local train loss: 0.6406\n",
      "global round: 177  client: 62  local train loss: 0.5298\n",
      "global round: 177  client: 51  local train loss: 0.8157\n",
      "global round: 177  avg train loss:0.0647  global test loss: 0.4528  global test accu: 0.8963\n",
      "================================================================================================================\n",
      "global round: 178  client: 96  local train loss: 0.4872\n",
      "global round: 178  client: 21  local train loss: 0.5285\n",
      "global round: 178  client: 90  local train loss: 0.5863\n",
      "global round: 178  client: 53  local train loss: 0.5179\n",
      "global round: 178  client: 41  local train loss: 0.5611\n",
      "global round: 178  client: 51  local train loss: 0.8149\n",
      "global round: 178  client: 74  local train loss: 0.6139\n",
      "global round: 178  client: 89  local train loss: 0.5552\n",
      "global round: 178  client: 85  local train loss: 0.6125\n",
      "global round: 178  client: 86  local train loss: 0.6646\n",
      "global round: 178  avg train loss:0.0536  global test loss: 0.4520  global test accu: 0.8966\n",
      "================================================================================================================\n",
      "global round: 179  client: 18  local train loss: 0.5827\n",
      "global round: 179  client: 22  local train loss: 0.6490\n",
      "global round: 179  client: 64  local train loss: 0.6268\n",
      "global round: 179  client: 16  local train loss: 0.6637\n",
      "global round: 179  client: 60  local train loss: 0.6484\n",
      "global round: 179  client: 23  local train loss: 0.5330\n",
      "global round: 179  client: 31  local train loss: 0.7708\n",
      "global round: 179  client: 43  local train loss: 0.6055\n",
      "global round: 179  client: 41  local train loss: 0.5583\n",
      "global round: 179  client: 78  local train loss: 0.6135\n",
      "global round: 179  avg train loss:0.0487  global test loss: 0.4525  global test accu: 0.8964\n",
      "================================================================================================================\n",
      "global round: 180  client: 36  local train loss: 0.5268\n",
      "global round: 180  client: 50  local train loss: 0.5921\n",
      "global round: 180  client: 18  local train loss: 0.5932\n",
      "global round: 180  client: 80  local train loss: 0.6819\n",
      "global round: 180  client: 31  local train loss: 0.7877\n",
      "global round: 180  client: 99  local train loss: 0.5602\n",
      "global round: 180  client: 27  local train loss: 0.5595\n",
      "global round: 180  client: 46  local train loss: 0.5988\n",
      "global round: 180  client: 82  local train loss: 0.5840\n",
      "global round: 180  client: 59  local train loss: 0.6050\n",
      "global round: 180  avg train loss:0.0526  global test loss: 0.4508  global test accu: 0.8966\n",
      "================================================================================================================\n",
      "global round: 181  client: 36  local train loss: 0.5368\n",
      "global round: 181  client: 53  local train loss: 0.5195\n",
      "global round: 181  client: 63  local train loss: 0.5874\n",
      "global round: 181  client: 59  local train loss: 0.5793\n",
      "global round: 181  client: 05  local train loss: 0.6825\n",
      "global round: 181  client: 11  local train loss: 0.5923\n",
      "global round: 181  client: 99  local train loss: 0.5371\n",
      "global round: 181  client: 51  local train loss: 0.8161\n",
      "global round: 181  client: 42  local train loss: 0.6260\n",
      "global round: 181  client: 82  local train loss: 0.5826\n",
      "global round: 181  avg train loss:0.0385  global test loss: 0.4498  global test accu: 0.8968\n",
      "================================================================================================================\n",
      "global round: 182  client: 15  local train loss: 0.6967\n",
      "global round: 182  client: 85  local train loss: 0.6293\n",
      "global round: 182  client: 12  local train loss: 0.6004\n",
      "global round: 182  client: 65  local train loss: 0.5519\n",
      "global round: 182  client: 59  local train loss: 0.5783\n",
      "global round: 182  client: 36  local train loss: 0.5248\n",
      "global round: 182  client: 66  local train loss: 0.5885\n",
      "global round: 182  client: 47  local train loss: 0.5610\n",
      "global round: 182  client: 64  local train loss: 0.5831\n",
      "global round: 182  client: 57  local train loss: 0.5436\n",
      "global round: 182  avg train loss:0.0454  global test loss: 0.4493  global test accu: 0.8971\n",
      "================================================================================================================\n",
      "global round: 183  client: 27  local train loss: 0.5457\n",
      "global round: 183  client: 12  local train loss: 0.5816\n",
      "global round: 183  client: 45  local train loss: 0.6002\n",
      "global round: 183  client: 10  local train loss: 0.5976\n",
      "global round: 183  client: 36  local train loss: 0.5256\n",
      "global round: 183  client: 19  local train loss: 0.5597\n",
      "global round: 183  client: 04  local train loss: 0.6092\n",
      "global round: 183  client: 00  local train loss: 0.6039\n",
      "global round: 183  client: 24  local train loss: 0.5763\n",
      "global round: 183  client: 13  local train loss: 0.6843\n",
      "global round: 183  avg train loss:0.0478  global test loss: 0.4478  global test accu: 0.8972\n",
      "================================================================================================================\n",
      "global round: 184  client: 21  local train loss: 0.5170\n",
      "global round: 184  client: 87  local train loss: 0.5781\n",
      "global round: 184  client: 06  local train loss: 0.5737\n",
      "global round: 184  client: 25  local train loss: 0.6306\n",
      "global round: 184  client: 50  local train loss: 0.5760\n",
      "global round: 184  client: 63  local train loss: 0.5835\n",
      "global round: 184  client: 70  local train loss: 0.4813\n",
      "global round: 184  client: 49  local train loss: 0.5447\n",
      "global round: 184  client: 68  local train loss: 0.6306\n",
      "global round: 184  client: 91  local train loss: 0.5146\n",
      "global round: 184  avg train loss:0.0580  global test loss: 0.4452  global test accu: 0.8975\n",
      "================================================================================================================\n",
      "global round: 185  client: 88  local train loss: 0.5598\n",
      "global round: 185  client: 02  local train loss: 0.5756\n",
      "global round: 185  client: 43  local train loss: 0.5856\n",
      "global round: 185  client: 80  local train loss: 0.6540\n",
      "global round: 185  client: 68  local train loss: 0.5985\n",
      "global round: 185  client: 59  local train loss: 0.5733\n",
      "global round: 185  client: 42  local train loss: 0.6289\n",
      "global round: 185  client: 61  local train loss: 0.6352\n",
      "global round: 185  client: 89  local train loss: 0.5495\n",
      "global round: 185  client: 06  local train loss: 0.5581\n",
      "global round: 185  avg train loss:0.0533  global test loss: 0.4429  global test accu: 0.8977\n",
      "================================================================================================================\n",
      "global round: 186  client: 40  local train loss: 0.6506\n",
      "global round: 186  client: 49  local train loss: 0.4703\n",
      "global round: 186  client: 10  local train loss: 0.5875\n",
      "global round: 186  client: 75  local train loss: 0.6319\n",
      "global round: 186  client: 71  local train loss: 0.5839\n",
      "global round: 186  client: 94  local train loss: 0.5435\n",
      "global round: 186  client: 60  local train loss: 0.6142\n",
      "global round: 186  client: 57  local train loss: 0.5296\n",
      "global round: 186  client: 65  local train loss: 0.5498\n",
      "global round: 186  client: 24  local train loss: 0.5639\n",
      "global round: 186  avg train loss:0.0438  global test loss: 0.4428  global test accu: 0.8976\n",
      "================================================================================================================\n",
      "global round: 187  client: 48  local train loss: 0.5797\n",
      "global round: 187  client: 75  local train loss: 0.5806\n",
      "global round: 187  client: 73  local train loss: 0.5749\n",
      "global round: 187  client: 18  local train loss: 0.5833\n",
      "global round: 187  client: 64  local train loss: 0.5878\n",
      "global round: 187  client: 62  local train loss: 0.5319\n",
      "global round: 187  client: 00  local train loss: 0.5997\n",
      "global round: 187  client: 76  local train loss: 0.6212\n",
      "global round: 187  client: 37  local train loss: 0.6283\n",
      "global round: 187  client: 51  local train loss: 0.8127\n",
      "global round: 187  avg train loss:0.0654  global test loss: 0.4416  global test accu: 0.8980\n",
      "================================================================================================================\n",
      "global round: 188  client: 02  local train loss: 0.5642\n",
      "global round: 188  client: 40  local train loss: 0.6374\n",
      "global round: 188  client: 74  local train loss: 0.6027\n",
      "global round: 188  client: 20  local train loss: 0.5612\n",
      "global round: 188  client: 82  local train loss: 0.5858\n",
      "global round: 188  client: 21  local train loss: 0.5060\n",
      "global round: 188  client: 73  local train loss: 0.5603\n",
      "global round: 188  client: 09  local train loss: 0.6099\n",
      "global round: 188  client: 24  local train loss: 0.5608\n",
      "global round: 188  client: 07  local train loss: 0.6186\n",
      "global round: 188  avg train loss:0.0622  global test loss: 0.4400  global test accu: 0.8978\n",
      "================================================================================================================\n",
      "global round: 189  client: 22  local train loss: 0.5918\n",
      "global round: 189  client: 27  local train loss: 0.5533\n",
      "global round: 189  client: 06  local train loss: 0.5525\n",
      "global round: 189  client: 65  local train loss: 0.5437\n",
      "global round: 189  client: 64  local train loss: 0.5728\n",
      "global round: 189  client: 62  local train loss: 0.5088\n",
      "global round: 189  client: 97  local train loss: 0.6165\n",
      "global round: 189  client: 81  local train loss: 0.5763\n",
      "global round: 189  client: 57  local train loss: 0.5372\n",
      "global round: 189  client: 76  local train loss: 0.6086\n",
      "global round: 189  avg train loss:0.0694  global test loss: 0.4383  global test accu: 0.8982\n",
      "================================================================================================================\n",
      "global round: 190  client: 76  local train loss: 0.6084\n",
      "global round: 190  client: 19  local train loss: 0.5525\n",
      "global round: 190  client: 28  local train loss: 0.6923\n",
      "global round: 190  client: 38  local train loss: 0.5601\n",
      "global round: 190  client: 36  local train loss: 0.5221\n",
      "global round: 190  client: 15  local train loss: 0.6417\n",
      "global round: 190  client: 98  local train loss: 0.6269\n",
      "global round: 190  client: 89  local train loss: 0.5280\n",
      "global round: 190  client: 11  local train loss: 0.5917\n",
      "global round: 190  client: 01  local train loss: 0.5922\n",
      "global round: 190  avg train loss:0.0537  global test loss: 0.4384  global test accu: 0.8982\n",
      "================================================================================================================\n",
      "global round: 191  client: 54  local train loss: 0.5861\n",
      "global round: 191  client: 84  local train loss: 0.5859\n",
      "global round: 191  client: 22  local train loss: 0.5784\n",
      "global round: 191  client: 68  local train loss: 0.5683\n",
      "global round: 191  client: 98  local train loss: 0.6214\n",
      "global round: 191  client: 45  local train loss: 0.5399\n",
      "global round: 191  client: 74  local train loss: 0.5880\n",
      "global round: 191  client: 43  local train loss: 0.5667\n",
      "global round: 191  client: 90  local train loss: 0.5863\n",
      "global round: 191  client: 25  local train loss: 0.6276\n",
      "global round: 191  avg train loss:0.0618  global test loss: 0.4369  global test accu: 0.8987\n",
      "================================================================================================================\n",
      "global round: 192  client: 33  local train loss: 0.6118\n",
      "global round: 192  client: 83  local train loss: 0.5922\n",
      "global round: 192  client: 25  local train loss: 0.6045\n",
      "global round: 192  client: 31  local train loss: 0.7846\n",
      "global round: 192  client: 36  local train loss: 0.5108\n",
      "global round: 192  client: 51  local train loss: 0.8521\n",
      "global round: 192  client: 97  local train loss: 0.5988\n",
      "global round: 192  client: 88  local train loss: 0.5457\n",
      "global round: 192  client: 17  local train loss: 0.7680\n",
      "global round: 192  client: 50  local train loss: 0.5775\n",
      "global round: 192  avg train loss:0.0448  global test loss: 0.4354  global test accu: 0.8986\n",
      "================================================================================================================\n",
      "global round: 193  client: 60  local train loss: 0.6081\n",
      "global round: 193  client: 89  local train loss: 0.5105\n",
      "global round: 193  client: 70  local train loss: 0.4726\n",
      "global round: 193  client: 16  local train loss: 0.5983\n",
      "global round: 193  client: 27  local train loss: 0.5311\n",
      "global round: 193  client: 45  local train loss: 0.5256\n",
      "global round: 193  client: 61  local train loss: 0.6311\n",
      "global round: 193  client: 63  local train loss: 0.5718\n",
      "global round: 193  client: 19  local train loss: 0.5443\n",
      "global round: 193  client: 39  local train loss: 0.5402\n",
      "global round: 193  avg train loss:0.0493  global test loss: 0.4339  global test accu: 0.8986\n",
      "================================================================================================================\n",
      "global round: 194  client: 83  local train loss: 0.5621\n",
      "global round: 194  client: 87  local train loss: 0.5718\n",
      "global round: 194  client: 05  local train loss: 0.6207\n",
      "global round: 194  client: 04  local train loss: 0.5901\n",
      "global round: 194  client: 01  local train loss: 0.5859\n",
      "global round: 194  client: 68  local train loss: 0.5819\n",
      "global round: 194  client: 63  local train loss: 0.5645\n",
      "global round: 194  client: 15  local train loss: 0.6281\n",
      "global round: 194  client: 46  local train loss: 0.5954\n",
      "global round: 194  client: 56  local train loss: 0.6003\n",
      "global round: 194  avg train loss:0.0738  global test loss: 0.4316  global test accu: 0.8986\n",
      "================================================================================================================\n",
      "global round: 195  client: 43  local train loss: 0.5587\n",
      "global round: 195  client: 37  local train loss: 0.5770\n",
      "global round: 195  client: 26  local train loss: 0.7764\n",
      "global round: 195  client: 04  local train loss: 0.5904\n",
      "global round: 195  client: 21  local train loss: 0.4872\n",
      "global round: 195  client: 79  local train loss: 0.6369\n",
      "global round: 195  client: 09  local train loss: 0.5682\n",
      "global round: 195  client: 19  local train loss: 0.5364\n",
      "global round: 195  client: 32  local train loss: 0.6058\n",
      "global round: 195  client: 70  local train loss: 0.4719\n",
      "global round: 195  avg train loss:0.0436  global test loss: 0.4306  global test accu: 0.8989\n",
      "================================================================================================================\n",
      "global round: 196  client: 51  local train loss: 0.8429\n",
      "global round: 196  client: 06  local train loss: 0.5550\n",
      "global round: 196  client: 62  local train loss: 0.5104\n",
      "global round: 196  client: 26  local train loss: 0.7624\n",
      "global round: 196  client: 22  local train loss: 0.5794\n",
      "global round: 196  client: 34  local train loss: 0.6278\n",
      "global round: 196  client: 93  local train loss: 0.5739\n",
      "global round: 196  client: 03  local train loss: 0.5913\n",
      "global round: 196  client: 29  local train loss: 0.5114\n",
      "global round: 196  client: 56  local train loss: 0.5738\n",
      "global round: 196  avg train loss:0.0517  global test loss: 0.4300  global test accu: 0.8990\n",
      "================================================================================================================\n",
      "global round: 197  client: 77  local train loss: 0.6343\n",
      "global round: 197  client: 54  local train loss: 0.5592\n",
      "global round: 197  client: 21  local train loss: 0.4793\n",
      "global round: 197  client: 81  local train loss: 0.5506\n",
      "global round: 197  client: 75  local train loss: 0.5777\n",
      "global round: 197  client: 64  local train loss: 0.5649\n",
      "global round: 197  client: 23  local train loss: 0.5277\n",
      "global round: 197  client: 38  local train loss: 0.5438\n",
      "global round: 197  client: 39  local train loss: 0.5109\n",
      "global round: 197  client: 16  local train loss: 0.5784\n",
      "global round: 197  avg train loss:0.0486  global test loss: 0.4292  global test accu: 0.8990\n",
      "================================================================================================================\n",
      "global round: 198  client: 85  local train loss: 0.6126\n",
      "global round: 198  client: 68  local train loss: 0.5939\n",
      "global round: 198  client: 64  local train loss: 0.5619\n",
      "global round: 198  client: 36  local train loss: 0.5133\n",
      "global round: 198  client: 28  local train loss: 0.6065\n",
      "global round: 198  client: 30  local train loss: 0.5667\n",
      "global round: 198  client: 84  local train loss: 0.5524\n",
      "global round: 198  client: 11  local train loss: 0.5688\n",
      "global round: 198  client: 31  local train loss: 0.7402\n",
      "global round: 198  client: 10  local train loss: 0.5885\n",
      "global round: 198  avg train loss:0.0443  global test loss: 0.4290  global test accu: 0.8991\n",
      "================================================================================================================\n",
      "global round: 199  client: 14  local train loss: 0.5864\n",
      "global round: 199  client: 57  local train loss: 0.5401\n",
      "global round: 199  client: 98  local train loss: 0.6183\n",
      "global round: 199  client: 46  local train loss: 0.5835\n",
      "global round: 199  client: 74  local train loss: 0.5870\n",
      "global round: 199  client: 64  local train loss: 0.5630\n",
      "global round: 199  client: 26  local train loss: 0.7487\n",
      "global round: 199  client: 43  local train loss: 0.5540\n",
      "global round: 199  client: 49  local train loss: 0.5113\n",
      "global round: 199  client: 50  local train loss: 0.5703\n",
      "global round: 199  avg train loss:0.0503  global test loss: 0.4278  global test accu: 0.8995\n",
      "================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# iid, not client_equal_size\n",
    "histories, client = federated_learning(iid = True,\n",
    "                                       same_init = True,\n",
    "                                       client_equal_size = False,\n",
    "                                       num_global_round = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a755b4-6015-4783-ae14-0285d026221f",
   "metadata": {},
   "source": [
    "### iid, not client_equal_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36a6e65f-c411-4238-9f09-e24efc194a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (16, 4)) \n",
    "\n",
    "num_global_round = len(histories[\"local_train_losses\"])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_global_round + 1), histories[\"local_train_losses\"], label = 'avg local train loss')\n",
    "plt.plot(range(1, num_global_round + 1), histories[\"global_test_losses\"], label = 'global test loss')\n",
    "plt.xlabel('global round')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_global_round + 1), histories[\"global_test_accus\"], label = 'global test accus')\n",
    "plt.xlabel('global round')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cd5aa47-a6d4-4a5d-8fd7-287f03e2837d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5fb03e2c065426b97cee72fc8680159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ga92nam\\AppData\\Local\\Temp\\ipykernel_17828\\4185283577.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(image), torch.tensor(label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global round: 00  client: 40  local train loss: 2.1681\n",
      "global round: 00  client: 11  local train loss: 2.1828\n",
      "global round: 00  client: 58  local train loss: 2.1580\n",
      "global round: 00  client: 38  local train loss: 2.1582\n",
      "global round: 00  client: 96  local train loss: 2.1906\n",
      "global round: 00  client: 79  local train loss: 2.1684\n",
      "global round: 00  client: 36  local train loss: 2.1830\n",
      "global round: 00  client: 80  local train loss: 2.1697\n",
      "global round: 00  client: 92  local train loss: 2.1608\n",
      "global round: 00  client: 76  local train loss: 2.1458\n",
      "global round: 00  avg train loss:0.1971  global test loss: 2.3142  global test accu: 0.0882\n",
      "================================================================================================================\n",
      "global round: 01  client: 86  local train loss: 2.1578\n",
      "global round: 01  client: 75  local train loss: 2.1865\n",
      "global round: 01  client: 39  local train loss: 2.1544\n",
      "global round: 01  client: 23  local train loss: 2.1658\n",
      "global round: 01  client: 30  local train loss: 2.1814\n",
      "global round: 01  client: 92  local train loss: 2.1830\n",
      "global round: 01  client: 79  local train loss: 2.1834\n",
      "global round: 01  client: 71  local train loss: 2.1659\n",
      "global round: 01  client: 54  local train loss: 2.1739\n",
      "global round: 01  client: 45  local train loss: 2.1702\n",
      "global round: 01  avg train loss:0.1975  global test loss: 2.3095  global test accu: 0.0941\n",
      "================================================================================================================\n",
      "global round: 02  client: 92  local train loss: 2.1791\n",
      "global round: 02  client: 31  local train loss: 2.1774\n",
      "global round: 02  client: 19  local train loss: 2.1851\n",
      "global round: 02  client: 06  local train loss: 2.1782\n",
      "global round: 02  client: 34  local train loss: 2.1909\n",
      "global round: 02  client: 03  local train loss: 2.1838\n",
      "global round: 02  client: 20  local train loss: 2.1774\n",
      "global round: 02  client: 80  local train loss: 2.2022\n",
      "global round: 02  client: 07  local train loss: 2.1698\n",
      "global round: 02  client: 75  local train loss: 2.1980\n",
      "global round: 02  avg train loss:0.1986  global test loss: 2.3038  global test accu: 0.1036\n",
      "================================================================================================================\n",
      "global round: 03  client: 00  local train loss: 2.1516\n",
      "global round: 03  client: 83  local train loss: 2.1637\n",
      "global round: 03  client: 71  local train loss: 2.2091\n",
      "global round: 03  client: 99  local train loss: 2.1841\n",
      "global round: 03  client: 80  local train loss: 2.1881\n",
      "global round: 03  client: 30  local train loss: 2.1953\n",
      "global round: 03  client: 90  local train loss: 2.1651\n",
      "global round: 03  client: 86  local train loss: 2.1983\n",
      "global round: 03  client: 38  local train loss: 2.1814\n",
      "global round: 03  client: 72  local train loss: 2.1946\n",
      "global round: 03  avg train loss:0.1985  global test loss: 2.2956  global test accu: 0.1253\n",
      "================================================================================================================\n",
      "global round: 04  client: 92  local train loss: 2.1822\n",
      "global round: 04  client: 06  local train loss: 2.1993\n",
      "global round: 04  client: 69  local train loss: 2.1791\n",
      "global round: 04  client: 26  local train loss: 2.1811\n",
      "global round: 04  client: 62  local train loss: 2.1627\n",
      "global round: 04  client: 53  local train loss: 2.1544\n",
      "global round: 04  client: 56  local train loss: 2.1612\n",
      "global round: 04  client: 81  local train loss: 2.1648\n",
      "global round: 04  client: 65  local train loss: 2.1713\n",
      "global round: 04  client: 34  local train loss: 2.1719\n",
      "global round: 04  avg train loss:0.1975  global test loss: 2.2909  global test accu: 0.1380\n",
      "================================================================================================================\n",
      "global round: 05  client: 61  local train loss: 2.1685\n",
      "global round: 05  client: 76  local train loss: 2.1982\n",
      "global round: 05  client: 40  local train loss: 2.2033\n",
      "global round: 05  client: 98  local train loss: 2.1573\n",
      "global round: 05  client: 87  local train loss: 2.1354\n",
      "global round: 05  client: 33  local train loss: 2.1702\n",
      "global round: 05  client: 53  local train loss: 2.1833\n",
      "global round: 05  client: 01  local train loss: 2.1595\n",
      "global round: 05  client: 94  local train loss: 2.1640\n",
      "global round: 05  client: 48  local train loss: 2.2086\n",
      "global round: 05  avg train loss:0.1977  global test loss: 2.2872  global test accu: 0.1550\n",
      "================================================================================================================\n",
      "global round: 06  client: 31  local train loss: 2.1812\n",
      "global round: 06  client: 23  local train loss: 2.1882\n",
      "global round: 06  client: 19  local train loss: 2.1866\n",
      "global round: 06  client: 47  local train loss: 2.1979\n",
      "global round: 06  client: 68  local train loss: 2.1886\n",
      "global round: 06  client: 41  local train loss: 2.1761\n",
      "global round: 06  client: 73  local train loss: 2.1690\n",
      "global round: 06  client: 52  local train loss: 2.1719\n",
      "global round: 06  client: 48  local train loss: 2.1771\n",
      "global round: 06  client: 70  local train loss: 2.1713\n",
      "global round: 06  avg train loss:0.1983  global test loss: 2.2811  global test accu: 0.1906\n",
      "================================================================================================================\n",
      "global round: 07  client: 54  local train loss: 2.1913\n",
      "global round: 07  client: 63  local train loss: 2.1887\n",
      "global round: 07  client: 83  local train loss: 2.1887\n",
      "global round: 07  client: 67  local train loss: 2.1791\n",
      "global round: 07  client: 32  local train loss: 2.1555\n",
      "global round: 07  client: 15  local train loss: 2.1839\n",
      "global round: 07  client: 80  local train loss: 2.1778\n",
      "global round: 07  client: 60  local train loss: 2.1734\n",
      "global round: 07  client: 62  local train loss: 2.1760\n",
      "global round: 07  client: 87  local train loss: 2.1953\n",
      "global round: 07  avg train loss:0.1983  global test loss: 2.2743  global test accu: 0.2409\n",
      "================================================================================================================\n",
      "global round: 08  client: 16  local train loss: 2.1881\n",
      "global round: 08  client: 01  local train loss: 2.1816\n",
      "global round: 08  client: 76  local train loss: 2.1774\n",
      "global round: 08  client: 41  local train loss: 2.1778\n",
      "global round: 08  client: 65  local train loss: 2.1896\n",
      "global round: 08  client: 11  local train loss: 2.1896\n",
      "global round: 08  client: 15  local train loss: 2.1733\n",
      "global round: 08  client: 38  local train loss: 2.1615\n",
      "global round: 08  client: 68  local train loss: 2.1826\n",
      "global round: 08  client: 22  local train loss: 2.1725\n",
      "global round: 08  avg train loss:0.1981  global test loss: 2.2619  global test accu: 0.3062\n",
      "================================================================================================================\n",
      "global round: 09  client: 11  local train loss: 2.1539\n",
      "global round: 09  client: 18  local train loss: 2.2051\n",
      "global round: 09  client: 45  local train loss: 2.1941\n",
      "global round: 09  client: 27  local train loss: 2.1587\n",
      "global round: 09  client: 15  local train loss: 2.1511\n",
      "global round: 09  client: 64  local train loss: 2.1887\n",
      "global round: 09  client: 67  local train loss: 2.1616\n",
      "global round: 09  client: 98  local train loss: 2.1823\n",
      "global round: 09  client: 02  local train loss: 2.1519\n",
      "global round: 09  client: 94  local train loss: 2.1721\n",
      "global round: 09  avg train loss:0.1974  global test loss: 2.2551  global test accu: 0.3370\n",
      "================================================================================================================\n",
      "global round: 10  client: 00  local train loss: 2.1721\n",
      "global round: 10  client: 04  local train loss: 2.1863\n",
      "global round: 10  client: 96  local train loss: 2.1915\n",
      "global round: 10  client: 99  local train loss: 2.1922\n",
      "global round: 10  client: 52  local train loss: 2.1746\n",
      "global round: 10  client: 51  local train loss: 2.1719\n",
      "global round: 10  client: 31  local train loss: 2.1601\n",
      "global round: 10  client: 69  local train loss: 2.1771\n",
      "global round: 10  client: 38  local train loss: 2.1434\n",
      "global round: 10  client: 21  local train loss: 2.1551\n",
      "global round: 10  avg train loss:0.1975  global test loss: 2.2465  global test accu: 0.3701\n",
      "================================================================================================================\n",
      "global round: 11  client: 71  local train loss: 2.1873\n",
      "global round: 11  client: 43  local train loss: 2.1508\n",
      "global round: 11  client: 35  local train loss: 2.1648\n",
      "global round: 11  client: 08  local train loss: 2.1720\n",
      "global round: 11  client: 60  local train loss: 2.1836\n",
      "global round: 11  client: 93  local train loss: 2.1540\n",
      "global round: 11  client: 15  local train loss: 2.1487\n",
      "global round: 11  client: 96  local train loss: 2.1335\n",
      "global round: 11  client: 63  local train loss: 2.1598\n",
      "global round: 11  client: 02  local train loss: 2.1494\n",
      "global round: 11  avg train loss:0.1964  global test loss: 2.2404  global test accu: 0.4024\n",
      "================================================================================================================\n",
      "global round: 12  client: 74  local train loss: 2.1826\n",
      "global round: 12  client: 23  local train loss: 2.1617\n",
      "global round: 12  client: 05  local train loss: 2.1740\n",
      "global round: 12  client: 25  local train loss: 2.1657\n",
      "global round: 12  client: 89  local train loss: 2.1817\n",
      "global round: 12  client: 58  local train loss: 2.2023\n",
      "global round: 12  client: 15  local train loss: 2.1367\n",
      "global round: 12  client: 66  local train loss: 2.1642\n",
      "global round: 12  client: 61  local train loss: 2.1799\n",
      "global round: 12  client: 75  local train loss: 2.1856\n",
      "global round: 12  avg train loss:0.1976  global test loss: 2.2377  global test accu: 0.4125\n",
      "================================================================================================================\n",
      "global round: 13  client: 99  local train loss: 2.1435\n",
      "global round: 13  client: 60  local train loss: 2.1455\n",
      "global round: 13  client: 80  local train loss: 2.1673\n",
      "global round: 13  client: 88  local train loss: 2.1609\n",
      "global round: 13  client: 82  local train loss: 2.1619\n",
      "global round: 13  client: 13  local train loss: 2.1623\n",
      "global round: 13  client: 65  local train loss: 2.1561\n",
      "global round: 13  client: 05  local train loss: 2.1451\n",
      "global round: 13  client: 45  local train loss: 2.1411\n",
      "global round: 13  client: 66  local train loss: 2.1528\n",
      "global round: 13  avg train loss:0.1958  global test loss: 2.2299  global test accu: 0.4372\n",
      "================================================================================================================\n",
      "global round: 14  client: 35  local train loss: 2.1307\n",
      "global round: 14  client: 36  local train loss: 2.2072\n",
      "global round: 14  client: 01  local train loss: 2.1489\n",
      "global round: 14  client: 78  local train loss: 2.1946\n",
      "global round: 14  client: 15  local train loss: 2.1384\n",
      "global round: 14  client: 46  local train loss: 2.1481\n",
      "global round: 14  client: 26  local train loss: 2.1795\n",
      "global round: 14  client: 61  local train loss: 2.1314\n",
      "global round: 14  client: 29  local train loss: 2.1781\n",
      "global round: 14  client: 16  local train loss: 2.1570\n",
      "global round: 14  avg train loss:0.1965  global test loss: 2.2229  global test accu: 0.4686\n",
      "================================================================================================================\n",
      "global round: 15  client: 44  local train loss: 2.1577\n",
      "global round: 15  client: 43  local train loss: 2.1375\n",
      "global round: 15  client: 78  local train loss: 2.1298\n",
      "global round: 15  client: 74  local train loss: 2.1503\n",
      "global round: 15  client: 34  local train loss: 2.1595\n",
      "global round: 15  client: 02  local train loss: 2.1317\n",
      "global round: 15  client: 57  local train loss: 2.1926\n",
      "global round: 15  client: 23  local train loss: 2.1238\n",
      "global round: 15  client: 12  local train loss: 2.1681\n",
      "global round: 15  client: 47  local train loss: 2.1666\n",
      "global round: 15  avg train loss:0.1956  global test loss: 2.2161  global test accu: 0.4850\n",
      "================================================================================================================\n",
      "global round: 16  client: 21  local train loss: 2.1082\n",
      "global round: 16  client: 75  local train loss: 2.1449\n",
      "global round: 16  client: 83  local train loss: 2.1709\n",
      "global round: 16  client: 78  local train loss: 2.1210\n",
      "global round: 16  client: 60  local train loss: 2.1416\n",
      "global round: 16  client: 32  local train loss: 2.1654\n",
      "global round: 16  client: 29  local train loss: 2.1381\n",
      "global round: 16  client: 45  local train loss: 2.1239\n",
      "global round: 16  client: 41  local train loss: 2.1503\n",
      "global round: 16  client: 12  local train loss: 2.1222\n",
      "global round: 16  avg train loss:0.1944  global test loss: 2.2008  global test accu: 0.5173\n",
      "================================================================================================================\n",
      "global round: 17  client: 33  local train loss: 2.1834\n",
      "global round: 17  client: 66  local train loss: 2.1402\n",
      "global round: 17  client: 65  local train loss: 2.1365\n",
      "global round: 17  client: 32  local train loss: 2.0849\n",
      "global round: 17  client: 58  local train loss: 2.1329\n",
      "global round: 17  client: 19  local train loss: 2.1666\n",
      "global round: 17  client: 21  local train loss: 2.0701\n",
      "global round: 17  client: 06  local train loss: 2.1772\n",
      "global round: 17  client: 17  local train loss: 2.1832\n",
      "global round: 17  client: 59  local train loss: 2.1845\n",
      "global round: 17  avg train loss:0.1951  global test loss: 2.1929  global test accu: 0.5313\n",
      "================================================================================================================\n",
      "global round: 18  client: 50  local train loss: 2.1698\n",
      "global round: 18  client: 42  local train loss: 2.1666\n",
      "global round: 18  client: 00  local train loss: 2.1292\n",
      "global round: 18  client: 58  local train loss: 2.0888\n",
      "global round: 18  client: 43  local train loss: 2.1108\n",
      "global round: 18  client: 46  local train loss: 2.1406\n",
      "global round: 18  client: 87  local train loss: 2.1766\n",
      "global round: 18  client: 56  local train loss: 2.1849\n",
      "global round: 18  client: 33  local train loss: 2.0880\n",
      "global round: 18  client: 15  local train loss: 2.1245\n",
      "global round: 18  avg train loss:0.1944  global test loss: 2.1853  global test accu: 0.5469\n",
      "================================================================================================================\n",
      "global round: 19  client: 59  local train loss: 2.1003\n",
      "global round: 19  client: 96  local train loss: 2.1327\n",
      "global round: 19  client: 37  local train loss: 2.1843\n",
      "global round: 19  client: 46  local train loss: 2.0943\n",
      "global round: 19  client: 92  local train loss: 2.1717\n",
      "global round: 19  client: 83  local train loss: 2.1054\n",
      "global round: 19  client: 57  local train loss: 2.1071\n",
      "global round: 19  client: 18  local train loss: 2.1351\n",
      "global round: 19  client: 10  local train loss: 2.1555\n",
      "global round: 19  client: 19  local train loss: 2.0910\n",
      "global round: 19  avg train loss:0.1934  global test loss: 2.1773  global test accu: 0.5603\n",
      "================================================================================================================\n",
      "global round: 20  client: 51  local train loss: 2.1484\n",
      "global round: 20  client: 91  local train loss: 2.1607\n",
      "global round: 20  client: 64  local train loss: 2.1482\n",
      "global round: 20  client: 02  local train loss: 2.1183\n",
      "global round: 20  client: 61  local train loss: 2.1225\n",
      "global round: 20  client: 05  local train loss: 2.1292\n",
      "global round: 20  client: 21  local train loss: 2.0653\n",
      "global round: 20  client: 07  local train loss: 2.1898\n",
      "global round: 20  client: 87  local train loss: 2.0935\n",
      "global round: 20  client: 24  local train loss: 2.1579\n",
      "global round: 20  avg train loss:0.1939  global test loss: 2.1705  global test accu: 0.5743\n",
      "================================================================================================================\n",
      "global round: 21  client: 30  local train loss: 2.1746\n",
      "global round: 21  client: 85  local train loss: 2.1442\n",
      "global round: 21  client: 42  local train loss: 2.0942\n",
      "global round: 21  client: 21  local train loss: 2.0430\n",
      "global round: 21  client: 13  local train loss: 2.1181\n",
      "global round: 21  client: 52  local train loss: 2.1379\n",
      "global round: 21  client: 40  local train loss: 2.1641\n",
      "global round: 21  client: 92  local train loss: 2.0669\n",
      "global round: 21  client: 20  local train loss: 2.1846\n",
      "global round: 21  client: 33  local train loss: 2.0843\n",
      "global round: 21  avg train loss:0.1928  global test loss: 2.1602  global test accu: 0.5908\n",
      "================================================================================================================\n",
      "global round: 22  client: 97  local train loss: 2.1904\n",
      "global round: 22  client: 11  local train loss: 2.1502\n",
      "global round: 22  client: 52  local train loss: 2.0554\n",
      "global round: 22  client: 88  local train loss: 2.1277\n",
      "global round: 22  client: 31  local train loss: 2.1270\n",
      "global round: 22  client: 80  local train loss: 2.1298\n",
      "global round: 22  client: 69  local train loss: 2.1376\n",
      "global round: 22  client: 37  local train loss: 2.0581\n",
      "global round: 22  client: 61  local train loss: 2.0668\n",
      "global round: 22  client: 05  local train loss: 2.0699\n",
      "global round: 22  avg train loss:0.1919  global test loss: 2.1499  global test accu: 0.6026\n",
      "================================================================================================================\n",
      "global round: 23  client: 92  local train loss: 2.0459\n",
      "global round: 23  client: 31  local train loss: 2.0275\n",
      "global round: 23  client: 24  local train loss: 2.0839\n",
      "global round: 23  client: 45  local train loss: 2.0923\n",
      "global round: 23  client: 10  local train loss: 2.0647\n",
      "global round: 23  client: 35  local train loss: 2.1126\n",
      "global round: 23  client: 36  local train loss: 2.1341\n",
      "global round: 23  client: 19  local train loss: 2.0739\n",
      "global round: 23  client: 06  local train loss: 2.0961\n",
      "global round: 23  client: 32  local train loss: 2.0770\n",
      "global round: 23  avg train loss:0.1892  global test loss: 2.1349  global test accu: 0.6186\n",
      "================================================================================================================\n",
      "global round: 24  client: 48  local train loss: 2.1784\n",
      "global round: 24  client: 17  local train loss: 2.0905\n",
      "global round: 24  client: 73  local train loss: 2.1796\n",
      "global round: 24  client: 19  local train loss: 2.0278\n",
      "global round: 24  client: 40  local train loss: 2.0448\n",
      "global round: 24  client: 87  local train loss: 2.0785\n",
      "global round: 24  client: 36  local train loss: 2.0469\n",
      "global round: 24  client: 34  local train loss: 2.1101\n",
      "global round: 24  client: 03  local train loss: 2.2011\n",
      "global round: 24  client: 45  local train loss: 2.0223\n",
      "global round: 24  avg train loss:0.1907  global test loss: 2.1216  global test accu: 0.6282\n",
      "================================================================================================================\n",
      "global round: 25  client: 72  local train loss: 2.1676\n",
      "global round: 25  client: 89  local train loss: 2.1353\n",
      "global round: 25  client: 13  local train loss: 2.0413\n",
      "global round: 25  client: 50  local train loss: 2.0968\n",
      "global round: 25  client: 51  local train loss: 2.0692\n",
      "global round: 25  client: 44  local train loss: 2.1250\n",
      "global round: 25  client: 55  local train loss: 2.1878\n",
      "global round: 25  client: 95  local train loss: 2.1681\n",
      "global round: 25  client: 74  local train loss: 2.1274\n",
      "global round: 25  client: 46  local train loss: 2.0833\n",
      "global round: 25  avg train loss:0.1927  global test loss: 2.1184  global test accu: 0.6330\n",
      "================================================================================================================\n",
      "global round: 26  client: 78  local train loss: 2.1019\n",
      "global round: 26  client: 24  local train loss: 2.0351\n",
      "global round: 26  client: 70  local train loss: 2.1741\n",
      "global round: 26  client: 60  local train loss: 2.1091\n",
      "global round: 26  client: 15  local train loss: 2.0848\n",
      "global round: 26  client: 31  local train loss: 2.0123\n",
      "global round: 26  client: 05  local train loss: 2.0480\n",
      "global round: 26  client: 28  local train loss: 2.1701\n",
      "global round: 26  client: 47  local train loss: 2.1154\n",
      "global round: 26  client: 33  local train loss: 2.0533\n",
      "global round: 26  avg train loss:0.1900  global test loss: 2.1095  global test accu: 0.6390\n",
      "================================================================================================================\n",
      "global round: 27  client: 21  local train loss: 2.0292\n",
      "global round: 27  client: 77  local train loss: 2.1778\n",
      "global round: 27  client: 72  local train loss: 2.0040\n",
      "global round: 27  client: 29  local train loss: 2.1138\n",
      "global round: 27  client: 85  local train loss: 2.0421\n",
      "global round: 27  client: 09  local train loss: 2.1590\n",
      "global round: 27  client: 30  local train loss: 2.0524\n",
      "global round: 27  client: 11  local train loss: 2.0503\n",
      "global round: 27  client: 22  local train loss: 2.1502\n",
      "global round: 27  client: 59  local train loss: 2.0820\n",
      "global round: 27  avg train loss:0.1896  global test loss: 2.1049  global test accu: 0.6405\n",
      "================================================================================================================\n",
      "global round: 28  client: 09  local train loss: 2.0107\n",
      "global round: 28  client: 38  local train loss: 2.1255\n",
      "global round: 28  client: 48  local train loss: 2.0260\n",
      "global round: 28  client: 18  local train loss: 2.0611\n",
      "global round: 28  client: 54  local train loss: 2.1546\n",
      "global round: 28  client: 41  local train loss: 2.1017\n",
      "global round: 28  client: 64  local train loss: 2.0635\n",
      "global round: 28  client: 62  local train loss: 2.1592\n",
      "global round: 28  client: 76  local train loss: 2.1500\n",
      "global round: 28  client: 72  local train loss: 1.9919\n",
      "global round: 28  avg train loss:0.1895  global test loss: 2.0932  global test accu: 0.6438\n",
      "================================================================================================================\n",
      "global round: 29  client: 32  local train loss: 2.0136\n",
      "global round: 29  client: 31  local train loss: 1.9847\n",
      "global round: 29  client: 04  local train loss: 2.1434\n",
      "global round: 29  client: 82  local train loss: 2.1406\n",
      "global round: 29  client: 42  local train loss: 2.0651\n",
      "global round: 29  client: 76  local train loss: 1.9784\n",
      "global round: 29  client: 70  local train loss: 2.0015\n",
      "global round: 29  client: 36  local train loss: 2.0318\n",
      "global round: 29  client: 91  local train loss: 2.0610\n",
      "global round: 29  client: 22  local train loss: 1.9977\n",
      "global round: 29  avg train loss:0.1856  global test loss: 2.0786  global test accu: 0.6534\n",
      "================================================================================================================\n",
      "global round: 30  client: 09  local train loss: 1.9951\n",
      "global round: 30  client: 22  local train loss: 1.9683\n",
      "global round: 30  client: 46  local train loss: 2.0202\n",
      "global round: 30  client: 54  local train loss: 1.9726\n",
      "global round: 30  client: 05  local train loss: 2.0007\n",
      "global round: 30  client: 74  local train loss: 2.0289\n",
      "global round: 30  client: 68  local train loss: 2.1556\n",
      "global round: 30  client: 23  local train loss: 2.1063\n",
      "global round: 30  client: 16  local train loss: 2.1241\n",
      "global round: 30  client: 63  local train loss: 2.1248\n",
      "global round: 30  avg train loss:0.1863  global test loss: 2.0655  global test accu: 0.6609\n",
      "================================================================================================================\n",
      "global round: 31  client: 25  local train loss: 2.1359\n",
      "global round: 31  client: 71  local train loss: 2.1495\n",
      "global round: 31  client: 65  local train loss: 2.0993\n",
      "global round: 31  client: 58  local train loss: 2.0798\n",
      "global round: 31  client: 17  local train loss: 2.0113\n",
      "global round: 31  client: 61  local train loss: 2.0467\n",
      "global round: 31  client: 32  local train loss: 1.9546\n",
      "global round: 31  client: 98  local train loss: 2.1437\n",
      "global round: 31  client: 76  local train loss: 1.9691\n",
      "global round: 31  client: 03  local train loss: 2.0281\n",
      "global round: 31  avg train loss:0.1874  global test loss: 2.0550  global test accu: 0.6625\n",
      "================================================================================================================\n",
      "global round: 32  client: 70  local train loss: 1.9748\n",
      "global round: 32  client: 33  local train loss: 2.0024\n",
      "global round: 32  client: 17  local train loss: 1.9427\n",
      "global round: 32  client: 38  local train loss: 1.9683\n",
      "global round: 32  client: 05  local train loss: 1.9575\n",
      "global round: 32  client: 55  local train loss: 2.0243\n",
      "global round: 32  client: 74  local train loss: 1.9768\n",
      "global round: 32  client: 59  local train loss: 2.0013\n",
      "global round: 32  client: 68  local train loss: 1.9708\n",
      "global round: 32  client: 64  local train loss: 1.9822\n",
      "global round: 32  avg train loss:0.1800  global test loss: 2.0370  global test accu: 0.6709\n",
      "================================================================================================================\n",
      "global round: 33  client: 05  local train loss: 1.9267\n",
      "global round: 33  client: 95  local train loss: 2.0091\n",
      "global round: 33  client: 45  local train loss: 2.0014\n",
      "global round: 33  client: 84  local train loss: 2.1436\n",
      "global round: 33  client: 11  local train loss: 2.0049\n",
      "global round: 33  client: 93  local train loss: 2.1201\n",
      "global round: 33  client: 90  local train loss: 2.1584\n",
      "global round: 33  client: 63  local train loss: 1.9441\n",
      "global round: 33  client: 10  local train loss: 2.0098\n",
      "global round: 33  client: 94  local train loss: 2.1308\n",
      "global round: 33  avg train loss:0.1859  global test loss: 2.0311  global test accu: 0.6692\n",
      "================================================================================================================\n",
      "global round: 34  client: 10  local train loss: 1.8987\n",
      "global round: 34  client: 37  local train loss: 2.0246\n",
      "global round: 34  client: 83  local train loss: 2.0820\n",
      "global round: 34  client: 30  local train loss: 1.9951\n",
      "global round: 34  client: 48  local train loss: 2.0020\n",
      "global round: 34  client: 36  local train loss: 1.9922\n",
      "global round: 34  client: 55  local train loss: 1.9361\n",
      "global round: 34  client: 08  local train loss: 2.1402\n",
      "global round: 34  client: 52  local train loss: 2.0443\n",
      "global round: 34  client: 19  local train loss: 2.0132\n",
      "global round: 34  avg train loss:0.1830  global test loss: 2.0186  global test accu: 0.6748\n",
      "================================================================================================================\n",
      "global round: 35  client: 01  local train loss: 2.1209\n",
      "global round: 35  client: 58  local train loss: 1.9343\n",
      "global round: 35  client: 60  local train loss: 2.0143\n",
      "global round: 35  client: 11  local train loss: 1.9263\n",
      "global round: 35  client: 82  local train loss: 1.9798\n",
      "global round: 35  client: 37  local train loss: 1.8806\n",
      "global round: 35  client: 90  local train loss: 1.8801\n",
      "global round: 35  client: 35  local train loss: 2.0231\n",
      "global round: 35  client: 64  local train loss: 1.9276\n",
      "global round: 35  client: 41  local train loss: 1.9858\n",
      "global round: 35  avg train loss:0.1788  global test loss: 2.0031  global test accu: 0.6797\n",
      "================================================================================================================\n",
      "global round: 36  client: 21  local train loss: 1.9651\n",
      "global round: 36  client: 48  local train loss: 1.9237\n",
      "global round: 36  client: 84  local train loss: 1.8950\n",
      "global round: 36  client: 12  local train loss: 2.1001\n",
      "global round: 36  client: 15  local train loss: 2.0007\n",
      "global round: 36  client: 36  local train loss: 1.9317\n",
      "global round: 36  client: 90  local train loss: 1.8594\n",
      "global round: 36  client: 38  local train loss: 1.9109\n",
      "global round: 36  client: 30  local train loss: 1.9024\n",
      "global round: 36  client: 65  local train loss: 1.9563\n",
      "global round: 36  avg train loss:0.1768  global test loss: 1.9868  global test accu: 0.6827\n",
      "================================================================================================================\n",
      "global round: 37  client: 37  local train loss: 1.8728\n",
      "global round: 37  client: 18  local train loss: 1.9730\n",
      "global round: 37  client: 49  local train loss: 2.1717\n",
      "global round: 37  client: 09  local train loss: 1.9704\n",
      "global round: 37  client: 79  local train loss: 2.1831\n",
      "global round: 37  client: 91  local train loss: 1.9596\n",
      "global round: 37  client: 11  local train loss: 1.9034\n",
      "global round: 37  client: 15  local train loss: 1.8708\n",
      "global round: 37  client: 52  local train loss: 1.9013\n",
      "global round: 37  client: 93  local train loss: 1.8927\n",
      "global round: 37  avg train loss:0.1791  global test loss: 1.9782  global test accu: 0.6856\n",
      "================================================================================================================\n",
      "global round: 38  client: 59  local train loss: 1.9323\n",
      "global round: 38  client: 14  local train loss: 2.1932\n",
      "global round: 38  client: 63  local train loss: 1.9138\n",
      "global round: 38  client: 61  local train loss: 1.9425\n",
      "global round: 38  client: 20  local train loss: 2.0518\n",
      "global round: 38  client: 96  local train loss: 2.0754\n",
      "global round: 38  client: 38  local train loss: 1.8579\n",
      "global round: 38  client: 68  local train loss: 1.9507\n",
      "global round: 38  client: 08  local train loss: 1.9019\n",
      "global round: 38  client: 92  local train loss: 2.0175\n",
      "global round: 38  avg train loss:0.1803  global test loss: 1.9713  global test accu: 0.6884\n",
      "================================================================================================================\n",
      "global round: 39  client: 46  local train loss: 1.9627\n",
      "global round: 39  client: 62  local train loss: 1.9730\n",
      "global round: 39  client: 41  local train loss: 1.8947\n",
      "global round: 39  client: 22  local train loss: 1.9558\n",
      "global round: 39  client: 08  local train loss: 1.8626\n",
      "global round: 39  client: 93  local train loss: 1.8418\n",
      "global round: 39  client: 75  local train loss: 2.1114\n",
      "global round: 39  client: 50  local train loss: 2.0225\n",
      "global round: 39  client: 79  local train loss: 1.8585\n",
      "global round: 39  client: 16  local train loss: 1.9618\n",
      "global round: 39  avg train loss:0.1768  global test loss: 1.9572  global test accu: 0.6949\n",
      "================================================================================================================\n",
      "global round: 40  client: 32  local train loss: 1.9292\n",
      "global round: 40  client: 43  local train loss: 2.0752\n",
      "global round: 40  client: 53  local train loss: 2.1689\n",
      "global round: 40  client: 54  local train loss: 1.9443\n",
      "global round: 40  client: 95  local train loss: 1.9119\n",
      "global round: 40  client: 92  local train loss: 1.8401\n",
      "global round: 40  client: 29  local train loss: 2.0210\n",
      "global round: 40  client: 76  local train loss: 1.9412\n",
      "global round: 40  client: 70  local train loss: 1.9322\n",
      "global round: 40  client: 56  local train loss: 2.0803\n",
      "global round: 40  avg train loss:0.1804  global test loss: 1.9486  global test accu: 0.6949\n",
      "================================================================================================================\n",
      "global round: 41  client: 83  local train loss: 1.9101\n",
      "global round: 41  client: 97  local train loss: 2.0449\n",
      "global round: 41  client: 63  local train loss: 1.8527\n",
      "global round: 41  client: 79  local train loss: 1.8554\n",
      "global round: 41  client: 91  local train loss: 1.8528\n",
      "global round: 41  client: 47  local train loss: 1.9928\n",
      "global round: 41  client: 41  local train loss: 1.8524\n",
      "global round: 41  client: 04  local train loss: 1.9693\n",
      "global round: 41  client: 21  local train loss: 1.8348\n",
      "global round: 41  client: 55  local train loss: 1.9169\n",
      "global round: 41  avg train loss:0.1735  global test loss: 1.9330  global test accu: 0.6990\n",
      "================================================================================================================\n",
      "global round: 42  client: 90  local train loss: 1.8445\n",
      "global round: 42  client: 49  local train loss: 1.8705\n",
      "global round: 42  client: 71  local train loss: 1.9581\n",
      "global round: 42  client: 14  local train loss: 1.8853\n",
      "global round: 42  client: 33  local train loss: 1.9196\n",
      "global round: 42  client: 09  local train loss: 1.8771\n",
      "global round: 42  client: 72  local train loss: 1.9818\n",
      "global round: 42  client: 45  local train loss: 1.9084\n",
      "global round: 42  client: 56  local train loss: 1.8356\n",
      "global round: 42  client: 22  local train loss: 1.8469\n",
      "global round: 42  avg train loss:0.1721  global test loss: 1.9171  global test accu: 0.7011\n",
      "================================================================================================================\n",
      "global round: 43  client: 31  local train loss: 1.9520\n",
      "global round: 43  client: 83  local train loss: 1.8251\n",
      "global round: 43  client: 40  local train loss: 2.0034\n",
      "global round: 43  client: 82  local train loss: 1.9129\n",
      "global round: 43  client: 12  local train loss: 1.8793\n",
      "global round: 43  client: 42  local train loss: 1.9779\n",
      "global round: 43  client: 90  local train loss: 1.7747\n",
      "global round: 43  client: 60  local train loss: 1.9051\n",
      "global round: 43  client: 09  local train loss: 1.8213\n",
      "global round: 43  client: 55  local train loss: 1.8348\n",
      "global round: 43  avg train loss:0.1717  global test loss: 1.9021  global test accu: 0.7045\n",
      "================================================================================================================\n",
      "global round: 44  client: 64  local train loss: 1.8892\n",
      "global round: 44  client: 11  local train loss: 1.8784\n",
      "global round: 44  client: 96  local train loss: 1.8520\n",
      "global round: 44  client: 26  local train loss: 2.1249\n",
      "global round: 44  client: 30  local train loss: 1.8744\n",
      "global round: 44  client: 16  local train loss: 1.8486\n",
      "global round: 44  client: 79  local train loss: 1.8342\n",
      "global round: 44  client: 15  local train loss: 1.8660\n",
      "global round: 44  client: 86  local train loss: 2.1761\n",
      "global round: 44  client: 98  local train loss: 1.9422\n",
      "global round: 44  avg train loss:0.1753  global test loss: 1.8918  global test accu: 0.7067\n",
      "================================================================================================================\n",
      "global round: 45  client: 81  local train loss: 2.1880\n",
      "global round: 45  client: 34  local train loss: 2.0058\n",
      "global round: 45  client: 76  local train loss: 1.8337\n",
      "global round: 45  client: 26  local train loss: 1.7893\n",
      "global round: 45  client: 16  local train loss: 1.7870\n",
      "global round: 45  client: 32  local train loss: 1.8098\n",
      "global round: 45  client: 53  local train loss: 1.8145\n",
      "global round: 45  client: 01  local train loss: 1.8818\n",
      "global round: 45  client: 47  local train loss: 1.8074\n",
      "global round: 45  client: 00  local train loss: 2.0712\n",
      "global round: 45  avg train loss:0.1726  global test loss: 1.8802  global test accu: 0.7087\n",
      "================================================================================================================\n",
      "global round: 46  client: 67  local train loss: 2.1335\n",
      "global round: 46  client: 35  local train loss: 1.8754\n",
      "global round: 46  client: 74  local train loss: 1.9511\n",
      "global round: 46  client: 70  local train loss: 1.8442\n",
      "global round: 46  client: 83  local train loss: 1.7944\n",
      "global round: 46  client: 85  local train loss: 1.9749\n",
      "global round: 46  client: 28  local train loss: 2.0146\n",
      "global round: 46  client: 24  local train loss: 2.0104\n",
      "global round: 46  client: 54  local train loss: 1.8247\n",
      "global round: 46  client: 04  local train loss: 1.8248\n",
      "global round: 46  avg train loss:0.1750  global test loss: 1.8723  global test accu: 0.7098\n",
      "================================================================================================================\n",
      "global round: 47  client: 31  local train loss: 1.7633\n",
      "global round: 47  client: 58  local train loss: 1.8851\n",
      "global round: 47  client: 41  local train loss: 1.8277\n",
      "global round: 47  client: 38  local train loss: 1.8450\n",
      "global round: 47  client: 20  local train loss: 1.8621\n",
      "global round: 47  client: 11  local train loss: 1.7932\n",
      "global round: 47  client: 19  local train loss: 1.9108\n",
      "global round: 47  client: 56  local train loss: 1.8121\n",
      "global round: 47  client: 92  local train loss: 1.8139\n",
      "global round: 47  client: 45  local train loss: 1.7950\n",
      "global round: 47  avg train loss:0.1664  global test loss: 1.8559  global test accu: 0.7132\n",
      "================================================================================================================\n",
      "global round: 48  client: 26  local train loss: 1.7842\n",
      "global round: 48  client: 47  local train loss: 1.7649\n",
      "global round: 48  client: 59  local train loss: 1.8654\n",
      "global round: 48  client: 33  local train loss: 1.8044\n",
      "global round: 48  client: 97  local train loss: 1.8174\n",
      "global round: 48  client: 55  local train loss: 1.8056\n",
      "global round: 48  client: 49  local train loss: 1.8055\n",
      "global round: 48  client: 09  local train loss: 1.8094\n",
      "global round: 48  client: 68  local train loss: 1.8836\n",
      "global round: 48  client: 10  local train loss: 1.8880\n",
      "global round: 48  avg train loss:0.1657  global test loss: 1.8395  global test accu: 0.7157\n",
      "================================================================================================================\n",
      "global round: 49  client: 70  local train loss: 1.7727\n",
      "global round: 49  client: 78  local train loss: 2.0074\n",
      "global round: 49  client: 38  local train loss: 1.7406\n",
      "global round: 49  client: 96  local train loss: 1.7812\n",
      "global round: 49  client: 65  local train loss: 1.8896\n",
      "global round: 49  client: 66  local train loss: 2.1030\n",
      "global round: 49  client: 58  local train loss: 1.7343\n",
      "global round: 49  client: 55  local train loss: 1.7470\n",
      "global round: 49  client: 52  local train loss: 1.8600\n",
      "global round: 49  client: 04  local train loss: 1.7650\n",
      "global round: 49  avg train loss:0.1673  global test loss: 1.8265  global test accu: 0.7189\n",
      "================================================================================================================\n",
      "global round: 50  client: 00  local train loss: 1.7532\n",
      "global round: 50  client: 40  local train loss: 1.7667\n",
      "global round: 50  client: 12  local train loss: 1.8023\n",
      "global round: 50  client: 71  local train loss: 1.8270\n",
      "global round: 50  client: 65  local train loss: 1.7409\n",
      "global round: 50  client: 10  local train loss: 1.7025\n",
      "global round: 50  client: 38  local train loss: 1.7063\n",
      "global round: 50  client: 44  local train loss: 2.0144\n",
      "global round: 50  client: 17  local train loss: 1.9269\n",
      "global round: 50  client: 02  local train loss: 2.0680\n",
      "global round: 50  avg train loss:0.1664  global test loss: 1.8142  global test accu: 0.7202\n",
      "================================================================================================================\n",
      "global round: 51  client: 00  local train loss: 1.6992\n",
      "global round: 51  client: 43  local train loss: 1.8170\n",
      "global round: 51  client: 86  local train loss: 1.7741\n",
      "global round: 51  client: 24  local train loss: 1.7741\n",
      "global round: 51  client: 63  local train loss: 1.8192\n",
      "global round: 51  client: 74  local train loss: 1.7911\n",
      "global round: 51  client: 48  local train loss: 1.8951\n",
      "global round: 51  client: 76  local train loss: 1.7625\n",
      "global round: 51  client: 10  local train loss: 1.6865\n",
      "global round: 51  client: 45  local train loss: 1.7410\n",
      "global round: 51  avg train loss:0.1615  global test loss: 1.7971  global test accu: 0.7227\n",
      "================================================================================================================\n",
      "global round: 52  client: 44  local train loss: 1.7044\n",
      "global round: 52  client: 02  local train loss: 1.6922\n",
      "global round: 52  client: 38  local train loss: 1.6937\n",
      "global round: 52  client: 56  local train loss: 1.7520\n",
      "global round: 52  client: 39  local train loss: 2.1897\n",
      "global round: 52  client: 67  local train loss: 1.7341\n",
      "global round: 52  client: 72  local train loss: 1.8014\n",
      "global round: 52  client: 43  local train loss: 1.6736\n",
      "global round: 52  client: 65  local train loss: 1.7331\n",
      "global round: 52  client: 88  local train loss: 2.0345\n",
      "global round: 52  avg train loss:0.1637  global test loss: 1.7838  global test accu: 0.7245\n",
      "================================================================================================================\n",
      "global round: 53  client: 85  local train loss: 1.7272\n",
      "global round: 53  client: 15  local train loss: 1.7840\n",
      "global round: 53  client: 26  local train loss: 1.7554\n",
      "global round: 53  client: 14  local train loss: 1.8379\n",
      "global round: 53  client: 99  local train loss: 2.1346\n",
      "global round: 53  client: 76  local train loss: 1.6885\n",
      "global round: 53  client: 17  local train loss: 1.7163\n",
      "global round: 53  client: 69  local train loss: 2.0476\n",
      "global round: 53  client: 51  local train loss: 2.0109\n",
      "global round: 53  client: 97  local train loss: 1.7361\n",
      "global round: 53  avg train loss:0.1676  global test loss: 1.7765  global test accu: 0.7248\n",
      "================================================================================================================\n",
      "global round: 54  client: 95  local train loss: 1.8303\n",
      "global round: 54  client: 91  local train loss: 1.8048\n",
      "global round: 54  client: 04  local train loss: 1.7304\n",
      "global round: 54  client: 18  local train loss: 1.8544\n",
      "global round: 54  client: 39  local train loss: 1.6626\n",
      "global round: 54  client: 14  local train loss: 1.7060\n",
      "global round: 54  client: 21  local train loss: 1.7798\n",
      "global round: 54  client: 73  local train loss: 2.0078\n",
      "global round: 54  client: 79  local train loss: 1.7938\n",
      "global round: 54  client: 27  local train loss: 2.1377\n",
      "global round: 54  avg train loss:0.1664  global test loss: 1.7689  global test accu: 0.7261\n",
      "================================================================================================================\n",
      "global round: 55  client: 60  local train loss: 1.8085\n",
      "global round: 55  client: 08  local train loss: 1.8474\n",
      "global round: 55  client: 43  local train loss: 1.6646\n",
      "global round: 55  client: 67  local train loss: 1.6674\n",
      "global round: 55  client: 35  local train loss: 1.7484\n",
      "global round: 55  client: 09  local train loss: 1.7468\n",
      "global round: 55  client: 71  local train loss: 1.7402\n",
      "global round: 55  client: 30  local train loss: 1.7812\n",
      "global round: 55  client: 58  local train loss: 1.7181\n",
      "global round: 55  client: 25  local train loss: 1.9315\n",
      "global round: 55  avg train loss:0.1605  global test loss: 1.7549  global test accu: 0.7281\n",
      "================================================================================================================\n",
      "global round: 56  client: 32  local train loss: 1.7436\n",
      "global round: 56  client: 59  local train loss: 1.7473\n",
      "global round: 56  client: 91  local train loss: 1.6521\n",
      "global round: 56  client: 01  local train loss: 1.7605\n",
      "global round: 56  client: 63  local train loss: 1.6824\n",
      "global round: 56  client: 50  local train loss: 1.8546\n",
      "global round: 56  client: 81  local train loss: 1.7675\n",
      "global round: 56  client: 45  local train loss: 1.6819\n",
      "global round: 56  client: 20  local train loss: 1.7560\n",
      "global round: 56  client: 22  local train loss: 1.8059\n",
      "global round: 56  avg train loss:0.1587  global test loss: 1.7403  global test accu: 0.7309\n",
      "================================================================================================================\n",
      "global round: 57  client: 23  local train loss: 1.9408\n",
      "global round: 57  client: 29  local train loss: 1.8693\n",
      "global round: 57  client: 32  local train loss: 1.6199\n",
      "global round: 57  client: 15  local train loss: 1.6771\n",
      "global round: 57  client: 83  local train loss: 1.7703\n",
      "global round: 57  client: 05  local train loss: 1.9199\n",
      "global round: 57  client: 96  local train loss: 1.7169\n",
      "global round: 57  client: 72  local train loss: 1.6768\n",
      "global round: 57  client: 81  local train loss: 1.6503\n",
      "global round: 57  client: 68  local train loss: 1.7678\n",
      "global round: 57  avg train loss:0.1601  global test loss: 1.7280  global test accu: 0.7328\n",
      "================================================================================================================\n",
      "global round: 58  client: 44  local train loss: 1.6895\n",
      "global round: 58  client: 48  local train loss: 1.7157\n",
      "global round: 58  client: 30  local train loss: 1.6540\n",
      "global round: 58  client: 47  local train loss: 1.7282\n",
      "global round: 58  client: 00  local train loss: 1.6861\n",
      "global round: 58  client: 46  local train loss: 1.8567\n",
      "global round: 58  client: 03  local train loss: 1.9591\n",
      "global round: 58  client: 62  local train loss: 1.8303\n",
      "global round: 58  client: 50  local train loss: 1.6542\n",
      "global round: 58  client: 45  local train loss: 1.6318\n",
      "global round: 58  avg train loss:0.1582  global test loss: 1.7150  global test accu: 0.7359\n",
      "================================================================================================================\n",
      "global round: 59  client: 89  local train loss: 1.9988\n",
      "global round: 59  client: 18  local train loss: 1.6573\n",
      "global round: 59  client: 68  local train loss: 1.6664\n",
      "global round: 59  client: 29  local train loss: 1.6731\n",
      "global round: 59  client: 11  local train loss: 1.7618\n",
      "global round: 59  client: 71  local train loss: 1.6882\n",
      "global round: 59  client: 54  local train loss: 1.7492\n",
      "global round: 59  client: 07  local train loss: 2.0720\n",
      "global round: 59  client: 52  local train loss: 1.7164\n",
      "global round: 59  client: 59  local train loss: 1.6502\n",
      "global round: 59  avg train loss:0.1603  global test loss: 1.7049  global test accu: 0.7385\n",
      "================================================================================================================\n",
      "global round: 60  client: 75  local train loss: 1.8661\n",
      "global round: 60  client: 71  local train loss: 1.6486\n",
      "global round: 60  client: 57  local train loss: 2.0622\n",
      "global round: 60  client: 03  local train loss: 1.6442\n",
      "global round: 60  client: 86  local train loss: 1.7003\n",
      "global round: 60  client: 94  local train loss: 1.8941\n",
      "global round: 60  client: 91  local train loss: 1.6218\n",
      "global round: 60  client: 11  local train loss: 1.6217\n",
      "global round: 60  client: 70  local train loss: 1.7309\n",
      "global round: 60  client: 74  local train loss: 1.7341\n",
      "global round: 60  avg train loss:0.1593  global test loss: 1.6946  global test accu: 0.7421\n",
      "================================================================================================================\n",
      "global round: 61  client: 82  local train loss: 1.8087\n",
      "global round: 61  client: 19  local train loss: 1.7447\n",
      "global round: 61  client: 08  local train loss: 1.6510\n",
      "global round: 61  client: 24  local train loss: 1.7075\n",
      "global round: 61  client: 15  local train loss: 1.6377\n",
      "global round: 61  client: 73  local train loss: 1.6566\n",
      "global round: 61  client: 34  local train loss: 1.7587\n",
      "global round: 61  client: 81  local train loss: 1.6418\n",
      "global round: 61  client: 69  local train loss: 1.6686\n",
      "global round: 61  client: 94  local train loss: 1.5629\n",
      "global round: 61  avg train loss:0.1531  global test loss: 1.6791  global test accu: 0.7449\n",
      "================================================================================================================\n",
      "global round: 62  client: 64  local train loss: 1.7826\n",
      "global round: 62  client: 95  local train loss: 1.6689\n",
      "global round: 62  client: 18  local train loss: 1.5985\n",
      "global round: 62  client: 06  local train loss: 2.0362\n",
      "global round: 62  client: 43  local train loss: 1.6433\n",
      "global round: 62  client: 85  local train loss: 1.6400\n",
      "global round: 62  client: 57  local train loss: 1.5800\n",
      "global round: 62  client: 13  local train loss: 1.9994\n",
      "global round: 62  client: 99  local train loss: 1.6629\n",
      "global round: 62  client: 98  local train loss: 1.7816\n",
      "global round: 62  avg train loss:0.1581  global test loss: 1.6715  global test accu: 0.7435\n",
      "================================================================================================================\n",
      "global round: 63  client: 84  local train loss: 1.8479\n",
      "global round: 63  client: 11  local train loss: 1.6156\n",
      "global round: 63  client: 97  local train loss: 1.6820\n",
      "global round: 63  client: 28  local train loss: 1.7776\n",
      "global round: 63  client: 45  local train loss: 1.6145\n",
      "global round: 63  client: 98  local train loss: 1.5878\n",
      "global round: 63  client: 47  local train loss: 1.6123\n",
      "global round: 63  client: 64  local train loss: 1.5801\n",
      "global round: 63  client: 69  local train loss: 1.5939\n",
      "global round: 63  client: 57  local train loss: 1.5705\n",
      "global round: 63  avg train loss:0.1498  global test loss: 1.6550  global test accu: 0.7460\n",
      "================================================================================================================\n",
      "global round: 64  client: 44  local train loss: 1.6241\n",
      "global round: 64  client: 49  local train loss: 1.7448\n",
      "global round: 64  client: 18  local train loss: 1.5722\n",
      "global round: 64  client: 43  local train loss: 1.5640\n",
      "global round: 64  client: 40  local train loss: 1.6953\n",
      "global round: 64  client: 76  local train loss: 1.6709\n",
      "global round: 64  client: 26  local train loss: 1.6999\n",
      "global round: 64  client: 66  local train loss: 1.7358\n",
      "global round: 64  client: 09  local train loss: 1.6687\n",
      "global round: 64  client: 77  local train loss: 2.0161\n",
      "global round: 64  avg train loss:0.1545  global test loss: 1.6448  global test accu: 0.7477\n",
      "================================================================================================================\n",
      "global round: 65  client: 70  local train loss: 1.6195\n",
      "global round: 65  client: 34  local train loss: 1.5787\n",
      "global round: 65  client: 14  local train loss: 1.7029\n",
      "global round: 65  client: 88  local train loss: 1.6577\n",
      "global round: 65  client: 37  local train loss: 1.8450\n",
      "global round: 65  client: 74  local train loss: 1.6366\n",
      "global round: 65  client: 82  local train loss: 1.6037\n",
      "global round: 65  client: 40  local train loss: 1.5445\n",
      "global round: 65  client: 92  local train loss: 1.7260\n",
      "global round: 65  client: 21  local train loss: 1.6189\n",
      "global round: 65  avg train loss:0.1503  global test loss: 1.6313  global test accu: 0.7489\n",
      "================================================================================================================\n",
      "global round: 66  client: 81  local train loss: 1.6035\n",
      "global round: 66  client: 19  local train loss: 1.5916\n",
      "global round: 66  client: 03  local train loss: 1.6340\n",
      "global round: 66  client: 63  local train loss: 1.6351\n",
      "global round: 66  client: 04  local train loss: 1.6790\n",
      "global round: 66  client: 56  local train loss: 1.6830\n",
      "global round: 66  client: 45  local train loss: 1.5638\n",
      "global round: 66  client: 95  local train loss: 1.5775\n",
      "global round: 66  client: 91  local train loss: 1.5829\n",
      "global round: 66  client: 24  local train loss: 1.6113\n",
      "global round: 66  avg train loss:0.1469  global test loss: 1.6153  global test accu: 0.7510\n",
      "================================================================================================================\n",
      "global round: 67  client: 94  local train loss: 1.5637\n",
      "global round: 67  client: 53  local train loss: 1.7542\n",
      "global round: 67  client: 54  local train loss: 1.6061\n",
      "global round: 67  client: 85  local train loss: 1.5493\n",
      "global round: 67  client: 49  local train loss: 1.5668\n",
      "global round: 67  client: 62  local train loss: 1.5951\n",
      "global round: 67  client: 90  local train loss: 1.7627\n",
      "global round: 67  client: 37  local train loss: 1.5204\n",
      "global round: 67  client: 68  local train loss: 1.6490\n",
      "global round: 67  client: 39  local train loss: 1.6675\n",
      "global round: 67  avg train loss:0.1476  global test loss: 1.6027  global test accu: 0.7513\n",
      "================================================================================================================\n",
      "global round: 68  client: 64  local train loss: 1.5649\n",
      "global round: 68  client: 38  local train loss: 1.6706\n",
      "global round: 68  client: 50  local train loss: 1.6328\n",
      "global round: 68  client: 33  local train loss: 1.7272\n",
      "global round: 68  client: 55  local train loss: 1.7384\n",
      "global round: 68  client: 87  local train loss: 2.0265\n",
      "global round: 68  client: 96  local train loss: 1.6308\n",
      "global round: 68  client: 22  local train loss: 1.6391\n",
      "global round: 68  client: 75  local train loss: 1.6312\n",
      "global round: 68  client: 81  local train loss: 1.5474\n",
      "global round: 68  avg train loss:0.1528  global test loss: 1.5951  global test accu: 0.7527\n",
      "================================================================================================================\n",
      "global round: 69  client: 69  local train loss: 1.5770\n",
      "global round: 69  client: 42  local train loss: 1.7981\n",
      "global round: 69  client: 44  local train loss: 1.5646\n",
      "global round: 69  client: 09  local train loss: 1.5719\n",
      "global round: 69  client: 64  local train loss: 1.5217\n",
      "global round: 69  client: 81  local train loss: 1.5282\n",
      "global round: 69  client: 65  local train loss: 1.7046\n",
      "global round: 69  client: 98  local train loss: 1.5751\n",
      "global round: 69  client: 94  local train loss: 1.4948\n",
      "global round: 69  client: 32  local train loss: 1.6096\n",
      "global round: 69  avg train loss:0.1450  global test loss: 1.5804  global test accu: 0.7552\n",
      "================================================================================================================\n",
      "global round: 70  client: 33  local train loss: 1.5054\n",
      "global round: 70  client: 67  local train loss: 1.6416\n",
      "global round: 70  client: 69  local train loss: 1.5145\n",
      "global round: 70  client: 65  local train loss: 1.5364\n",
      "global round: 70  client: 10  local train loss: 1.6701\n",
      "global round: 70  client: 73  local train loss: 1.5938\n",
      "global round: 70  client: 53  local train loss: 1.5129\n",
      "global round: 70  client: 84  local train loss: 1.5241\n",
      "global round: 70  client: 78  local train loss: 1.7206\n",
      "global round: 70  client: 00  local train loss: 1.6103\n",
      "global round: 70  avg train loss:0.1439  global test loss: 1.5664  global test accu: 0.7561\n",
      "================================================================================================================\n",
      "global round: 71  client: 70  local train loss: 1.5624\n",
      "global round: 71  client: 58  local train loss: 1.6456\n",
      "global round: 71  client: 64  local train loss: 1.5128\n",
      "global round: 71  client: 05  local train loss: 1.6290\n",
      "global round: 71  client: 72  local train loss: 1.6260\n",
      "global round: 71  client: 76  local train loss: 1.5534\n",
      "global round: 71  client: 32  local train loss: 1.4775\n",
      "global round: 71  client: 30  local train loss: 1.6242\n",
      "global round: 71  client: 18  local train loss: 1.5542\n",
      "global round: 71  client: 11  local train loss: 1.5777\n",
      "global round: 71  avg train loss:0.1433  global test loss: 1.5528  global test accu: 0.7579\n",
      "================================================================================================================\n",
      "global round: 72  client: 27  local train loss: 1.6301\n",
      "global round: 72  client: 87  local train loss: 1.5108\n",
      "global round: 72  client: 93  local train loss: 1.8211\n",
      "global round: 72  client: 68  local train loss: 1.5585\n",
      "global round: 72  client: 60  local train loss: 1.6717\n",
      "global round: 72  client: 46  local train loss: 1.6349\n",
      "global round: 72  client: 98  local train loss: 1.5202\n",
      "global round: 72  client: 58  local train loss: 1.4749\n",
      "global round: 72  client: 59  local train loss: 1.6238\n",
      "global round: 72  client: 66  local train loss: 1.5845\n",
      "global round: 72  avg train loss:0.1457  global test loss: 1.5418  global test accu: 0.7590\n",
      "================================================================================================================\n",
      "global round: 73  client: 82  local train loss: 1.5712\n",
      "global round: 73  client: 16  local train loss: 1.7793\n",
      "global round: 73  client: 72  local train loss: 1.4854\n",
      "global round: 73  client: 29  local train loss: 1.6593\n",
      "global round: 73  client: 40  local train loss: 1.5366\n",
      "global round: 73  client: 30  local train loss: 1.4802\n",
      "global round: 73  client: 18  local train loss: 1.4787\n",
      "global round: 73  client: 20  local train loss: 1.6608\n",
      "global round: 73  client: 86  local train loss: 1.6058\n",
      "global round: 73  client: 42  local train loss: 1.5105\n",
      "global round: 73  avg train loss:0.1433  global test loss: 1.5295  global test accu: 0.7613\n",
      "================================================================================================================\n",
      "global round: 74  client: 72  local train loss: 1.4653\n",
      "global round: 74  client: 52  local train loss: 1.6085\n",
      "global round: 74  client: 39  local train loss: 1.5211\n",
      "global round: 74  client: 02  local train loss: 1.6775\n",
      "global round: 74  client: 48  local train loss: 1.6463\n",
      "global round: 74  client: 56  local train loss: 1.5433\n",
      "global round: 74  client: 61  local train loss: 1.8614\n",
      "global round: 74  client: 51  local train loss: 1.6677\n",
      "global round: 74  client: 01  local train loss: 1.6297\n",
      "global round: 74  client: 91  local train loss: 1.5146\n",
      "global round: 74  avg train loss:0.1467  global test loss: 1.5224  global test accu: 0.7625\n",
      "================================================================================================================\n",
      "global round: 75  client: 05  local train loss: 1.4862\n",
      "global round: 75  client: 76  local train loss: 1.4763\n",
      "global round: 75  client: 86  local train loss: 1.4598\n",
      "global round: 75  client: 51  local train loss: 1.4467\n",
      "global round: 75  client: 01  local train loss: 1.4486\n",
      "global round: 75  client: 42  local train loss: 1.4704\n",
      "global round: 75  client: 90  local train loss: 1.4835\n",
      "global round: 75  client: 44  local train loss: 1.5103\n",
      "global round: 75  client: 63  local train loss: 1.5155\n",
      "global round: 75  client: 87  local train loss: 1.4824\n",
      "global round: 75  avg train loss:0.1344  global test loss: 1.5033  global test accu: 0.7652\n",
      "================================================================================================================\n",
      "global round: 76  client: 11  local train loss: 1.4962\n",
      "global round: 76  client: 86  local train loss: 1.4431\n",
      "global round: 76  client: 28  local train loss: 1.5922\n",
      "global round: 76  client: 01  local train loss: 1.4409\n",
      "global round: 76  client: 29  local train loss: 1.5195\n",
      "global round: 76  client: 75  local train loss: 1.5533\n",
      "global round: 76  client: 79  local train loss: 1.6790\n",
      "global round: 76  client: 41  local train loss: 1.7586\n",
      "global round: 76  client: 97  local train loss: 1.5756\n",
      "global round: 76  client: 44  local train loss: 1.4481\n",
      "global round: 76  avg train loss:0.1410  global test loss: 1.4915  global test accu: 0.7678\n",
      "================================================================================================================\n",
      "global round: 77  client: 06  local train loss: 1.5871\n",
      "global round: 77  client: 54  local train loss: 1.5107\n",
      "global round: 77  client: 44  local train loss: 1.4445\n",
      "global round: 77  client: 07  local train loss: 1.6179\n",
      "global round: 77  client: 72  local train loss: 1.4632\n",
      "global round: 77  client: 53  local train loss: 1.4882\n",
      "global round: 77  client: 95  local train loss: 1.5298\n",
      "global round: 77  client: 35  local train loss: 1.6362\n",
      "global round: 77  client: 56  local train loss: 1.4678\n",
      "global round: 77  client: 17  local train loss: 1.6805\n",
      "global round: 77  avg train loss:0.1402  global test loss: 1.4811  global test accu: 0.7690\n",
      "================================================================================================================\n",
      "global round: 78  client: 57  local train loss: 1.5645\n",
      "global round: 78  client: 34  local train loss: 1.5466\n",
      "global round: 78  client: 25  local train loss: 1.6396\n",
      "global round: 78  client: 32  local train loss: 1.4612\n",
      "global round: 78  client: 68  local train loss: 1.5102\n",
      "global round: 78  client: 26  local train loss: 1.5839\n",
      "global round: 78  client: 97  local train loss: 1.4438\n",
      "global round: 78  client: 38  local train loss: 1.4987\n",
      "global round: 78  client: 82  local train loss: 1.4881\n",
      "global round: 78  client: 33  local train loss: 1.4938\n",
      "global round: 78  avg train loss:0.1385  global test loss: 1.4696  global test accu: 0.7699\n",
      "================================================================================================================\n",
      "global round: 79  client: 25  local train loss: 1.4028\n",
      "global round: 79  client: 19  local train loss: 1.5426\n",
      "global round: 79  client: 91  local train loss: 1.4350\n",
      "global round: 79  client: 74  local train loss: 1.5867\n",
      "global round: 79  client: 72  local train loss: 1.4234\n",
      "global round: 79  client: 22  local train loss: 1.5096\n",
      "global round: 79  client: 79  local train loss: 1.4439\n",
      "global round: 79  client: 18  local train loss: 1.4594\n",
      "global round: 79  client: 80  local train loss: 2.0424\n",
      "global round: 79  client: 46  local train loss: 1.4868\n",
      "global round: 79  avg train loss:0.1394  global test loss: 1.4604  global test accu: 0.7734\n",
      "================================================================================================================\n",
      "global round: 80  client: 21  local train loss: 1.4993\n",
      "global round: 80  client: 92  local train loss: 1.5155\n",
      "global round: 80  client: 19  local train loss: 1.4086\n",
      "global round: 80  client: 98  local train loss: 1.4833\n",
      "global round: 80  client: 18  local train loss: 1.4013\n",
      "global round: 80  client: 91  local train loss: 1.3879\n",
      "global round: 80  client: 27  local train loss: 1.4303\n",
      "global round: 80  client: 93  local train loss: 1.4472\n",
      "global round: 80  client: 55  local train loss: 1.5419\n",
      "global round: 80  client: 04  local train loss: 1.5446\n",
      "global round: 80  avg train loss:0.1333  global test loss: 1.4469  global test accu: 0.7750\n",
      "================================================================================================================\n",
      "global round: 81  client: 86  local train loss: 1.4402\n",
      "global round: 81  client: 80  local train loss: 1.3752\n",
      "global round: 81  client: 32  local train loss: 1.3965\n",
      "global round: 81  client: 42  local train loss: 1.4491\n",
      "global round: 81  client: 14  local train loss: 1.5882\n",
      "global round: 81  client: 59  local train loss: 1.4961\n",
      "global round: 81  client: 01  local train loss: 1.4295\n",
      "global round: 81  client: 41  local train loss: 1.4466\n",
      "global round: 81  client: 21  local train loss: 1.3505\n",
      "global round: 81  client: 92  local train loss: 1.3537\n",
      "global round: 81  avg train loss:0.1302  global test loss: 1.4304  global test accu: 0.7770\n",
      "================================================================================================================\n",
      "global round: 82  client: 96  local train loss: 1.5173\n",
      "global round: 82  client: 99  local train loss: 1.5864\n",
      "global round: 82  client: 27  local train loss: 1.3631\n",
      "global round: 82  client: 40  local train loss: 1.4518\n",
      "global round: 82  client: 61  local train loss: 1.4556\n",
      "global round: 82  client: 28  local train loss: 1.4562\n",
      "global round: 82  client: 19  local train loss: 1.4008\n",
      "global round: 82  client: 63  local train loss: 1.4304\n",
      "global round: 82  client: 98  local train loss: 1.4052\n",
      "global round: 82  client: 65  local train loss: 1.5239\n",
      "global round: 82  avg train loss:0.1326  global test loss: 1.4177  global test accu: 0.7783\n",
      "================================================================================================================\n",
      "global round: 83  client: 92  local train loss: 1.3444\n",
      "global round: 83  client: 50  local train loss: 1.5231\n",
      "global round: 83  client: 33  local train loss: 1.4086\n",
      "global round: 83  client: 63  local train loss: 1.3565\n",
      "global round: 83  client: 40  local train loss: 1.3565\n",
      "global round: 83  client: 13  local train loss: 1.5568\n",
      "global round: 83  client: 16  local train loss: 1.4600\n",
      "global round: 83  client: 96  local train loss: 1.3802\n",
      "global round: 83  client: 87  local train loss: 1.4605\n",
      "global round: 83  client: 10  local train loss: 1.4608\n",
      "global round: 83  avg train loss:0.1301  global test loss: 1.4041  global test accu: 0.7790\n",
      "================================================================================================================\n",
      "global round: 84  client: 22  local train loss: 1.4064\n",
      "global round: 84  client: 92  local train loss: 1.3217\n",
      "global round: 84  client: 26  local train loss: 1.4438\n",
      "global round: 84  client: 20  local train loss: 1.4824\n",
      "global round: 84  client: 95  local train loss: 1.4256\n",
      "global round: 84  client: 73  local train loss: 1.4956\n",
      "global round: 84  client: 74  local train loss: 1.4565\n",
      "global round: 84  client: 96  local train loss: 1.3690\n",
      "global round: 84  client: 34  local train loss: 1.4131\n",
      "global round: 84  client: 93  local train loss: 1.3697\n",
      "global round: 84  avg train loss:0.1289  global test loss: 1.3899  global test accu: 0.7807\n",
      "================================================================================================================\n",
      "global round: 85  client: 49  local train loss: 1.5351\n",
      "global round: 85  client: 25  local train loss: 1.3997\n",
      "global round: 85  client: 82  local train loss: 1.4411\n",
      "global round: 85  client: 02  local train loss: 1.4428\n",
      "global round: 85  client: 41  local train loss: 1.3978\n",
      "global round: 85  client: 70  local train loss: 1.5006\n",
      "global round: 85  client: 33  local train loss: 1.3566\n",
      "global round: 85  client: 85  local train loss: 1.4889\n",
      "global round: 85  client: 88  local train loss: 1.5311\n",
      "global round: 85  client: 53  local train loss: 1.4111\n",
      "global round: 85  avg train loss:0.1319  global test loss: 1.3806  global test accu: 0.7822\n",
      "================================================================================================================\n",
      "global round: 86  client: 06  local train loss: 1.4335\n",
      "global round: 86  client: 49  local train loss: 1.3587\n",
      "global round: 86  client: 37  local train loss: 1.5065\n",
      "global round: 86  client: 73  local train loss: 1.3562\n",
      "global round: 86  client: 85  local train loss: 1.3068\n",
      "global round: 86  client: 76  local train loss: 1.4397\n",
      "global round: 86  client: 91  local train loss: 1.3671\n",
      "global round: 86  client: 32  local train loss: 1.3689\n",
      "global round: 86  client: 36  local train loss: 1.9004\n",
      "global round: 86  client: 93  local train loss: 1.3296\n",
      "global round: 86  avg train loss:0.1306  global test loss: 1.3713  global test accu: 0.7820\n",
      "================================================================================================================\n",
      "global round: 87  client: 16  local train loss: 1.3652\n",
      "global round: 87  client: 22  local train loss: 1.3493\n",
      "global round: 87  client: 74  local train loss: 1.4030\n",
      "global round: 87  client: 25  local train loss: 1.3415\n",
      "global round: 87  client: 10  local train loss: 1.3239\n",
      "global round: 87  client: 49  local train loss: 1.3491\n",
      "global round: 87  client: 98  local train loss: 1.3808\n",
      "global round: 87  client: 73  local train loss: 1.3496\n",
      "global round: 87  client: 24  local train loss: 1.5564\n",
      "global round: 87  client: 55  local train loss: 1.4147\n",
      "global round: 87  avg train loss:0.1258  global test loss: 1.3565  global test accu: 0.7842\n",
      "================================================================================================================\n",
      "global round: 88  client: 55  local train loss: 1.3434\n",
      "global round: 88  client: 45  local train loss: 1.5302\n",
      "global round: 88  client: 48  local train loss: 1.4914\n",
      "global round: 88  client: 11  local train loss: 1.4537\n",
      "global round: 88  client: 21  local train loss: 1.3368\n",
      "global round: 88  client: 79  local train loss: 1.4197\n",
      "global round: 88  client: 47  local train loss: 1.5653\n",
      "global round: 88  client: 37  local train loss: 1.3107\n",
      "global round: 88  client: 85  local train loss: 1.3118\n",
      "global round: 88  client: 70  local train loss: 1.3625\n",
      "global round: 88  avg train loss:0.1284  global test loss: 1.3465  global test accu: 0.7861\n",
      "================================================================================================================\n",
      "global round: 89  client: 90  local train loss: 1.3907\n",
      "global round: 89  client: 83  local train loss: 1.6359\n",
      "global round: 89  client: 98  local train loss: 1.3400\n",
      "global round: 89  client: 55  local train loss: 1.3432\n",
      "global round: 89  client: 37  local train loss: 1.2927\n",
      "global round: 89  client: 75  local train loss: 1.4688\n",
      "global round: 89  client: 24  local train loss: 1.3523\n",
      "global round: 89  client: 94  local train loss: 1.4787\n",
      "global round: 89  client: 88  local train loss: 1.3230\n",
      "global round: 89  client: 30  local train loss: 1.4646\n",
      "global round: 89  avg train loss:0.1281  global test loss: 1.3372  global test accu: 0.7865\n",
      "================================================================================================================\n",
      "global round: 90  client: 89  local train loss: 1.5863\n",
      "global round: 90  client: 04  local train loss: 1.3962\n",
      "global round: 90  client: 54  local train loss: 1.4184\n",
      "global round: 90  client: 71  local train loss: 1.6439\n",
      "global round: 90  client: 29  local train loss: 1.4922\n",
      "global round: 90  client: 14  local train loss: 1.4239\n",
      "global round: 90  client: 55  local train loss: 1.3335\n",
      "global round: 90  client: 22  local train loss: 1.3176\n",
      "global round: 90  client: 45  local train loss: 1.3045\n",
      "global round: 90  client: 38  local train loss: 1.3953\n",
      "global round: 90  avg train loss:0.1301  global test loss: 1.3299  global test accu: 0.7889\n",
      "================================================================================================================\n",
      "global round: 91  client: 39  local train loss: 1.4499\n",
      "global round: 91  client: 67  local train loss: 1.4818\n",
      "global round: 91  client: 28  local train loss: 1.4022\n",
      "global round: 91  client: 69  local train loss: 1.5040\n",
      "global round: 91  client: 18  local train loss: 1.3928\n",
      "global round: 91  client: 21  local train loss: 1.2720\n",
      "global round: 91  client: 03  local train loss: 1.5686\n",
      "global round: 91  client: 33  local train loss: 1.3446\n",
      "global round: 91  client: 61  local train loss: 1.3727\n",
      "global round: 91  client: 20  local train loss: 1.3694\n",
      "global round: 91  avg train loss:0.1287  global test loss: 1.3227  global test accu: 0.7897\n",
      "================================================================================================================\n",
      "global round: 92  client: 38  local train loss: 1.2812\n",
      "global round: 92  client: 14  local train loss: 1.3448\n",
      "global round: 92  client: 75  local train loss: 1.3561\n",
      "global round: 92  client: 04  local train loss: 1.3073\n",
      "global round: 92  client: 48  local train loss: 1.3523\n",
      "global round: 92  client: 18  local train loss: 1.2964\n",
      "global round: 92  client: 05  local train loss: 1.4466\n",
      "global round: 92  client: 08  local train loss: 1.5848\n",
      "global round: 92  client: 16  local train loss: 1.3254\n",
      "global round: 92  client: 55  local train loss: 1.3262\n",
      "global round: 92  avg train loss:0.1238  global test loss: 1.3097  global test accu: 0.7929\n",
      "================================================================================================================\n",
      "global round: 93  client: 86  local train loss: 1.3873\n",
      "global round: 93  client: 26  local train loss: 1.3869\n",
      "global round: 93  client: 89  local train loss: 1.2856\n",
      "global round: 93  client: 06  local train loss: 1.3555\n",
      "global round: 93  client: 47  local train loss: 1.3027\n",
      "global round: 93  client: 38  local train loss: 1.2698\n",
      "global round: 93  client: 60  local train loss: 1.5044\n",
      "global round: 93  client: 83  local train loss: 1.3143\n",
      "global round: 93  client: 02  local train loss: 1.3326\n",
      "global round: 93  client: 17  local train loss: 1.4429\n",
      "global round: 93  avg train loss:0.1235  global test loss: 1.2981  global test accu: 0.7952\n",
      "================================================================================================================\n",
      "global round: 94  client: 85  local train loss: 1.2917\n",
      "global round: 94  client: 68  local train loss: 1.4540\n",
      "global round: 94  client: 57  local train loss: 1.4067\n",
      "global round: 94  client: 29  local train loss: 1.3680\n",
      "global round: 94  client: 37  local train loss: 1.2900\n",
      "global round: 94  client: 88  local train loss: 1.2862\n",
      "global round: 94  client: 64  local train loss: 1.4884\n",
      "global round: 94  client: 14  local train loss: 1.3354\n",
      "global round: 94  client: 81  local train loss: 1.5208\n",
      "global round: 94  client: 16  local train loss: 1.2905\n",
      "global round: 94  avg train loss:0.1248  global test loss: 1.2892  global test accu: 0.7961\n",
      "================================================================================================================\n",
      "global round: 95  client: 60  local train loss: 1.3059\n",
      "global round: 95  client: 62  local train loss: 1.5006\n",
      "global round: 95  client: 34  local train loss: 1.3440\n",
      "global round: 95  client: 78  local train loss: 1.4986\n",
      "global round: 95  client: 41  local train loss: 1.3631\n",
      "global round: 95  client: 84  local train loss: 1.4517\n",
      "global round: 95  client: 69  local train loss: 1.3061\n",
      "global round: 95  client: 86  local train loss: 1.2864\n",
      "global round: 95  client: 42  local train loss: 1.3936\n",
      "global round: 95  client: 57  local train loss: 1.2622\n",
      "global round: 95  avg train loss:0.1247  global test loss: 1.2814  global test accu: 0.7971\n",
      "================================================================================================================\n",
      "global round: 96  client: 53  local train loss: 1.3285\n",
      "global round: 96  client: 11  local train loss: 1.3218\n",
      "global round: 96  client: 39  local train loss: 1.2855\n",
      "global round: 96  client: 70  local train loss: 1.3327\n",
      "global round: 96  client: 23  local train loss: 1.6002\n",
      "global round: 96  client: 94  local train loss: 1.2747\n",
      "global round: 96  client: 86  local train loss: 1.2709\n",
      "global round: 96  client: 31  local train loss: 1.7201\n",
      "global round: 96  client: 75  local train loss: 1.3311\n",
      "global round: 96  client: 79  local train loss: 1.3374\n",
      "global round: 96  avg train loss:0.1255  global test loss: 1.2752  global test accu: 0.7985\n",
      "================================================================================================================\n",
      "global round: 97  client: 04  local train loss: 1.2963\n",
      "global round: 97  client: 38  local train loss: 1.2567\n",
      "global round: 97  client: 43  local train loss: 1.5500\n",
      "global round: 97  client: 35  local train loss: 1.4039\n",
      "global round: 97  client: 52  local train loss: 1.4571\n",
      "global round: 97  client: 33  local train loss: 1.2859\n",
      "global round: 97  client: 21  local train loss: 1.2539\n",
      "global round: 97  client: 63  local train loss: 1.3377\n",
      "global round: 97  client: 23  local train loss: 1.2306\n",
      "global round: 97  client: 96  local train loss: 1.3567\n",
      "global round: 97  avg train loss:0.1221  global test loss: 1.2673  global test accu: 0.7979\n",
      "================================================================================================================\n",
      "global round: 98  client: 43  local train loss: 1.2246\n",
      "global round: 98  client: 91  local train loss: 1.3010\n",
      "global round: 98  client: 00  local train loss: 1.4918\n",
      "global round: 98  client: 07  local train loss: 1.4243\n",
      "global round: 98  client: 50  local train loss: 1.3678\n",
      "global round: 98  client: 25  local train loss: 1.3195\n",
      "global round: 98  client: 15  local train loss: 1.5915\n",
      "global round: 98  client: 04  local train loss: 1.2618\n",
      "global round: 98  client: 74  local train loss: 1.3785\n",
      "global round: 98  client: 29  local train loss: 1.3313\n",
      "global round: 98  avg train loss:0.1245  global test loss: 1.2609  global test accu: 0.7991\n",
      "================================================================================================================\n",
      "global round: 99  client: 54  local train loss: 1.2885\n",
      "global round: 99  client: 67  local train loss: 1.2790\n",
      "global round: 99  client: 81  local train loss: 1.2763\n",
      "global round: 99  client: 49  local train loss: 1.3339\n",
      "global round: 99  client: 82  local train loss: 1.3736\n",
      "global round: 99  client: 98  local train loss: 1.3232\n",
      "global round: 99  client: 04  local train loss: 1.2532\n",
      "global round: 99  client: 76  local train loss: 1.3273\n",
      "global round: 99  client: 19  local train loss: 1.3849\n",
      "global round: 99  client: 75  local train loss: 1.3190\n",
      "global round: 99  avg train loss:0.1196  global test loss: 1.2502  global test accu: 0.8009\n",
      "================================================================================================================\n",
      "global round: 100  client: 43  local train loss: 1.2299\n",
      "global round: 100  client: 23  local train loss: 1.2269\n",
      "global round: 100  client: 41  local train loss: 1.2857\n",
      "global round: 100  client: 15  local train loss: 1.2532\n",
      "global round: 100  client: 13  local train loss: 1.3318\n",
      "global round: 100  client: 46  local train loss: 1.4241\n",
      "global round: 100  client: 90  local train loss: 1.2630\n",
      "global round: 100  client: 35  local train loss: 1.2467\n",
      "global round: 100  client: 73  local train loss: 1.3330\n",
      "global round: 100  client: 24  local train loss: 1.3340\n",
      "global round: 100  avg train loss:0.1175  global test loss: 1.2393  global test accu: 0.8018\n",
      "================================================================================================================\n",
      "global round: 101  client: 69  local train loss: 1.2764\n",
      "global round: 101  client: 52  local train loss: 1.2450\n",
      "global round: 101  client: 56  local train loss: 1.4337\n",
      "global round: 101  client: 47  local train loss: 1.2686\n",
      "global round: 101  client: 57  local train loss: 1.2591\n",
      "global round: 101  client: 29  local train loss: 1.3197\n",
      "global round: 101  client: 80  local train loss: 1.3709\n",
      "global round: 101  client: 58  local train loss: 1.4721\n",
      "global round: 101  client: 19  local train loss: 1.2505\n",
      "global round: 101  client: 74  local train loss: 1.3007\n",
      "global round: 101  avg train loss:0.1200  global test loss: 1.2303  global test accu: 0.8036\n",
      "================================================================================================================\n",
      "global round: 102  client: 23  local train loss: 1.2151\n",
      "global round: 102  client: 68  local train loss: 1.3048\n",
      "global round: 102  client: 72  local train loss: 1.4166\n",
      "global round: 102  client: 15  local train loss: 1.2397\n",
      "global round: 102  client: 69  local train loss: 1.2358\n",
      "global round: 102  client: 46  local train loss: 1.2577\n",
      "global round: 102  client: 94  local train loss: 1.2350\n",
      "global round: 102  client: 27  local train loss: 1.3407\n",
      "global round: 102  client: 22  local train loss: 1.3038\n",
      "global round: 102  client: 67  local train loss: 1.2323\n",
      "global round: 102  avg train loss:0.1162  global test loss: 1.2195  global test accu: 0.8051\n",
      "================================================================================================================\n",
      "global round: 103  client: 89  local train loss: 1.2638\n",
      "global round: 103  client: 87  local train loss: 1.3763\n",
      "global round: 103  client: 53  local train loss: 1.2450\n",
      "global round: 103  client: 06  local train loss: 1.2956\n",
      "global round: 103  client: 23  local train loss: 1.1976\n",
      "global round: 103  client: 47  local train loss: 1.2071\n",
      "global round: 103  client: 16  local train loss: 1.2722\n",
      "global round: 103  client: 15  local train loss: 1.2282\n",
      "global round: 103  client: 34  local train loss: 1.2602\n",
      "global round: 103  client: 18  local train loss: 1.2901\n",
      "global round: 103  avg train loss:0.1149  global test loss: 1.2085  global test accu: 0.8062\n",
      "================================================================================================================\n",
      "global round: 104  client: 77  local train loss: 1.5853\n",
      "global round: 104  client: 65  local train loss: 1.4063\n",
      "global round: 104  client: 42  local train loss: 1.2785\n",
      "global round: 104  client: 25  local train loss: 1.2361\n",
      "global round: 104  client: 19  local train loss: 1.2378\n",
      "global round: 104  client: 15  local train loss: 1.2244\n",
      "global round: 104  client: 47  local train loss: 1.1994\n",
      "global round: 104  client: 70  local train loss: 1.2765\n",
      "global round: 104  client: 33  local train loss: 1.2565\n",
      "global round: 104  client: 32  local train loss: 1.3154\n",
      "global round: 104  avg train loss:0.1183  global test loss: 1.2012  global test accu: 0.8081\n",
      "================================================================================================================\n",
      "global round: 105  client: 66  local train loss: 1.5020\n",
      "global round: 105  client: 45  local train loss: 1.2985\n",
      "global round: 105  client: 04  local train loss: 1.2474\n",
      "global round: 105  client: 72  local train loss: 1.2309\n",
      "global round: 105  client: 46  local train loss: 1.2431\n",
      "global round: 105  client: 05  local train loss: 1.2947\n",
      "global round: 105  client: 53  local train loss: 1.2001\n",
      "global round: 105  client: 14  local train loss: 1.3174\n",
      "global round: 105  client: 70  local train loss: 1.2145\n",
      "global round: 105  client: 56  local train loss: 1.2470\n",
      "global round: 105  avg train loss:0.1163  global test loss: 1.1919  global test accu: 0.8099\n",
      "================================================================================================================\n",
      "global round: 106  client: 70  local train loss: 1.2130\n",
      "global round: 106  client: 04  local train loss: 1.1946\n",
      "global round: 106  client: 65  local train loss: 1.2390\n",
      "global round: 106  client: 55  local train loss: 1.3096\n",
      "global round: 106  client: 48  local train loss: 1.3264\n",
      "global round: 106  client: 69  local train loss: 1.2279\n",
      "global round: 106  client: 12  local train loss: 1.7190\n",
      "global round: 106  client: 94  local train loss: 1.1914\n",
      "global round: 106  client: 57  local train loss: 1.2238\n",
      "global round: 106  client: 76  local train loss: 1.2316\n",
      "global round: 106  avg train loss:0.1171  global test loss: 1.1846  global test accu: 0.8108\n",
      "================================================================================================================\n",
      "global round: 107  client: 13  local train loss: 1.2083\n",
      "global round: 107  client: 69  local train loss: 1.1967\n",
      "global round: 107  client: 42  local train loss: 1.2127\n",
      "global round: 107  client: 92  local train loss: 1.3125\n",
      "global round: 107  client: 66  local train loss: 1.2366\n",
      "global round: 107  client: 49  local train loss: 1.2612\n",
      "global round: 107  client: 73  local train loss: 1.2410\n",
      "global round: 107  client: 60  local train loss: 1.2901\n",
      "global round: 107  client: 53  local train loss: 1.1796\n",
      "global round: 107  client: 02  local train loss: 1.2685\n",
      "global round: 107  avg train loss:0.1128  global test loss: 1.1743  global test accu: 0.8114\n",
      "================================================================================================================\n",
      "global round: 108  client: 98  local train loss: 1.2591\n",
      "global round: 108  client: 73  local train loss: 1.1919\n",
      "global round: 108  client: 48  local train loss: 1.2376\n",
      "global round: 108  client: 85  local train loss: 1.2372\n",
      "global round: 108  client: 77  local train loss: 1.2448\n",
      "global round: 108  client: 17  local train loss: 1.3079\n",
      "global round: 108  client: 69  local train loss: 1.1931\n",
      "global round: 108  client: 78  local train loss: 1.2807\n",
      "global round: 108  client: 74  local train loss: 1.2879\n",
      "global round: 108  client: 01  local train loss: 1.3767\n",
      "global round: 108  avg train loss:0.1147  global test loss: 1.1656  global test accu: 0.8118\n",
      "================================================================================================================\n",
      "global round: 109  client: 92  local train loss: 1.1360\n",
      "global round: 109  client: 70  local train loss: 1.2092\n",
      "global round: 109  client: 22  local train loss: 1.2104\n",
      "global round: 109  client: 50  local train loss: 1.2593\n",
      "global round: 109  client: 77  local train loss: 1.2198\n",
      "global round: 109  client: 78  local train loss: 1.1942\n",
      "global round: 109  client: 62  local train loss: 1.2327\n",
      "global round: 109  client: 47  local train loss: 1.1903\n",
      "global round: 109  client: 15  local train loss: 1.2177\n",
      "global round: 109  client: 84  local train loss: 1.2234\n",
      "global round: 109  avg train loss:0.1099  global test loss: 1.1546  global test accu: 0.8134\n",
      "================================================================================================================\n",
      "global round: 110  client: 77  local train loss: 1.2095\n",
      "global round: 110  client: 33  local train loss: 1.1988\n",
      "global round: 110  client: 06  local train loss: 1.2303\n",
      "global round: 110  client: 74  local train loss: 1.2289\n",
      "global round: 110  client: 14  local train loss: 1.2515\n",
      "global round: 110  client: 12  local train loss: 1.1950\n",
      "global round: 110  client: 86  local train loss: 1.2702\n",
      "global round: 110  client: 21  local train loss: 1.2093\n",
      "global round: 110  client: 81  local train loss: 1.2590\n",
      "global round: 110  client: 11  local train loss: 1.2681\n",
      "global round: 110  avg train loss:0.1120  global test loss: 1.1453  global test accu: 0.8154\n",
      "================================================================================================================\n",
      "global round: 111  client: 10  local train loss: 1.2895\n",
      "global round: 111  client: 85  local train loss: 1.1524\n",
      "global round: 111  client: 18  local train loss: 1.2146\n",
      "global round: 111  client: 01  local train loss: 1.1683\n",
      "global round: 111  client: 91  local train loss: 1.2150\n",
      "global round: 111  client: 16  local train loss: 1.2103\n",
      "global round: 111  client: 71  local train loss: 1.3435\n",
      "global round: 111  client: 56  local train loss: 1.2177\n",
      "global round: 111  client: 50  local train loss: 1.1711\n",
      "global round: 111  client: 43  local train loss: 1.2215\n",
      "global round: 111  avg train loss:0.1109  global test loss: 1.1376  global test accu: 0.8151\n",
      "================================================================================================================\n",
      "global round: 112  client: 24  local train loss: 1.2620\n",
      "global round: 112  client: 98  local train loss: 1.1907\n",
      "global round: 112  client: 32  local train loss: 1.1927\n",
      "global round: 112  client: 63  local train loss: 1.2314\n",
      "global round: 112  client: 02  local train loss: 1.1718\n",
      "global round: 112  client: 90  local train loss: 1.1770\n",
      "global round: 112  client: 12  local train loss: 1.1760\n",
      "global round: 112  client: 01  local train loss: 1.1438\n",
      "global round: 112  client: 46  local train loss: 1.2173\n",
      "global round: 112  client: 21  local train loss: 1.1193\n",
      "global round: 112  avg train loss:0.1080  global test loss: 1.1279  global test accu: 0.8157\n",
      "================================================================================================================\n",
      "global round: 113  client: 32  local train loss: 1.1322\n",
      "global round: 113  client: 37  local train loss: 1.2526\n",
      "global round: 113  client: 67  local train loss: 1.2102\n",
      "global round: 113  client: 13  local train loss: 1.1564\n",
      "global round: 113  client: 93  local train loss: 1.3183\n",
      "global round: 113  client: 46  local train loss: 1.1659\n",
      "global round: 113  client: 59  local train loss: 1.3915\n",
      "global round: 113  client: 61  local train loss: 1.3083\n",
      "global round: 113  client: 07  local train loss: 1.2565\n",
      "global round: 113  client: 72  local train loss: 1.2059\n",
      "global round: 113  avg train loss:0.1127  global test loss: 1.1235  global test accu: 0.8160\n",
      "================================================================================================================\n",
      "global round: 114  client: 41  local train loss: 1.2602\n",
      "global round: 114  client: 74  local train loss: 1.2129\n",
      "global round: 114  client: 98  local train loss: 1.1585\n",
      "global round: 114  client: 31  local train loss: 1.2183\n",
      "global round: 114  client: 26  local train loss: 1.3159\n",
      "global round: 114  client: 38  local train loss: 1.2399\n",
      "global round: 114  client: 90  local train loss: 1.0919\n",
      "global round: 114  client: 69  local train loss: 1.1805\n",
      "global round: 114  client: 46  local train loss: 1.1746\n",
      "global round: 114  client: 10  local train loss: 1.1219\n",
      "global round: 114  avg train loss:0.1089  global test loss: 1.1152  global test accu: 0.8174\n",
      "================================================================================================================\n",
      "global round: 115  client: 21  local train loss: 1.1019\n",
      "global round: 115  client: 07  local train loss: 1.1532\n",
      "global round: 115  client: 97  local train loss: 1.4154\n",
      "global round: 115  client: 12  local train loss: 1.1664\n",
      "global round: 115  client: 66  local train loss: 1.2225\n",
      "global round: 115  client: 79  local train loss: 1.2728\n",
      "global round: 115  client: 10  local train loss: 1.1020\n",
      "global round: 115  client: 70  local train loss: 1.1835\n",
      "global round: 115  client: 13  local train loss: 1.1248\n",
      "global round: 115  client: 19  local train loss: 1.2190\n",
      "global round: 115  avg train loss:0.1087  global test loss: 1.1073  global test accu: 0.8183\n",
      "================================================================================================================\n",
      "global round: 116  client: 40  local train loss: 1.3493\n",
      "global round: 116  client: 30  local train loss: 1.3214\n",
      "global round: 116  client: 43  local train loss: 1.1383\n",
      "global round: 116  client: 76  local train loss: 1.1807\n",
      "global round: 116  client: 83  local train loss: 1.2861\n",
      "global round: 116  client: 20  local train loss: 1.3270\n",
      "global round: 116  client: 06  local train loss: 1.1906\n",
      "global round: 116  client: 84  local train loss: 1.1299\n",
      "global round: 116  client: 48  local train loss: 1.2271\n",
      "global round: 116  client: 05  local train loss: 1.2105\n",
      "global round: 116  avg train loss:0.1124  global test loss: 1.1037  global test accu: 0.8189\n",
      "================================================================================================================\n",
      "global round: 117  client: 97  local train loss: 1.1359\n",
      "global round: 117  client: 22  local train loss: 1.1642\n",
      "global round: 117  client: 15  local train loss: 1.1757\n",
      "global round: 117  client: 61  local train loss: 1.1598\n",
      "global round: 117  client: 56  local train loss: 1.1789\n",
      "global round: 117  client: 89  local train loss: 1.2054\n",
      "global round: 117  client: 85  local train loss: 1.1255\n",
      "global round: 117  client: 95  local train loss: 1.3511\n",
      "global round: 117  client: 30  local train loss: 1.1319\n",
      "global round: 117  client: 33  local train loss: 1.1643\n",
      "global round: 117  avg train loss:0.1072  global test loss: 1.0954  global test accu: 0.8204\n",
      "================================================================================================================\n",
      "global round: 118  client: 60  local train loss: 1.2067\n",
      "global round: 118  client: 34  local train loss: 1.2076\n",
      "global round: 118  client: 21  local train loss: 1.0856\n",
      "global round: 118  client: 56  local train loss: 1.1467\n",
      "global round: 118  client: 87  local train loss: 1.2297\n",
      "global round: 118  client: 25  local train loss: 1.2013\n",
      "global round: 118  client: 12  local train loss: 1.1546\n",
      "global round: 118  client: 44  local train loss: 1.4260\n",
      "global round: 118  client: 45  local train loss: 1.1914\n",
      "global round: 118  client: 00  local train loss: 1.2511\n",
      "global round: 118  avg train loss:0.1100  global test loss: 1.0905  global test accu: 0.8209\n",
      "================================================================================================================\n",
      "global round: 119  client: 50  local train loss: 1.1569\n",
      "global round: 119  client: 55  local train loss: 1.2188\n",
      "global round: 119  client: 53  local train loss: 1.1692\n",
      "global round: 119  client: 52  local train loss: 1.2233\n",
      "global round: 119  client: 81  local train loss: 1.1687\n",
      "global round: 119  client: 27  local train loss: 1.1908\n",
      "global round: 119  client: 93  local train loss: 1.1163\n",
      "global round: 119  client: 22  local train loss: 1.1175\n",
      "global round: 119  client: 95  local train loss: 1.1334\n",
      "global round: 119  client: 89  local train loss: 1.1124\n",
      "global round: 119  avg train loss:0.1055  global test loss: 1.0824  global test accu: 0.8214\n",
      "================================================================================================================\n",
      "global round: 120  client: 68  local train loss: 1.2623\n",
      "global round: 120  client: 28  local train loss: 1.3261\n",
      "global round: 120  client: 56  local train loss: 1.1452\n",
      "global round: 120  client: 94  local train loss: 1.1572\n",
      "global round: 120  client: 53  local train loss: 1.0977\n",
      "global round: 120  client: 74  local train loss: 1.1946\n",
      "global round: 120  client: 03  local train loss: 1.3457\n",
      "global round: 120  client: 34  local train loss: 1.1143\n",
      "global round: 120  client: 21  local train loss: 1.0726\n",
      "global round: 120  client: 96  local train loss: 1.2626\n",
      "global round: 120  avg train loss:0.1089  global test loss: 1.0771  global test accu: 0.8214\n",
      "================================================================================================================\n",
      "global round: 121  client: 11  local train loss: 1.1698\n",
      "global round: 121  client: 97  local train loss: 1.1393\n",
      "global round: 121  client: 08  local train loss: 1.2793\n",
      "global round: 121  client: 76  local train loss: 1.1206\n",
      "global round: 121  client: 47  local train loss: 1.1513\n",
      "global round: 121  client: 83  local train loss: 1.1402\n",
      "global round: 121  client: 53  local train loss: 1.1022\n",
      "global round: 121  client: 28  local train loss: 1.1409\n",
      "global round: 121  client: 01  local train loss: 1.1362\n",
      "global round: 121  client: 44  local train loss: 1.1242\n",
      "global round: 121  avg train loss:0.1046  global test loss: 1.0684  global test accu: 0.8225\n",
      "================================================================================================================\n",
      "global round: 122  client: 32  local train loss: 1.1298\n",
      "global round: 122  client: 17  local train loss: 1.2112\n",
      "global round: 122  client: 81  local train loss: 1.1186\n",
      "global round: 122  client: 89  local train loss: 1.1016\n",
      "global round: 122  client: 84  local train loss: 1.0854\n",
      "global round: 122  client: 29  local train loss: 1.2940\n",
      "global round: 122  client: 52  local train loss: 1.1159\n",
      "global round: 122  client: 56  local train loss: 1.1354\n",
      "global round: 122  client: 23  local train loss: 1.1867\n",
      "global round: 122  client: 87  local train loss: 1.1352\n",
      "global round: 122  avg train loss:0.1047  global test loss: 1.0606  global test accu: 0.8230\n",
      "================================================================================================================\n",
      "global round: 123  client: 80  local train loss: 1.2140\n",
      "global round: 123  client: 50  local train loss: 1.1216\n",
      "global round: 123  client: 89  local train loss: 1.0886\n",
      "global round: 123  client: 01  local train loss: 1.0874\n",
      "global round: 123  client: 05  local train loss: 1.1413\n",
      "global round: 123  client: 83  local train loss: 1.1140\n",
      "global round: 123  client: 38  local train loss: 1.1116\n",
      "global round: 123  client: 65  local train loss: 1.2421\n",
      "global round: 123  client: 61  local train loss: 1.1339\n",
      "global round: 123  client: 94  local train loss: 1.0768\n",
      "global round: 123  avg train loss:0.1030  global test loss: 1.0521  global test accu: 0.8238\n",
      "================================================================================================================\n",
      "global round: 124  client: 67  local train loss: 1.1340\n",
      "global round: 124  client: 02  local train loss: 1.1397\n",
      "global round: 124  client: 78  local train loss: 1.1794\n",
      "global round: 124  client: 44  local train loss: 1.1038\n",
      "global round: 124  client: 79  local train loss: 1.1473\n",
      "global round: 124  client: 94  local train loss: 1.0580\n",
      "global round: 124  client: 47  local train loss: 1.0871\n",
      "global round: 124  client: 43  local train loss: 1.1164\n",
      "global round: 124  client: 25  local train loss: 1.1086\n",
      "global round: 124  client: 82  local train loss: 1.2712\n",
      "global round: 124  avg train loss:0.1031  global test loss: 1.0450  global test accu: 0.8244\n",
      "================================================================================================================\n",
      "global round: 125  client: 93  local train loss: 1.0887\n",
      "global round: 125  client: 57  local train loss: 1.1835\n",
      "global round: 125  client: 35  local train loss: 1.2219\n",
      "global round: 125  client: 25  local train loss: 1.0757\n",
      "global round: 125  client: 12  local train loss: 1.1390\n",
      "global round: 125  client: 09  local train loss: 1.5145\n",
      "global round: 125  client: 31  local train loss: 1.0916\n",
      "global round: 125  client: 67  local train loss: 1.0644\n",
      "global round: 125  client: 91  local train loss: 1.1202\n",
      "global round: 125  client: 03  local train loss: 1.1548\n",
      "global round: 125  avg train loss:0.1059  global test loss: 1.0415  global test accu: 0.8240\n",
      "================================================================================================================\n",
      "global round: 126  client: 23  local train loss: 1.0735\n",
      "global round: 126  client: 65  local train loss: 1.1416\n",
      "global round: 126  client: 40  local train loss: 1.1183\n",
      "global round: 126  client: 54  local train loss: 1.2302\n",
      "global round: 126  client: 41  local train loss: 1.1641\n",
      "global round: 126  client: 26  local train loss: 1.1824\n",
      "global round: 126  client: 49  local train loss: 1.1982\n",
      "global round: 126  client: 93  local train loss: 1.0669\n",
      "global round: 126  client: 28  local train loss: 1.1285\n",
      "global round: 126  client: 78  local train loss: 1.1080\n",
      "global round: 126  avg train loss:0.1037  global test loss: 1.0347  global test accu: 0.8257\n",
      "================================================================================================================\n",
      "global round: 127  client: 35  local train loss: 1.0793\n",
      "global round: 127  client: 08  local train loss: 1.0774\n",
      "global round: 127  client: 64  local train loss: 1.2805\n",
      "global round: 127  client: 47  local train loss: 1.0673\n",
      "global round: 127  client: 85  local train loss: 1.0933\n",
      "global round: 127  client: 50  local train loss: 1.0885\n",
      "global round: 127  client: 78  local train loss: 1.0974\n",
      "global round: 127  client: 72  local train loss: 1.1635\n",
      "global round: 127  client: 21  local train loss: 1.0619\n",
      "global round: 127  client: 12  local train loss: 1.0958\n",
      "global round: 127  avg train loss:0.1010  global test loss: 1.0271  global test accu: 0.8260\n",
      "================================================================================================================\n",
      "global round: 128  client: 11  local train loss: 1.1071\n",
      "global round: 128  client: 97  local train loss: 1.1245\n",
      "global round: 128  client: 45  local train loss: 1.1121\n",
      "global round: 128  client: 34  local train loss: 1.1084\n",
      "global round: 128  client: 43  local train loss: 1.0649\n",
      "global round: 128  client: 94  local train loss: 1.0524\n",
      "global round: 128  client: 72  local train loss: 1.0875\n",
      "global round: 128  client: 38  local train loss: 1.0671\n",
      "global round: 128  client: 59  local train loss: 1.1705\n",
      "global round: 128  client: 42  local train loss: 1.1966\n",
      "global round: 128  avg train loss:0.1008  global test loss: 1.0197  global test accu: 0.8264\n",
      "================================================================================================================\n",
      "global round: 129  client: 21  local train loss: 1.0215\n",
      "global round: 129  client: 42  local train loss: 1.0696\n",
      "global round: 129  client: 36  local train loss: 1.3713\n",
      "global round: 129  client: 38  local train loss: 1.0416\n",
      "global round: 129  client: 69  local train loss: 1.1357\n",
      "global round: 129  client: 58  local train loss: 1.2075\n",
      "global round: 129  client: 94  local train loss: 1.0322\n",
      "global round: 129  client: 02  local train loss: 1.0623\n",
      "global round: 129  client: 67  local train loss: 1.0714\n",
      "global round: 129  client: 90  local train loss: 1.0903\n",
      "global round: 129  avg train loss:0.1009  global test loss: 1.0142  global test accu: 0.8275\n",
      "================================================================================================================\n",
      "global round: 130  client: 56  local train loss: 1.1116\n",
      "global round: 130  client: 16  local train loss: 1.1574\n",
      "global round: 130  client: 68  local train loss: 1.1528\n",
      "global round: 130  client: 64  local train loss: 1.0723\n",
      "global round: 130  client: 45  local train loss: 1.0522\n",
      "global round: 130  client: 66  local train loss: 1.1813\n",
      "global round: 130  client: 14  local train loss: 1.2140\n",
      "global round: 130  client: 43  local train loss: 1.0438\n",
      "global round: 130  client: 30  local train loss: 1.1274\n",
      "global round: 130  client: 37  local train loss: 1.1308\n",
      "global round: 130  avg train loss:0.1022  global test loss: 1.0084  global test accu: 0.8292\n",
      "================================================================================================================\n",
      "global round: 131  client: 20  local train loss: 1.1578\n",
      "global round: 131  client: 97  local train loss: 1.0787\n",
      "global round: 131  client: 46  local train loss: 1.1681\n",
      "global round: 131  client: 87  local train loss: 1.1116\n",
      "global round: 131  client: 29  local train loss: 1.1627\n",
      "global round: 131  client: 34  local train loss: 1.0687\n",
      "global round: 131  client: 17  local train loss: 1.1394\n",
      "global round: 131  client: 43  local train loss: 1.0364\n",
      "global round: 131  client: 92  local train loss: 1.1330\n",
      "global round: 131  client: 58  local train loss: 1.0404\n",
      "global round: 131  avg train loss:0.1009  global test loss: 1.0017  global test accu: 0.8302\n",
      "================================================================================================================\n",
      "global round: 132  client: 31  local train loss: 1.0468\n",
      "global round: 132  client: 56  local train loss: 1.0806\n",
      "global round: 132  client: 23  local train loss: 1.0501\n",
      "global round: 132  client: 19  local train loss: 1.1446\n",
      "global round: 132  client: 42  local train loss: 1.0735\n",
      "global round: 132  client: 73  local train loss: 1.1884\n",
      "global round: 132  client: 74  local train loss: 1.1666\n",
      "global round: 132  client: 61  local train loss: 1.1006\n",
      "global round: 132  client: 25  local train loss: 1.0719\n",
      "global round: 132  client: 69  local train loss: 1.0711\n",
      "global round: 132  avg train loss:0.0999  global test loss: 0.9952  global test accu: 0.8308\n",
      "================================================================================================================\n",
      "global round: 133  client: 54  local train loss: 1.0611\n",
      "global round: 133  client: 21  local train loss: 1.0190\n",
      "global round: 133  client: 99  local train loss: 1.3808\n",
      "global round: 133  client: 27  local train loss: 1.0833\n",
      "global round: 133  client: 70  local train loss: 1.1432\n",
      "global round: 133  client: 40  local train loss: 1.0641\n",
      "global round: 133  client: 45  local train loss: 1.0421\n",
      "global round: 133  client: 92  local train loss: 1.0042\n",
      "global round: 133  client: 79  local train loss: 1.0969\n",
      "global round: 133  client: 19  local train loss: 1.0656\n",
      "global round: 133  avg train loss:0.0996  global test loss: 0.9903  global test accu: 0.8314\n",
      "================================================================================================================\n",
      "global round: 134  client: 39  local train loss: 1.2475\n",
      "global round: 134  client: 48  local train loss: 1.1776\n",
      "global round: 134  client: 27  local train loss: 1.0094\n",
      "global round: 134  client: 84  local train loss: 1.0567\n",
      "global round: 134  client: 78  local train loss: 1.0890\n",
      "global round: 134  client: 55  local train loss: 1.1339\n",
      "global round: 134  client: 34  local train loss: 1.0445\n",
      "global round: 134  client: 67  local train loss: 1.0422\n",
      "global round: 134  client: 85  local train loss: 1.0458\n",
      "global round: 134  client: 47  local train loss: 1.0577\n",
      "global round: 134  avg train loss:0.0991  global test loss: 0.9852  global test accu: 0.8320\n",
      "================================================================================================================\n",
      "global round: 135  client: 97  local train loss: 1.0685\n",
      "global round: 135  client: 39  local train loss: 1.0258\n",
      "global round: 135  client: 16  local train loss: 1.0599\n",
      "global round: 135  client: 51  local train loss: 1.4366\n",
      "global round: 135  client: 80  local train loss: 1.0663\n",
      "global round: 135  client: 40  local train loss: 1.0325\n",
      "global round: 135  client: 61  local train loss: 1.0619\n",
      "global round: 135  client: 11  local train loss: 1.0745\n",
      "global round: 135  client: 12  local train loss: 1.0910\n",
      "global round: 135  client: 14  local train loss: 1.1001\n",
      "global round: 135  avg train loss:0.1002  global test loss: 0.9800  global test accu: 0.8321\n",
      "================================================================================================================\n",
      "global round: 136  client: 66  local train loss: 1.1012\n",
      "global round: 136  client: 67  local train loss: 1.0256\n",
      "global round: 136  client: 65  local train loss: 1.1222\n",
      "global round: 136  client: 55  local train loss: 1.0558\n",
      "global round: 136  client: 37  local train loss: 1.0349\n",
      "global round: 136  client: 40  local train loss: 1.0214\n",
      "global round: 136  client: 63  local train loss: 1.1278\n",
      "global round: 136  client: 90  local train loss: 1.0205\n",
      "global round: 136  client: 38  local train loss: 1.0366\n",
      "global round: 136  client: 88  local train loss: 1.2480\n",
      "global round: 136  avg train loss:0.0981  global test loss: 0.9746  global test accu: 0.8324\n",
      "================================================================================================================\n",
      "global round: 137  client: 36  local train loss: 1.1029\n",
      "global round: 137  client: 51  local train loss: 1.0348\n",
      "global round: 137  client: 46  local train loss: 1.0745\n",
      "global round: 137  client: 96  local train loss: 1.1263\n",
      "global round: 137  client: 67  local train loss: 1.0208\n",
      "global round: 137  client: 19  local train loss: 1.0546\n",
      "global round: 137  client: 22  local train loss: 1.1122\n",
      "global round: 137  client: 31  local train loss: 1.0127\n",
      "global round: 137  client: 16  local train loss: 1.0390\n",
      "global round: 137  client: 48  local train loss: 1.0900\n",
      "global round: 137  avg train loss:0.0970  global test loss: 0.9671  global test accu: 0.8336\n",
      "================================================================================================================\n",
      "global round: 138  client: 61  local train loss: 1.0609\n",
      "global round: 138  client: 84  local train loss: 0.9894\n",
      "global round: 138  client: 52  local train loss: 1.0944\n",
      "global round: 138  client: 07  local train loss: 1.1377\n",
      "global round: 138  client: 21  local train loss: 0.9997\n",
      "global round: 138  client: 27  local train loss: 1.0071\n",
      "global round: 138  client: 55  local train loss: 1.0557\n",
      "global round: 138  client: 71  local train loss: 1.2099\n",
      "global round: 138  client: 67  local train loss: 1.0072\n",
      "global round: 138  client: 31  local train loss: 0.9916\n",
      "global round: 138  avg train loss:0.0959  global test loss: 0.9609  global test accu: 0.8338\n",
      "================================================================================================================\n",
      "global round: 139  client: 81  local train loss: 1.1158\n",
      "global round: 139  client: 36  local train loss: 1.0728\n",
      "global round: 139  client: 40  local train loss: 1.0119\n",
      "global round: 139  client: 73  local train loss: 1.0569\n",
      "global round: 139  client: 07  local train loss: 1.0200\n",
      "global round: 139  client: 22  local train loss: 1.0185\n",
      "global round: 139  client: 38  local train loss: 1.0023\n",
      "global round: 139  client: 95  local train loss: 1.1254\n",
      "global round: 139  client: 55  local train loss: 1.0472\n",
      "global round: 139  client: 53  local train loss: 1.0836\n",
      "global round: 139  avg train loss:0.0960  global test loss: 0.9543  global test accu: 0.8349\n",
      "================================================================================================================\n",
      "global round: 140  client: 63  local train loss: 1.0035\n",
      "global round: 140  client: 28  local train loss: 1.1037\n",
      "global round: 140  client: 46  local train loss: 1.0563\n",
      "global round: 140  client: 76  local train loss: 1.0947\n",
      "global round: 140  client: 29  local train loss: 1.1247\n",
      "global round: 140  client: 86  local train loss: 1.1594\n",
      "global round: 140  client: 07  local train loss: 1.0090\n",
      "global round: 140  client: 02  local train loss: 1.0440\n",
      "global round: 140  client: 23  local train loss: 1.0202\n",
      "global round: 140  client: 04  local train loss: 1.1994\n",
      "global round: 140  avg train loss:0.0983  global test loss: 0.9506  global test accu: 0.8352\n",
      "================================================================================================================\n",
      "global round: 141  client: 13  local train loss: 1.1158\n",
      "global round: 141  client: 96  local train loss: 1.0444\n",
      "global round: 141  client: 94  local train loss: 1.0219\n",
      "global round: 141  client: 05  local train loss: 1.1062\n",
      "global round: 141  client: 22  local train loss: 1.0147\n",
      "global round: 141  client: 57  local train loss: 1.0690\n",
      "global round: 141  client: 28  local train loss: 1.0479\n",
      "global round: 141  client: 69  local train loss: 1.0501\n",
      "global round: 141  client: 40  local train loss: 1.0006\n",
      "global round: 141  client: 09  local train loss: 1.0868\n",
      "global round: 141  avg train loss:0.0960  global test loss: 0.9454  global test accu: 0.8357\n",
      "================================================================================================================\n",
      "global round: 142  client: 07  local train loss: 1.0092\n",
      "global round: 142  client: 42  local train loss: 1.0529\n",
      "global round: 142  client: 06  local train loss: 1.1589\n",
      "global round: 142  client: 17  local train loss: 1.0884\n",
      "global round: 142  client: 49  local train loss: 1.0969\n",
      "global round: 142  client: 19  local train loss: 1.0379\n",
      "global round: 142  client: 93  local train loss: 1.0564\n",
      "global round: 142  client: 96  local train loss: 1.0271\n",
      "global round: 142  client: 69  local train loss: 1.0161\n",
      "global round: 142  client: 72  local train loss: 1.0837\n",
      "global round: 142  avg train loss:0.0966  global test loss: 0.9404  global test accu: 0.8361\n",
      "================================================================================================================\n",
      "global round: 143  client: 59  local train loss: 1.0882\n",
      "global round: 143  client: 69  local train loss: 1.0052\n",
      "global round: 143  client: 06  local train loss: 1.0326\n",
      "global round: 143  client: 73  local train loss: 1.0240\n",
      "global round: 143  client: 83  local train loss: 1.0911\n",
      "global round: 143  client: 96  local train loss: 1.0183\n",
      "global round: 143  client: 58  local train loss: 1.0402\n",
      "global round: 143  client: 20  local train loss: 1.0894\n",
      "global round: 143  client: 55  local train loss: 1.0454\n",
      "global round: 143  client: 80  local train loss: 1.0244\n",
      "global round: 143  avg train loss:0.0951  global test loss: 0.9342  global test accu: 0.8359\n",
      "================================================================================================================\n",
      "global round: 144  client: 62  local train loss: 1.1364\n",
      "global round: 144  client: 45  local train loss: 1.0335\n",
      "global round: 144  client: 11  local train loss: 1.0365\n",
      "global round: 144  client: 49  local train loss: 1.0212\n",
      "global round: 144  client: 73  local train loss: 1.0139\n",
      "global round: 144  client: 31  local train loss: 0.9764\n",
      "global round: 144  client: 17  local train loss: 1.0314\n",
      "global round: 144  client: 37  local train loss: 1.0137\n",
      "global round: 144  client: 39  local train loss: 1.0202\n",
      "global round: 144  client: 98  local train loss: 1.1515\n",
      "global round: 144  avg train loss:0.0949  global test loss: 0.9297  global test accu: 0.8364\n",
      "================================================================================================================\n",
      "global round: 145  client: 23  local train loss: 0.9839\n",
      "global round: 145  client: 27  local train loss: 0.9888\n",
      "global round: 145  client: 35  local train loss: 1.0706\n",
      "global round: 145  client: 83  local train loss: 1.0085\n",
      "global round: 145  client: 98  local train loss: 1.0098\n",
      "global round: 145  client: 31  local train loss: 0.9560\n",
      "global round: 145  client: 50  local train loss: 1.0863\n",
      "global round: 145  client: 29  local train loss: 1.0872\n",
      "global round: 145  client: 69  local train loss: 1.0020\n",
      "global round: 145  client: 24  local train loss: 1.1734\n",
      "global round: 145  avg train loss:0.0942  global test loss: 0.9243  global test accu: 0.8378\n",
      "================================================================================================================\n",
      "global round: 146  client: 15  local train loss: 1.1373\n",
      "global round: 146  client: 85  local train loss: 1.0167\n",
      "global round: 146  client: 93  local train loss: 0.9734\n",
      "global round: 146  client: 56  local train loss: 1.0689\n",
      "global round: 146  client: 22  local train loss: 1.0049\n",
      "global round: 146  client: 18  local train loss: 1.1567\n",
      "global round: 146  client: 17  local train loss: 1.0370\n",
      "global round: 146  client: 94  local train loss: 0.9730\n",
      "global round: 146  client: 41  local train loss: 1.0970\n",
      "global round: 146  client: 75  local train loss: 1.2928\n",
      "global round: 146  avg train loss:0.0978  global test loss: 0.9229  global test accu: 0.8381\n",
      "================================================================================================================\n",
      "global round: 147  client: 89  local train loss: 1.0772\n",
      "global round: 147  client: 57  local train loss: 0.9964\n",
      "global round: 147  client: 05  local train loss: 1.0192\n",
      "global round: 147  client: 74  local train loss: 1.1036\n",
      "global round: 147  client: 55  local train loss: 1.0251\n",
      "global round: 147  client: 07  local train loss: 1.0042\n",
      "global round: 147  client: 24  local train loss: 1.0252\n",
      "global round: 147  client: 59  local train loss: 1.0196\n",
      "global round: 147  client: 30  local train loss: 1.0626\n",
      "global round: 147  client: 77  local train loss: 1.2059\n",
      "global round: 147  avg train loss:0.0958  global test loss: 0.9185  global test accu: 0.8385\n",
      "================================================================================================================\n",
      "global round: 148  client: 40  local train loss: 0.9905\n",
      "global round: 148  client: 94  local train loss: 0.9554\n",
      "global round: 148  client: 34  local train loss: 1.0377\n",
      "global round: 148  client: 02  local train loss: 0.9872\n",
      "global round: 148  client: 32  local train loss: 1.0812\n",
      "global round: 148  client: 42  local train loss: 1.0168\n",
      "global round: 148  client: 12  local train loss: 1.0546\n",
      "global round: 148  client: 01  local train loss: 1.0831\n",
      "global round: 148  client: 19  local train loss: 1.0169\n",
      "global round: 148  client: 76  local train loss: 1.0128\n",
      "global round: 148  avg train loss:0.0931  global test loss: 0.9139  global test accu: 0.8388\n",
      "================================================================================================================\n",
      "global round: 149  client: 37  local train loss: 0.9763\n",
      "global round: 149  client: 97  local train loss: 1.0504\n",
      "global round: 149  client: 86  local train loss: 1.0187\n",
      "global round: 149  client: 87  local train loss: 1.0805\n",
      "global round: 149  client: 59  local train loss: 1.0016\n",
      "global round: 149  client: 40  local train loss: 0.9669\n",
      "global round: 149  client: 54  local train loss: 1.0371\n",
      "global round: 149  client: 58  local train loss: 0.9886\n",
      "global round: 149  client: 60  local train loss: 1.1535\n",
      "global round: 149  client: 48  local train loss: 1.0682\n",
      "global round: 149  avg train loss:0.0940  global test loss: 0.9094  global test accu: 0.8392\n",
      "================================================================================================================\n",
      "global round: 150  client: 13  local train loss: 0.9917\n",
      "global round: 150  client: 57  local train loss: 0.9757\n",
      "global round: 150  client: 70  local train loss: 1.0568\n",
      "global round: 150  client: 96  local train loss: 1.0172\n",
      "global round: 150  client: 25  local train loss: 1.0365\n",
      "global round: 150  client: 80  local train loss: 0.9843\n",
      "global round: 150  client: 31  local train loss: 0.9460\n",
      "global round: 150  client: 36  local train loss: 1.0540\n",
      "global round: 150  client: 72  local train loss: 1.0311\n",
      "global round: 150  client: 03  local train loss: 1.1382\n",
      "global round: 150  avg train loss:0.0930  global test loss: 0.9045  global test accu: 0.8399\n",
      "================================================================================================================\n",
      "global round: 151  client: 20  local train loss: 1.0321\n",
      "global round: 151  client: 32  local train loss: 0.9731\n",
      "global round: 151  client: 98  local train loss: 1.0141\n",
      "global round: 151  client: 16  local train loss: 1.0194\n",
      "global round: 151  client: 79  local train loss: 1.0529\n",
      "global round: 151  client: 83  local train loss: 1.0027\n",
      "global round: 151  client: 41  local train loss: 1.0197\n",
      "global round: 151  client: 51  local train loss: 1.0227\n",
      "global round: 151  client: 40  local train loss: 0.9665\n",
      "global round: 151  client: 06  local train loss: 1.0254\n",
      "global round: 151  avg train loss:0.0921  global test loss: 0.8989  global test accu: 0.8403\n",
      "================================================================================================================\n",
      "global round: 152  client: 91  local train loss: 1.0496\n",
      "global round: 152  client: 83  local train loss: 0.9785\n",
      "global round: 152  client: 27  local train loss: 0.9560\n",
      "global round: 152  client: 95  local train loss: 1.0358\n",
      "global round: 152  client: 19  local train loss: 0.9952\n",
      "global round: 152  client: 13  local train loss: 0.9653\n",
      "global round: 152  client: 93  local train loss: 0.9782\n",
      "global round: 152  client: 45  local train loss: 0.9785\n",
      "global round: 152  client: 90  local train loss: 0.9815\n",
      "global round: 152  client: 48  local train loss: 1.0359\n",
      "global round: 152  avg train loss:0.0905  global test loss: 0.8937  global test accu: 0.8405\n",
      "================================================================================================================\n",
      "global round: 153  client: 15  local train loss: 1.0047\n",
      "global round: 153  client: 84  local train loss: 0.9801\n",
      "global round: 153  client: 65  local train loss: 1.0742\n",
      "global round: 153  client: 34  local train loss: 0.9859\n",
      "global round: 153  client: 53  local train loss: 0.9939\n",
      "global round: 153  client: 01  local train loss: 0.9735\n",
      "global round: 153  client: 40  local train loss: 0.9543\n",
      "global round: 153  client: 11  local train loss: 0.9989\n",
      "global round: 153  client: 22  local train loss: 0.9803\n",
      "global round: 153  client: 48  local train loss: 1.0124\n",
      "global round: 153  avg train loss:0.0905  global test loss: 0.8882  global test accu: 0.8412\n",
      "================================================================================================================\n",
      "global round: 154  client: 07  local train loss: 0.9930\n",
      "global round: 154  client: 29  local train loss: 1.0560\n",
      "global round: 154  client: 64  local train loss: 1.0654\n",
      "global round: 154  client: 31  local train loss: 0.9340\n",
      "global round: 154  client: 53  local train loss: 0.9467\n",
      "global round: 154  client: 50  local train loss: 0.9942\n",
      "global round: 154  client: 58  local train loss: 0.9545\n",
      "global round: 154  client: 48  local train loss: 1.0138\n",
      "global round: 154  client: 21  local train loss: 0.9771\n",
      "global round: 154  client: 26  local train loss: 1.1238\n",
      "global round: 154  avg train loss:0.0914  global test loss: 0.8837  global test accu: 0.8419\n",
      "================================================================================================================\n",
      "global round: 155  client: 77  local train loss: 1.0360\n",
      "global round: 155  client: 08  local train loss: 1.0415\n",
      "global round: 155  client: 29  local train loss: 1.0220\n",
      "global round: 155  client: 93  local train loss: 0.9518\n",
      "global round: 155  client: 64  local train loss: 0.9722\n",
      "global round: 155  client: 32  local train loss: 0.9531\n",
      "global round: 155  client: 40  local train loss: 0.9423\n",
      "global round: 155  client: 18  local train loss: 0.9955\n",
      "global round: 155  client: 47  local train loss: 1.0200\n",
      "global round: 155  client: 62  local train loss: 0.9608\n",
      "global round: 155  avg train loss:0.0900  global test loss: 0.8787  global test accu: 0.8426\n",
      "================================================================================================================\n",
      "global round: 156  client: 89  local train loss: 0.9826\n",
      "global round: 156  client: 14  local train loss: 1.0851\n",
      "global round: 156  client: 49  local train loss: 1.0122\n",
      "global round: 156  client: 09  local train loss: 1.0079\n",
      "global round: 156  client: 47  local train loss: 0.9361\n",
      "global round: 156  client: 70  local train loss: 0.9955\n",
      "global round: 156  client: 92  local train loss: 0.9949\n",
      "global round: 156  client: 48  local train loss: 1.0155\n",
      "global round: 156  client: 16  local train loss: 0.9733\n",
      "global round: 156  client: 79  local train loss: 0.9877\n",
      "global round: 156  avg train loss:0.0908  global test loss: 0.8742  global test accu: 0.8438\n",
      "================================================================================================================\n",
      "global round: 157  client: 56  local train loss: 1.0132\n",
      "global round: 157  client: 01  local train loss: 0.9494\n",
      "global round: 157  client: 11  local train loss: 0.9655\n",
      "global round: 157  client: 68  local train loss: 1.0982\n",
      "global round: 157  client: 80  local train loss: 0.9648\n",
      "global round: 157  client: 78  local train loss: 1.0558\n",
      "global round: 157  client: 04  local train loss: 1.0202\n",
      "global round: 157  client: 14  local train loss: 1.0134\n",
      "global round: 157  client: 67  local train loss: 1.0000\n",
      "global round: 157  client: 58  local train loss: 0.9390\n",
      "global round: 157  avg train loss:0.0911  global test loss: 0.8704  global test accu: 0.8449\n",
      "================================================================================================================\n",
      "global round: 158  client: 84  local train loss: 0.9206\n",
      "global round: 158  client: 69  local train loss: 0.9958\n",
      "global round: 158  client: 80  local train loss: 0.9300\n",
      "global round: 158  client: 46  local train loss: 1.0316\n",
      "global round: 158  client: 41  local train loss: 1.0015\n",
      "global round: 158  client: 35  local train loss: 0.9915\n",
      "global round: 158  client: 96  local train loss: 0.9976\n",
      "global round: 158  client: 39  local train loss: 0.9766\n",
      "global round: 158  client: 95  local train loss: 0.9896\n",
      "global round: 158  client: 74  local train loss: 1.0456\n",
      "global round: 158  avg train loss:0.0898  global test loss: 0.8661  global test accu: 0.8452\n",
      "================================================================================================================\n",
      "global round: 159  client: 93  local train loss: 0.9382\n",
      "global round: 159  client: 88  local train loss: 1.0090\n",
      "global round: 159  client: 23  local train loss: 0.9662\n",
      "global round: 159  client: 87  local train loss: 0.9960\n",
      "global round: 159  client: 80  local train loss: 0.9260\n",
      "global round: 159  client: 05  local train loss: 1.0156\n",
      "global round: 159  client: 24  local train loss: 1.0312\n",
      "global round: 159  client: 72  local train loss: 0.9951\n",
      "global round: 159  client: 49  local train loss: 0.9634\n",
      "global round: 159  client: 47  local train loss: 0.9352\n",
      "global round: 159  avg train loss:0.0889  global test loss: 0.8616  global test accu: 0.8457\n",
      "================================================================================================================\n",
      "global round: 160  client: 98  local train loss: 0.9936\n",
      "global round: 160  client: 87  local train loss: 0.9605\n",
      "global round: 160  client: 34  local train loss: 0.9649\n",
      "global round: 160  client: 86  local train loss: 0.9844\n",
      "global round: 160  client: 26  local train loss: 1.0158\n",
      "global round: 160  client: 01  local train loss: 0.9387\n",
      "global round: 160  client: 39  local train loss: 0.9325\n",
      "global round: 160  client: 31  local train loss: 0.9260\n",
      "global round: 160  client: 03  local train loss: 1.0338\n",
      "global round: 160  client: 90  local train loss: 0.9196\n",
      "global round: 160  avg train loss:0.0879  global test loss: 0.8563  global test accu: 0.8461\n",
      "================================================================================================================\n",
      "global round: 161  client: 58  local train loss: 0.9479\n",
      "global round: 161  client: 38  local train loss: 0.9820\n",
      "global round: 161  client: 24  local train loss: 0.9892\n",
      "global round: 161  client: 14  local train loss: 1.0048\n",
      "global round: 161  client: 63  local train loss: 0.9749\n",
      "global round: 161  client: 62  local train loss: 0.9178\n",
      "global round: 161  client: 84  local train loss: 0.9073\n",
      "global round: 161  client: 98  local train loss: 0.9601\n",
      "global round: 161  client: 96  local train loss: 0.9633\n",
      "global round: 161  client: 50  local train loss: 0.9522\n",
      "global round: 161  avg train loss:0.0873  global test loss: 0.8513  global test accu: 0.8465\n",
      "================================================================================================================\n",
      "global round: 162  client: 47  local train loss: 0.9220\n",
      "global round: 162  client: 69  local train loss: 0.9550\n",
      "global round: 162  client: 32  local train loss: 0.9462\n",
      "global round: 162  client: 22  local train loss: 0.9571\n",
      "global round: 162  client: 25  local train loss: 0.9681\n",
      "global round: 162  client: 18  local train loss: 0.9596\n",
      "global round: 162  client: 40  local train loss: 0.9332\n",
      "global round: 162  client: 27  local train loss: 0.9314\n",
      "global round: 162  client: 38  local train loss: 0.9087\n",
      "global round: 162  client: 64  local train loss: 0.9693\n",
      "global round: 162  avg train loss:0.0859  global test loss: 0.8461  global test accu: 0.8469\n",
      "================================================================================================================\n",
      "global round: 163  client: 34  local train loss: 0.9442\n",
      "global round: 163  client: 81  local train loss: 1.0244\n",
      "global round: 163  client: 31  local train loss: 0.8969\n",
      "global round: 163  client: 90  local train loss: 0.8835\n",
      "global round: 163  client: 13  local train loss: 0.9552\n",
      "global round: 163  client: 09  local train loss: 0.9587\n",
      "global round: 163  client: 48  local train loss: 1.0094\n",
      "global round: 163  client: 89  local train loss: 0.9410\n",
      "global round: 163  client: 71  local train loss: 1.0706\n",
      "global round: 163  client: 25  local train loss: 0.9236\n",
      "global round: 163  avg train loss:0.0873  global test loss: 0.8420  global test accu: 0.8474\n",
      "================================================================================================================\n",
      "global round: 164  client: 34  local train loss: 0.9245\n",
      "global round: 164  client: 46  local train loss: 0.9713\n",
      "global round: 164  client: 21  local train loss: 0.9215\n",
      "global round: 164  client: 92  local train loss: 0.9056\n",
      "global round: 164  client: 70  local train loss: 0.9640\n",
      "global round: 164  client: 94  local train loss: 0.9511\n",
      "global round: 164  client: 79  local train loss: 0.9611\n",
      "global round: 164  client: 24  local train loss: 0.9736\n",
      "global round: 164  client: 78  local train loss: 0.9720\n",
      "global round: 164  client: 08  local train loss: 0.9264\n",
      "global round: 164  avg train loss:0.0861  global test loss: 0.8373  global test accu: 0.8482\n",
      "================================================================================================================\n",
      "global round: 165  client: 02  local train loss: 0.9669\n",
      "global round: 165  client: 84  local train loss: 0.8903\n",
      "global round: 165  client: 23  local train loss: 0.9201\n",
      "global round: 165  client: 42  local train loss: 0.9880\n",
      "global round: 165  client: 90  local train loss: 0.8775\n",
      "global round: 165  client: 79  local train loss: 0.9271\n",
      "global round: 165  client: 04  local train loss: 0.9469\n",
      "global round: 165  client: 97  local train loss: 0.9865\n",
      "global round: 165  client: 40  local train loss: 0.9019\n",
      "global round: 165  client: 93  local train loss: 0.9270\n",
      "global round: 165  avg train loss:0.0848  global test loss: 0.8330  global test accu: 0.8485\n",
      "================================================================================================================\n",
      "global round: 166  client: 40  local train loss: 0.8957\n",
      "global round: 166  client: 58  local train loss: 0.9135\n",
      "global round: 166  client: 59  local train loss: 0.9946\n",
      "global round: 166  client: 05  local train loss: 0.9588\n",
      "global round: 166  client: 50  local train loss: 0.9339\n",
      "global round: 166  client: 41  local train loss: 0.9641\n",
      "global round: 166  client: 77  local train loss: 1.0001\n",
      "global round: 166  client: 54  local train loss: 0.9725\n",
      "global round: 166  client: 45  local train loss: 0.9694\n",
      "global round: 166  client: 87  local train loss: 0.9548\n",
      "global round: 166  avg train loss:0.0869  global test loss: 0.8291  global test accu: 0.8491\n",
      "================================================================================================================\n",
      "global round: 167  client: 58  local train loss: 0.8927\n",
      "global round: 167  client: 34  local train loss: 0.9197\n",
      "global round: 167  client: 23  local train loss: 0.8935\n",
      "global round: 167  client: 52  local train loss: 1.0229\n",
      "global round: 167  client: 74  local train loss: 0.9987\n",
      "global round: 167  client: 30  local train loss: 0.9933\n",
      "global round: 167  client: 20  local train loss: 1.0066\n",
      "global round: 167  client: 62  local train loss: 0.8900\n",
      "global round: 167  client: 10  local train loss: 1.0949\n",
      "global round: 167  client: 78  local train loss: 0.9304\n",
      "global round: 167  avg train loss:0.0877  global test loss: 0.8269  global test accu: 0.8493\n",
      "================================================================================================================\n",
      "global round: 168  client: 83  local train loss: 0.9850\n",
      "global round: 168  client: 02  local train loss: 0.8951\n",
      "global round: 168  client: 33  local train loss: 1.1232\n",
      "global round: 168  client: 12  local train loss: 0.9990\n",
      "global round: 168  client: 61  local train loss: 1.0382\n",
      "global round: 168  client: 67  local train loss: 0.9410\n",
      "global round: 168  client: 89  local train loss: 0.9194\n",
      "global round: 168  client: 26  local train loss: 0.9908\n",
      "global round: 168  client: 15  local train loss: 0.9718\n",
      "global round: 168  client: 03  local train loss: 0.9941\n",
      "global round: 168  avg train loss:0.0896  global test loss: 0.8256  global test accu: 0.8494\n",
      "================================================================================================================\n",
      "global round: 169  client: 92  local train loss: 0.8825\n",
      "global round: 169  client: 77  local train loss: 0.9610\n",
      "global round: 169  client: 24  local train loss: 0.9644\n",
      "global round: 169  client: 84  local train loss: 0.8847\n",
      "global round: 169  client: 65  local train loss: 1.0107\n",
      "global round: 169  client: 08  local train loss: 0.8872\n",
      "global round: 169  client: 26  local train loss: 0.9635\n",
      "global round: 169  client: 22  local train loss: 0.9351\n",
      "global round: 169  client: 96  local train loss: 0.9514\n",
      "global round: 169  client: 28  local train loss: 1.0392\n",
      "global round: 169  avg train loss:0.0862  global test loss: 0.8212  global test accu: 0.8496\n",
      "================================================================================================================\n",
      "global round: 170  client: 86  local train loss: 0.9505\n",
      "global round: 170  client: 10  local train loss: 0.8792\n",
      "global round: 170  client: 89  local train loss: 0.9089\n",
      "global round: 170  client: 77  local train loss: 0.9543\n",
      "global round: 170  client: 19  local train loss: 0.9789\n",
      "global round: 170  client: 96  local train loss: 0.9364\n",
      "global round: 170  client: 62  local train loss: 0.8758\n",
      "global round: 170  client: 41  local train loss: 0.9474\n",
      "global round: 170  client: 87  local train loss: 0.9366\n",
      "global round: 170  client: 28  local train loss: 0.9425\n",
      "global round: 170  avg train loss:0.0846  global test loss: 0.8159  global test accu: 0.8506\n",
      "================================================================================================================\n",
      "global round: 171  client: 76  local train loss: 0.9755\n",
      "global round: 171  client: 03  local train loss: 0.9723\n",
      "global round: 171  client: 25  local train loss: 0.9161\n",
      "global round: 171  client: 26  local train loss: 0.9554\n",
      "global round: 171  client: 81  local train loss: 0.9399\n",
      "global round: 171  client: 10  local train loss: 0.8683\n",
      "global round: 171  client: 19  local train loss: 0.9095\n",
      "global round: 171  client: 58  local train loss: 0.8961\n",
      "global round: 171  client: 56  local train loss: 0.9765\n",
      "global round: 171  client: 78  local train loss: 0.9315\n",
      "global round: 171  avg train loss:0.0849  global test loss: 0.8114  global test accu: 0.8515\n",
      "================================================================================================================\n",
      "global round: 172  client: 35  local train loss: 0.9471\n",
      "global round: 172  client: 48  local train loss: 0.9803\n",
      "global round: 172  client: 45  local train loss: 0.8991\n",
      "global round: 172  client: 42  local train loss: 0.9279\n",
      "global round: 172  client: 50  local train loss: 0.9174\n",
      "global round: 172  client: 78  local train loss: 0.9172\n",
      "global round: 172  client: 11  local train loss: 0.9592\n",
      "global round: 172  client: 83  local train loss: 0.9147\n",
      "global round: 172  client: 61  local train loss: 0.9344\n",
      "global round: 172  client: 24  local train loss: 0.9584\n",
      "global round: 172  avg train loss:0.0851  global test loss: 0.8070  global test accu: 0.8520\n",
      "================================================================================================================\n",
      "global round: 173  client: 60  local train loss: 1.0138\n",
      "global round: 173  client: 43  local train loss: 1.0290\n",
      "global round: 173  client: 82  local train loss: 1.1070\n",
      "global round: 173  client: 26  local train loss: 0.9512\n",
      "global round: 173  client: 67  local train loss: 0.8990\n",
      "global round: 173  client: 31  local train loss: 0.8868\n",
      "global round: 173  client: 41  local train loss: 0.9344\n",
      "global round: 173  client: 00  local train loss: 1.1183\n",
      "global round: 173  client: 28  local train loss: 0.9371\n",
      "global round: 173  client: 24  local train loss: 0.9339\n",
      "global round: 173  avg train loss:0.0892  global test loss: 0.8071  global test accu: 0.8518\n",
      "================================================================================================================\n",
      "global round: 174  client: 60  local train loss: 0.9428\n",
      "global round: 174  client: 95  local train loss: 0.9724\n",
      "global round: 174  client: 43  local train loss: 0.8763\n",
      "global round: 174  client: 20  local train loss: 0.9472\n",
      "global round: 174  client: 46  local train loss: 0.9517\n",
      "global round: 174  client: 83  local train loss: 0.9140\n",
      "global round: 174  client: 19  local train loss: 0.9079\n",
      "global round: 174  client: 27  local train loss: 0.8973\n",
      "global round: 174  client: 87  local train loss: 0.9270\n",
      "global round: 174  client: 39  local train loss: 0.9272\n",
      "global round: 174  avg train loss:0.0842  global test loss: 0.8026  global test accu: 0.8520\n",
      "================================================================================================================\n",
      "global round: 175  client: 76  local train loss: 0.8964\n",
      "global round: 175  client: 55  local train loss: 1.0104\n",
      "global round: 175  client: 62  local train loss: 0.8680\n",
      "global round: 175  client: 28  local train loss: 0.9349\n",
      "global round: 175  client: 54  local train loss: 0.9061\n",
      "global round: 175  client: 90  local train loss: 0.8661\n",
      "global round: 175  client: 33  local train loss: 0.9091\n",
      "global round: 175  client: 57  local train loss: 0.9733\n",
      "global round: 175  client: 05  local train loss: 0.9404\n",
      "global round: 175  client: 79  local train loss: 0.9279\n",
      "global round: 175  avg train loss:0.0839  global test loss: 0.7994  global test accu: 0.8522\n",
      "================================================================================================================\n",
      "global round: 176  client: 32  local train loss: 0.9198\n",
      "global round: 176  client: 36  local train loss: 1.0209\n",
      "global round: 176  client: 60  local train loss: 0.9305\n",
      "global round: 176  client: 94  local train loss: 0.8880\n",
      "global round: 176  client: 43  local train loss: 0.8787\n",
      "global round: 176  client: 05  local train loss: 0.9133\n",
      "global round: 176  client: 64  local train loss: 0.9381\n",
      "global round: 176  client: 70  local train loss: 0.9292\n",
      "global round: 176  client: 87  local train loss: 0.9180\n",
      "global round: 176  client: 96  local train loss: 0.9315\n",
      "global round: 176  avg train loss:0.0843  global test loss: 0.7956  global test accu: 0.8523\n",
      "================================================================================================================\n",
      "global round: 177  client: 47  local train loss: 0.9127\n",
      "global round: 177  client: 56  local train loss: 0.9346\n",
      "global round: 177  client: 15  local train loss: 0.9230\n",
      "global round: 177  client: 98  local train loss: 0.9559\n",
      "global round: 177  client: 49  local train loss: 0.9580\n",
      "global round: 177  client: 72  local train loss: 0.9526\n",
      "global round: 177  client: 05  local train loss: 0.9031\n",
      "global round: 177  client: 53  local train loss: 0.9377\n",
      "global round: 177  client: 77  local train loss: 0.9577\n",
      "global round: 177  client: 69  local train loss: 0.9422\n",
      "global round: 177  avg train loss:0.0853  global test loss: 0.7931  global test accu: 0.8529\n",
      "================================================================================================================\n",
      "global round: 178  client: 08  local train loss: 0.8712\n",
      "global round: 178  client: 00  local train loss: 0.9059\n",
      "global round: 178  client: 63  local train loss: 0.8923\n",
      "global round: 178  client: 21  local train loss: 0.8795\n",
      "global round: 178  client: 64  local train loss: 0.9007\n",
      "global round: 178  client: 88  local train loss: 0.9160\n",
      "global round: 178  client: 78  local train loss: 0.9102\n",
      "global round: 178  client: 32  local train loss: 0.8730\n",
      "global round: 178  client: 25  local train loss: 0.8922\n",
      "global round: 178  client: 89  local train loss: 0.8947\n",
      "global round: 178  avg train loss:0.0812  global test loss: 0.7891  global test accu: 0.8529\n",
      "================================================================================================================\n",
      "global round: 179  client: 79  local train loss: 0.8953\n",
      "global round: 179  client: 32  local train loss: 0.8646\n",
      "global round: 179  client: 12  local train loss: 0.9290\n",
      "global round: 179  client: 98  local train loss: 0.9116\n",
      "global round: 179  client: 63  local train loss: 0.8380\n",
      "global round: 179  client: 13  local train loss: 0.9100\n",
      "global round: 179  client: 86  local train loss: 0.9130\n",
      "global round: 179  client: 83  local train loss: 0.9032\n",
      "global round: 179  client: 16  local train loss: 0.9476\n",
      "global round: 179  client: 70  local train loss: 0.9010\n",
      "global round: 179  avg train loss:0.0819  global test loss: 0.7850  global test accu: 0.8532\n",
      "================================================================================================================\n",
      "global round: 180  client: 72  local train loss: 0.9015\n",
      "global round: 180  client: 41  local train loss: 0.9314\n",
      "global round: 180  client: 42  local train loss: 0.9007\n",
      "global round: 180  client: 66  local train loss: 1.0759\n",
      "global round: 180  client: 24  local train loss: 0.9372\n",
      "global round: 180  client: 47  local train loss: 0.8670\n",
      "global round: 180  client: 44  local train loss: 1.0842\n",
      "global round: 180  client: 96  local train loss: 0.9131\n",
      "global round: 180  client: 53  local train loss: 0.8710\n",
      "global round: 180  client: 54  local train loss: 0.8791\n",
      "global round: 180  avg train loss:0.0851  global test loss: 0.7832  global test accu: 0.8533\n",
      "================================================================================================================\n",
      "global round: 181  client: 40  local train loss: 0.8944\n",
      "global round: 181  client: 86  local train loss: 0.8869\n",
      "global round: 181  client: 85  local train loss: 0.9620\n",
      "global round: 181  client: 19  local train loss: 0.9054\n",
      "global round: 181  client: 73  local train loss: 1.0038\n",
      "global round: 181  client: 13  local train loss: 0.8766\n",
      "global round: 181  client: 12  local train loss: 0.8990\n",
      "global round: 181  client: 05  local train loss: 0.9085\n",
      "global round: 181  client: 34  local train loss: 0.9058\n",
      "global round: 181  client: 82  local train loss: 0.9378\n",
      "global round: 181  avg train loss:0.0835  global test loss: 0.7807  global test accu: 0.8536\n",
      "================================================================================================================\n",
      "global round: 182  client: 50  local train loss: 0.8924\n",
      "global round: 182  client: 14  local train loss: 0.9904\n",
      "global round: 182  client: 54  local train loss: 0.8725\n",
      "global round: 182  client: 27  local train loss: 0.8630\n",
      "global round: 182  client: 90  local train loss: 0.8403\n",
      "global round: 182  client: 62  local train loss: 0.8545\n",
      "global round: 182  client: 85  local train loss: 0.8522\n",
      "global round: 182  client: 18  local train loss: 0.9378\n",
      "global round: 182  client: 17  local train loss: 1.0315\n",
      "global round: 182  client: 75  local train loss: 1.0487\n",
      "global round: 182  avg train loss:0.0835  global test loss: 0.7788  global test accu: 0.8535\n",
      "================================================================================================================\n",
      "global round: 183  client: 26  local train loss: 0.9467\n",
      "global round: 183  client: 17  local train loss: 0.9193\n",
      "global round: 183  client: 39  local train loss: 0.8759\n",
      "global round: 183  client: 54  local train loss: 0.8524\n",
      "global round: 183  client: 74  local train loss: 0.9673\n",
      "global round: 183  client: 16  local train loss: 0.8768\n",
      "global round: 183  client: 92  local train loss: 0.8644\n",
      "global round: 183  client: 62  local train loss: 0.8268\n",
      "global round: 183  client: 02  local train loss: 0.8904\n",
      "global round: 183  client: 87  local train loss: 0.9068\n",
      "global round: 183  avg train loss:0.0812  global test loss: 0.7747  global test accu: 0.8541\n",
      "================================================================================================================\n",
      "global round: 184  client: 83  local train loss: 0.8915\n",
      "global round: 184  client: 67  local train loss: 0.8801\n",
      "global round: 184  client: 55  local train loss: 0.9188\n",
      "global round: 184  client: 31  local train loss: 0.8532\n",
      "global round: 184  client: 04  local train loss: 0.9214\n",
      "global round: 184  client: 46  local train loss: 0.9254\n",
      "global round: 184  client: 64  local train loss: 0.8972\n",
      "global round: 184  client: 32  local train loss: 0.8687\n",
      "global round: 184  client: 40  local train loss: 0.8559\n",
      "global round: 184  client: 56  local train loss: 0.9164\n",
      "global round: 184  avg train loss:0.0812  global test loss: 0.7710  global test accu: 0.8545\n",
      "================================================================================================================\n",
      "global round: 185  client: 01  local train loss: 0.9196\n",
      "global round: 185  client: 58  local train loss: 0.8835\n",
      "global round: 185  client: 49  local train loss: 0.9109\n",
      "global round: 185  client: 74  local train loss: 0.9252\n",
      "global round: 185  client: 92  local train loss: 0.8291\n",
      "global round: 185  client: 44  local train loss: 0.8775\n",
      "global round: 185  client: 07  local train loss: 0.9716\n",
      "global round: 185  client: 71  local train loss: 0.9930\n",
      "global round: 185  client: 46  local train loss: 0.8915\n",
      "global round: 185  client: 59  local train loss: 0.9467\n",
      "global round: 185  avg train loss:0.0832  global test loss: 0.7686  global test accu: 0.8547\n",
      "================================================================================================================\n",
      "global round: 186  client: 45  local train loss: 0.8846\n",
      "global round: 186  client: 56  local train loss: 0.9031\n",
      "global round: 186  client: 36  local train loss: 0.9445\n",
      "global round: 186  client: 40  local train loss: 0.8480\n",
      "global round: 186  client: 52  local train loss: 0.9172\n",
      "global round: 186  client: 99  local train loss: 1.0634\n",
      "global round: 186  client: 46  local train loss: 0.8956\n",
      "global round: 186  client: 72  local train loss: 0.8975\n",
      "global round: 186  client: 04  local train loss: 0.8774\n",
      "global round: 186  client: 17  local train loss: 0.9215\n",
      "global round: 186  avg train loss:0.0832  global test loss: 0.7658  global test accu: 0.8554\n",
      "================================================================================================================\n",
      "global round: 187  client: 77  local train loss: 0.9346\n",
      "global round: 187  client: 85  local train loss: 0.8566\n",
      "global round: 187  client: 01  local train loss: 0.8560\n",
      "global round: 187  client: 84  local train loss: 0.8750\n",
      "global round: 187  client: 95  local train loss: 0.9235\n",
      "global round: 187  client: 63  local train loss: 0.8416\n",
      "global round: 187  client: 70  local train loss: 0.8947\n",
      "global round: 187  client: 79  local train loss: 0.8902\n",
      "global round: 187  client: 76  local train loss: 0.8872\n",
      "global round: 187  client: 68  local train loss: 0.9949\n",
      "global round: 187  avg train loss:0.0814  global test loss: 0.7631  global test accu: 0.8553\n",
      "================================================================================================================\n",
      "global round: 188  client: 21  local train loss: 0.8478\n",
      "global round: 188  client: 61  local train loss: 0.9170\n",
      "global round: 188  client: 37  local train loss: 0.9564\n",
      "global round: 188  client: 19  local train loss: 0.8833\n",
      "global round: 188  client: 49  local train loss: 0.8875\n",
      "global round: 188  client: 42  local train loss: 0.8847\n",
      "global round: 188  client: 15  local train loss: 0.8994\n",
      "global round: 188  client: 55  local train loss: 0.8945\n",
      "global round: 188  client: 92  local train loss: 0.8180\n",
      "global round: 188  client: 31  local train loss: 0.8300\n",
      "global round: 188  avg train loss:0.0802  global test loss: 0.7601  global test accu: 0.8554\n",
      "================================================================================================================\n",
      "global round: 189  client: 66  local train loss: 0.9281\n",
      "global round: 189  client: 11  local train loss: 0.9043\n",
      "global round: 189  client: 28  local train loss: 0.9168\n",
      "global round: 189  client: 26  local train loss: 0.9347\n",
      "global round: 189  client: 20  local train loss: 0.9305\n",
      "global round: 189  client: 05  local train loss: 0.8957\n",
      "global round: 189  client: 40  local train loss: 0.8391\n",
      "global round: 189  client: 06  local train loss: 0.9991\n",
      "global round: 189  client: 77  local train loss: 0.9113\n",
      "global round: 189  client: 80  local train loss: 0.9271\n",
      "global round: 189  avg train loss:0.0835  global test loss: 0.7581  global test accu: 0.8556\n",
      "================================================================================================================\n",
      "global round: 190  client: 11  local train loss: 0.8510\n",
      "global round: 190  client: 34  local train loss: 0.8771\n",
      "global round: 190  client: 44  local train loss: 0.8665\n",
      "global round: 190  client: 75  local train loss: 0.9390\n",
      "global round: 190  client: 83  local train loss: 0.8802\n",
      "global round: 190  client: 73  local train loss: 0.8846\n",
      "global round: 190  client: 69  local train loss: 0.8906\n",
      "global round: 190  client: 21  local train loss: 0.8184\n",
      "global round: 190  client: 77  local train loss: 0.9040\n",
      "global round: 190  client: 45  local train loss: 0.8512\n",
      "global round: 190  avg train loss:0.0797  global test loss: 0.7539  global test accu: 0.8555\n",
      "================================================================================================================\n",
      "global round: 191  client: 24  local train loss: 0.9195\n",
      "global round: 191  client: 05  local train loss: 0.8788\n",
      "global round: 191  client: 37  local train loss: 0.8464\n",
      "global round: 191  client: 63  local train loss: 0.8145\n",
      "global round: 191  client: 42  local train loss: 0.8707\n",
      "global round: 191  client: 36  local train loss: 0.9177\n",
      "global round: 191  client: 54  local train loss: 0.8628\n",
      "global round: 191  client: 32  local train loss: 0.8588\n",
      "global round: 191  client: 21  local train loss: 0.8169\n",
      "global round: 191  client: 00  local train loss: 0.8899\n",
      "global round: 191  avg train loss:0.0789  global test loss: 0.7498  global test accu: 0.8557\n",
      "================================================================================================================\n",
      "global round: 192  client: 64  local train loss: 0.8923\n",
      "global round: 192  client: 90  local train loss: 0.8271\n",
      "global round: 192  client: 93  local train loss: 0.9069\n",
      "global round: 192  client: 03  local train loss: 0.9659\n",
      "global round: 192  client: 41  local train loss: 0.9123\n",
      "global round: 192  client: 73  local train loss: 0.8598\n",
      "global round: 192  client: 11  local train loss: 0.8485\n",
      "global round: 192  client: 35  local train loss: 0.8994\n",
      "global round: 192  client: 22  local train loss: 0.9092\n",
      "global round: 192  client: 40  local train loss: 0.8393\n",
      "global round: 192  avg train loss:0.0806  global test loss: 0.7477  global test accu: 0.8562\n",
      "================================================================================================================\n",
      "global round: 193  client: 76  local train loss: 0.8562\n",
      "global round: 193  client: 31  local train loss: 0.8136\n",
      "global round: 193  client: 61  local train loss: 0.8966\n",
      "global round: 193  client: 89  local train loss: 0.8732\n",
      "global round: 193  client: 86  local train loss: 0.8806\n",
      "global round: 193  client: 79  local train loss: 0.8699\n",
      "global round: 193  client: 18  local train loss: 0.8830\n",
      "global round: 193  client: 60  local train loss: 0.9340\n",
      "global round: 193  client: 49  local train loss: 0.8772\n",
      "global round: 193  client: 97  local train loss: 0.9264\n",
      "global round: 193  avg train loss:0.0801  global test loss: 0.7451  global test accu: 0.8563\n",
      "================================================================================================================\n",
      "global round: 194  client: 54  local train loss: 0.8450\n",
      "global round: 194  client: 70  local train loss: 0.8713\n",
      "global round: 194  client: 68  local train loss: 0.9067\n",
      "global round: 194  client: 11  local train loss: 0.8455\n",
      "global round: 194  client: 28  local train loss: 0.8811\n",
      "global round: 194  client: 15  local train loss: 0.8773\n",
      "global round: 194  client: 10  local train loss: 0.8670\n",
      "global round: 194  client: 69  local train loss: 0.8624\n",
      "global round: 194  client: 89  local train loss: 0.8339\n",
      "global round: 194  client: 48  local train loss: 0.9552\n",
      "global round: 194  avg train loss:0.0795  global test loss: 0.7416  global test accu: 0.8572\n",
      "================================================================================================================\n",
      "global round: 195  client: 27  local train loss: 0.8371\n",
      "global round: 195  client: 13  local train loss: 0.8597\n",
      "global round: 195  client: 50  local train loss: 0.8777\n",
      "global round: 195  client: 92  local train loss: 0.8166\n",
      "global round: 195  client: 73  local train loss: 0.8611\n",
      "global round: 195  client: 05  local train loss: 0.8742\n",
      "global round: 195  client: 51  local train loss: 0.9682\n",
      "global round: 195  client: 90  local train loss: 0.7977\n",
      "global round: 195  client: 06  local train loss: 0.8856\n",
      "global round: 195  client: 23  local train loss: 0.8841\n",
      "global round: 195  avg train loss:0.0787  global test loss: 0.7397  global test accu: 0.8573\n",
      "================================================================================================================\n",
      "global round: 196  client: 56  local train loss: 0.9024\n",
      "global round: 196  client: 06  local train loss: 0.8712\n",
      "global round: 196  client: 55  local train loss: 0.8804\n",
      "global round: 196  client: 81  local train loss: 0.9169\n",
      "global round: 196  client: 72  local train loss: 0.8881\n",
      "global round: 196  client: 98  local train loss: 0.9008\n",
      "global round: 196  client: 15  local train loss: 0.8553\n",
      "global round: 196  client: 37  local train loss: 0.8324\n",
      "global round: 196  client: 02  local train loss: 0.8488\n",
      "global round: 196  client: 38  local train loss: 0.9041\n",
      "global round: 196  avg train loss:0.0800  global test loss: 0.7375  global test accu: 0.8578\n",
      "================================================================================================================\n",
      "global round: 197  client: 45  local train loss: 0.8383\n",
      "global round: 197  client: 54  local train loss: 0.8323\n",
      "global round: 197  client: 73  local train loss: 0.8502\n",
      "global round: 197  client: 16  local train loss: 0.8721\n",
      "global round: 197  client: 91  local train loss: 0.9242\n",
      "global round: 197  client: 19  local train loss: 0.8645\n",
      "global round: 197  client: 96  local train loss: 0.8943\n",
      "global round: 197  client: 59  local train loss: 0.9026\n",
      "global round: 197  client: 78  local train loss: 0.8987\n",
      "global round: 197  client: 01  local train loss: 0.8471\n",
      "global round: 197  avg train loss:0.0793  global test loss: 0.7355  global test accu: 0.8577\n",
      "================================================================================================================\n",
      "global round: 198  client: 07  local train loss: 0.8735\n",
      "global round: 198  client: 02  local train loss: 0.8147\n",
      "global round: 198  client: 67  local train loss: 0.8483\n",
      "global round: 198  client: 29  local train loss: 1.0200\n",
      "global round: 198  client: 13  local train loss: 0.8377\n",
      "global round: 198  client: 36  local train loss: 0.8999\n",
      "global round: 198  client: 97  local train loss: 0.8577\n",
      "global round: 198  client: 56  local train loss: 0.8665\n",
      "global round: 198  client: 04  local train loss: 0.8658\n",
      "global round: 198  client: 58  local train loss: 0.8435\n",
      "global round: 198  avg train loss:0.0793  global test loss: 0.7329  global test accu: 0.8581\n",
      "================================================================================================================\n",
      "global round: 199  client: 96  local train loss: 0.8669\n",
      "global round: 199  client: 45  local train loss: 0.8261\n",
      "global round: 199  client: 34  local train loss: 0.8557\n",
      "global round: 199  client: 51  local train loss: 0.8515\n",
      "global round: 199  client: 62  local train loss: 0.8321\n",
      "global round: 199  client: 38  local train loss: 0.8207\n",
      "global round: 199  client: 26  local train loss: 0.9091\n",
      "global round: 199  client: 18  local train loss: 0.8606\n",
      "global round: 199  client: 47  local train loss: 0.8574\n",
      "global round: 199  client: 81  local train loss: 0.8498\n",
      "global round: 199  avg train loss:0.0775  global test loss: 0.7295  global test accu: 0.8581\n",
      "================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# different init point\n",
    "histories, client = federated_learning(iid = True,\n",
    "                                       same_init = False,\n",
    "                                       client_equal_size = True,\n",
    "                                       num_global_round = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e648b5-474e-47a3-9b26-0d31e9e68b36",
   "metadata": {},
   "source": [
    "### different init point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86ff907f-c3bf-4544-998b-05ae91095bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (16, 4)) \n",
    "\n",
    "num_global_round = len(histories[\"local_train_losses\"])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_global_round + 1), histories[\"local_train_losses\"], label = 'avg local train loss')\n",
    "plt.plot(range(1, num_global_round + 1), histories[\"global_test_losses\"], label = 'global test loss')\n",
    "plt.xlabel('global round')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_global_round + 1), histories[\"global_test_accus\"], label = 'global test accus')\n",
    "plt.xlabel('global round')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
